{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gmplot\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "import dataLoader\n",
    "import torchTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %run torchTrain.ipynb\n",
    "# 上面这种引用ipynb的格式就不能带前面类的名字\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_two_old(list,number,b,k):\n",
    "    new_list = torch.tensor(list)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in new_list:\n",
    "        lat.append(i[0])\n",
    "        lng.append(i[1])\n",
    "    old_lat = torch.stack(lat[:k-1])\n",
    "    old_lng =torch.stack(lng[:k-1])\n",
    "    print(old_lat)\n",
    "    print(old_lng)\n",
    "    lat_predict = (lat[k-1:])\n",
    "    lng_predict = (lng[k-1:])\n",
    "    print(lat_predict)\n",
    "    print(lng_predict)\n",
    "    lat = torch.stack(lat)\n",
    "    lng =torch.stack(lng)\n",
    "    gmap = gmplot.GoogleMapPlotter(lat[0], lng[0], b)\n",
    "    gmap.plot(lat, lng,color='b',lw=20)  #描绘轨迹点\n",
    "    gmap.plot(lat_predict, lng_predict,color='r',lw=20)  #描绘轨迹点\n",
    "    gmap.draw(\"user{}.html\".format(number))   #显示图\n",
    "    print(\"over\")\n",
    "\n",
    "\n",
    "def draw(list,number):\n",
    "    new_list = torch.tensor(list)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in new_list:\n",
    "        lat.append(i[0])\n",
    "        lng.append(i[1])\n",
    "    lat = torch.stack(lat)#拼接出来的环境是多了一层结构\n",
    "    lng =torch.stack(lng)\n",
    "    gmap = gmplot.GoogleMapPlotter(lat[0], lng[0], 20)\n",
    "    gmap.plot(lat, lng,color='b',lw=20)  #描绘轨迹点\n",
    "    # gmap.plot(lat_predict, lng_predict,color='r',lw=20)  #描绘轨迹点\n",
    "    gmap.draw(\"user{}.html\".format(number))   #显示图\n",
    "    print(\"over\")\n",
    "\n",
    "def draw_two_new(list_pre,list_real,promot):\n",
    "    lat_pre, lng_pre = change_list_to_lat_lng(list_pre)\n",
    "    lat_real, lng_real = change_list_to_lat_lng(list_real)\n",
    "    gmap = gmplot.GoogleMapPlotter(lat_pre[0], lng_pre[0], 20)# 前面2个参数定义了center\n",
    "    gmap.plot(lat_pre, lng_pre,color='b',lw=30)  #描绘轨迹点\n",
    "    gmap.plot(lat_real, lng_real,color='r',lw=30)  #描绘轨迹点\n",
    "    gmap.draw(\"user{}.html\".format(promot))   #显示图\n",
    "    print(\"over\")\n",
    "\n",
    "def change_list_to_lat_lng(list):\n",
    "    new_list = torch.tensor(list)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in new_list:\n",
    "        lat.append(i[0])\n",
    "        lng.append(i[1])\n",
    "    lat = torch.stack(lat)#拼接出来的环境是多了一层结构\n",
    "    lng =torch.stack(lng)\n",
    "    return lat, lng\n",
    "# 搞一个批量训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_level : 8\n",
      "Train_h3_list SIZE : 22025\n",
      "Test_h3_list SIZE : 9327\n",
      "the train_data appear in test_data : 11737\n",
      "the test_data appear in train_data : 6716\n",
      "vocab_size : 590\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# coincide_number= 0\n",
    "# coincide = np.zeros(Train_h3_list.size)\n",
    "#\n",
    "\n",
    "\n",
    "train_dataloader,test_dataloader,vocab, Train_h3_list, Test_h3_list  = dataLoader.DataLoader.load_h3_list()\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False).fit(vocab.reshape(-1, 1))\n",
    "\n",
    "#这个函数现在没有用上\n",
    "def encoding(data):\n",
    "    return encoder.transform(data.reshape(-1,1))\n",
    "def decoding(one_hot_data):\n",
    "    return encoder.inverse_transform(one_hot_data)\n",
    "\n",
    "\n",
    "# 可以通过idnex找到对应的h3\n",
    "index_h  = dict(enumerate(vocab))\n",
    "\n",
    "# 可以通过h3编码找到对应的index\n",
    "h_index ={h3:i for i ,h3 in index_h.items()}\n",
    "\n",
    "\n",
    "def label_encode(data):\n",
    "    return np.array([h_index[ch] for ch in data])\n",
    "def label_decode(data):\n",
    "    return np.array([index_h[ch] for ch in data])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def test_dataloader(y,k):\n",
    "# 现在相当于是在往前看10步\n",
    "\n",
    "#暂时不加批量训练\n",
    "# def data_loader(dataset,batchsize,drop_last=True):\n",
    "#     for i in range(0,len(dataset)-batchsize+1,batchsize):\n",
    "#         batch = dataset[i:i+batchsize]\n",
    "#         batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.num_hiddens = 255\n",
    "        self.model =nn.LSTM(\n",
    "            input_size=vocab,\n",
    "            hidden_size=self.num_hiddens,\n",
    "            batch_first=True,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(self.num_hiddens,vocab)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x , state):\n",
    "        r_out, states= self.model(x.view(1,10,self.vocab) ,state)\n",
    "        outdata = self.output(r_out[:,-1,:])\n",
    "        return outdata, states\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        return (torch.zeros((\n",
    "            self.model.num_layers,\n",
    "            batch_size, self.num_hiddens), device=device),\n",
    "                torch.zeros((\n",
    "                    self.model.num_layers,\n",
    "                    batch_size, self.num_hiddens), device=device))\n",
    "\n",
    "net = RNN(len(vocab)).to(device)\n",
    "# net=nn.DataParallel(net) #这个暂时先别用\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.1,momentum=0.8)\n",
    "optimizer_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "loss_function = nn.CrossEntropyLoss()#输入是没有softmax的，这个函数是自己softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]C:\\Users\\Administrator\\.conda\\envs\\AISUStech\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Epochs60 | 0---------------\n",
      "average Train Loss : 1.733773315069271 , train acc : 0.7069725187372247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [05:48<5:42:38, 348.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.39003971235376195 \n",
      "--------------Epochs60 | 1---------------\n",
      "average Train Loss : 1.2793572919032479 , train acc : 0.768703156938451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [10:49<5:10:05, 320.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.39315230224321135 \n",
      "--------------Epochs60 | 2---------------\n",
      "average Train Loss : 0.910010220304338 , train acc : 0.8164887576652282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [15:55<4:58:06, 313.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.3868197917784695 \n",
      "--------------Epochs60 | 3---------------\n",
      "average Train Loss : 0.6915179902197366 , train acc : 0.8511469452645923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/60 [20:54<4:47:25, 307.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.38875174412364494 \n",
      "--------------Epochs60 | 4---------------\n",
      "average Train Loss : 0.57344193589598 , train acc : 0.8682716329775153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [25:52<4:38:55, 304.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.3934742943007406 \n",
      "--------------Epochs60 | 5---------------\n",
      "average Train Loss : 0.505959493172269 , train acc : 0.8800817624347036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [30:50<4:31:59, 302.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.39540624664591606 \n",
      "--------------Epochs60 | 6---------------\n",
      "average Train Loss : 0.4554950992221213 , train acc : 0.8903474903474904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [35:47<4:25:24, 300.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.3969088762477192 \n",
      "--------------Epochs60 | 7---------------\n",
      "average Train Loss : 0.4316457706393368 , train acc : 0.89697933227345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8/60 [40:45<4:19:41, 299.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.2231404958677686 \n",
      "--------------Epochs60 | 8---------------\n",
      "average Train Loss : 0.4168662967720872 , train acc : 0.8965250965250965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9/60 [45:43<4:14:30, 299.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.21916926049157454 \n",
      "--------------Epochs60 | 9---------------\n",
      "average Train Loss : 0.45104487529809223 , train acc : 0.8978423801953214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10/60 [50:57<4:13:12, 303.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.1917999356015885 \n",
      "--------------Epochs60 | 10---------------\n",
      "average Train Loss : 0.42429522484669546 , train acc : 0.8963434022257551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [56:00<4:07:47, 303.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.17140710529140282 \n",
      "--------------Epochs60 | 11---------------\n",
      "average Train Loss : 0.4413136728508971 , train acc : 0.8970701794231206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [1:01:08<4:03:52, 304.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.17870559192873242 \n",
      "--------------Epochs60 | 12---------------\n",
      "average Train Loss : 0.44883775089427663 , train acc : 0.8951623892800363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 13/60 [1:06:56<4:09:01, 317.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.13480734141891168 \n",
      "--------------Epochs60 | 13---------------\n",
      "average Train Loss : 0.5164257235833523 , train acc : 0.888575970928912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 14/60 [1:12:23<4:05:46, 320.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.34388751744123647 \n",
      "--------------Epochs60 | 14---------------\n",
      "average Train Loss : 0.5519119598853055 , train acc : 0.8874858051328639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 15/60 [1:17:47<4:01:13, 321.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.01652892561983471 \n",
      "--------------Epochs60 | 15---------------\n",
      "average Train Loss : 0.5735480868867817 , train acc : 0.8841244605950488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16/60 [1:23:57<4:06:44, 336.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.02329075882794891 \n",
      "--------------Epochs60 | 16---------------\n",
      "average Train Loss : 0.545814998296616 , train acc : 0.8837610719963661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 17/60 [1:30:19<4:10:45, 349.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.02919394654931845 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "epoches = 5\n",
    "\n",
    "\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "for epoch in trange(epoches):\n",
    "\n",
    "\n",
    "    optimizer_scheduler.step()\n",
    "    optimizer.step()\n",
    "\n",
    "    how_many_instance, loss_, how_many_instance_right = torchTrain.train_epoch(net,train_dataloader,loss_function,optimizer,device,top_k,label_decode,label_encode,encoder)\n",
    "\n",
    "    train_loss.append(loss_.cpu().detach().numpy() / how_many_instance)\n",
    "    train_acc.append(how_many_instance_right / how_many_instance)\n",
    "    print(f'--------------Epochs{epoches} | {epoch}---------------')\n",
    "    print(f'average Train Loss : {train_loss[-1]} , train acc : {train_acc[-1]}')\n",
    "\n",
    "    # if epoch%5 == 0:\n",
    "    how_many_instance, how_many_instance_right, predict_answer_list, real_answer_list = torchTrain.predict_epoch(net,test_dataloader,device,top_k,label_decode,encoder)\n",
    "\n",
    "    test_acc.append(how_many_instance_right / how_many_instance )\n",
    "    print(f'test accuracy : { test_acc[-1]} ')\n",
    "\n",
    "\n",
    "plt.plot(train_acc, label='Average Train Accuracy')\n",
    "plt.plot(train_loss, label='Average Train Loss')\n",
    "plt.plot(test_acc, label='test_acc')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# top_k = 5\n",
    "# name_id = 1\n",
    "# how_many_instance, how_many_instance_right, predict_answer_list = torchTrain.predict_epoch(net,test_dataloader,device,top_k,label_decode,encoder)\n",
    "# predict_answer_geo_list = dataLoader.h3_t_geo(predict_answer_list)\n",
    "# # old=h3_t_geo(i.tolist())\n",
    "# # total_list = old+predict\n",
    "# # print(total_list)\n",
    "# draw(predict_answer_geo_list,name_id,20,10)\n",
    "# name_id+=1\n",
    "#\n",
    "# print(predict_answer_list)\n",
    "#\n",
    "# torch.save(net,\"model_2022_4_8.pt\")\n",
    "top_k = 5\n",
    "name_id = 1\n",
    "\n",
    "# how_many_instance, how_many_instance_right, predict_answer_list, real_answer_list = torchTrain.predict_epoch(net,test_dataloader,device,top_k,label_decode,encoder)\n",
    "how_many_instance, how_many_instance_right, predict_answer_list, real_answer_list = torchTrain.predict_epoch(net,test_dataloader,device,top_k,label_decode,encoder)\n",
    "# print(predict_answer_list)\n",
    "predict_answer_geo_list = dataLoader.h3_t_geo(predict_answer_list)\n",
    "real_answer_geo_list = dataLoader.h3_t_geo(real_answer_list)\n",
    "# old=h3_t_geo(i.tolist())\n",
    "# total_list = old+predict\n",
    "# print(total_list)\n",
    "# draw(predict_answer_geo_list,1)\n",
    "# draw(real_answer_geo_list,2)\n",
    "draw_two_new(predict_answer_geo_list,real_answer_geo_list,\"prepare\")\n",
    "name_id+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}