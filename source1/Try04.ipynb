{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgmplot\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "File \u001B[1;32m~\\.conda\\envs\\limuconda\\lib\\site-packages\\torch\\__init__.py:711\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jit \u001B[38;5;28;01mas\u001B[39;00m jit\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m linalg \u001B[38;5;28;01mas\u001B[39;00m linalg\n\u001B[1;32m--> 711\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hub \u001B[38;5;28;01mas\u001B[39;00m hub\n\u001B[0;32m    712\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m random \u001B[38;5;28;01mas\u001B[39;00m random\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distributions \u001B[38;5;28;01mas\u001B[39;00m distributions\n",
      "File \u001B[1;32m~\\.conda\\envs\\limuconda\\lib\\site-packages\\torch\\hub.py:18\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m urlparse  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 18\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm  \u001B[38;5;66;03m# automatically select proper tqdm submodule if available\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\limuconda\\lib\\site-packages\\tqdm\\__init__.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_monitor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TMonitor, TqdmSynchronisationWarning\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tqdm_pandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm_pandas\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcli\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m main  \u001B[38;5;66;03m# TODO: remove in v5.0.0\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgui\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm \u001B[38;5;28;01mas\u001B[39;00m tqdm_gui  \u001B[38;5;66;03m# TODO: remove in v5.0.0\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgui\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m trange \u001B[38;5;28;01mas\u001B[39;00m tgrange  \u001B[38;5;66;03m# TODO: remove in v5.0.0\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\limuconda\\lib\\site-packages\\tqdm\\cli.py:10\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mast\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m literal_eval \u001B[38;5;28;01mas\u001B[39;00m numeric\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TqdmKeyError, TqdmTypeError, tqdm\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[0;32m     12\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     13\u001B[0m log \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\limuconda\\lib\\site-packages\\tqdm\\version.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"`tqdm` version detector. Precedence: installed dist, git, 'UNKNOWN'.\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_dist_ver\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:991\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:975\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:671\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:779\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:868\u001B[0m, in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1012\u001B[0m, in \u001B[0;36mpath_stats\u001B[1;34m(self, path)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:87\u001B[0m, in \u001B[0;36m_path_stat\u001B[1;34m(path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import gmplot\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import time\n",
    "from tqdm import trange\n",
    "import h3\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "import move_fromd2l as d2l\n",
    "\n",
    "def geo_t_h3(data):\n",
    "    h3_list =OrderedDict()\n",
    "\n",
    "    for i in data:\n",
    "        a = h3.geo_to_h3(i[0], i[1], 10)\n",
    "        h3_list.setdefault(a)\n",
    "    return h3_list\n",
    "def h3_t_geo(data):\n",
    "    new_list = []\n",
    "    for i in data:\n",
    "        i =h3.h3_to_geo(i)\n",
    "        new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "# draw(,130,10)\n",
    "# list,文件名，放大率\n",
    "def draw(list,number,b):\n",
    "    new_list = torch.tensor(list)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in new_list:\n",
    "        lat.append(i[0])\n",
    "        lng.append(i[1])\n",
    "    lat = torch.stack(lat)\n",
    "    lng =torch.stack(lng)\n",
    "    gmap = gmplot.GoogleMapPlotter(lat[0], lng[0], b)\n",
    "    gmap.plot(lat, lng,color='r',lw=10)  #描绘轨迹点\n",
    "    gmap.draw(\"user{}.html\".format(number))   #显示图\n",
    "    print(\"over\")\n",
    "# 这个提取出来有5个维度\n",
    "def dataset(user,start,end,step):\n",
    "    # user:第几个用户\n",
    "    # filenumber:取前面几天数据\n",
    "    # step：隔了多少步取一次\n",
    "    # userdata =  '.\\\\Geolife Trajectories 1.3\\\\Data\\\\' + user + '\\\\Trajectory\\\\'\n",
    "    # print(os.listdir('..'))路径老大难，主义当前文件位置\n",
    "    userdata='../Geolife Trajectories 1.3/Data/'+user+'/Trajectory/'\n",
    "    print(userdata)\n",
    "    filelist = os.listdir(userdata)  #返回指定路径下所有文件和文件夹的名字，并存放于一个列表中\n",
    "    filelist.sort()\n",
    "    names = ['lat','lng','zero','alt','days','date','time']\n",
    "    df_list = [# f为文件索引号，header为列数，names为列表列名，index_col为行索引的列编号或列名\n",
    "        pd.read_csv(userdata + f,header=6,names=names,index_col=False)\n",
    "    #隔行读取\n",
    "        for f in filelist[start:end]]\n",
    "    df = pd.concat(df_list, ignore_index=True) #表格列字段不同的表合并\n",
    "    df.drop(['zero', 'days'], axis=1, inplace=True) #drop函数默认删除行，列需要加axis = 1\n",
    "    df_min = df.iloc[::step, :]\n",
    "    return df_min\n",
    "# 这个提取出来有2个维度\n",
    "def synthetic_data(df_min):\n",
    "    a =df_min['lat'].tolist()\n",
    "    b = df_min['lng'].tolist()\n",
    "    a = torch.tensor(a,dtype=torch.float,requires_grad=True).reshape((-1, 1))\n",
    "    b = torch.tensor(b,dtype=torch.float,requires_grad=True).reshape((-1, 1))\n",
    "    features = torch.concat([a,b],1)\n",
    "    return features\n",
    "# 将(lat,lng)变成哈希值\n",
    "def generate_h3_list(data):\n",
    "    alist = geo_t_h3(data)\n",
    "    LIST = list(alist.keys())\n",
    "    return np.array(LIST)\n",
    "\n",
    "\n",
    "# 这个提取出来有5个维度\n",
    "train_dataset = dataset(\"006\",0,20,60)\n",
    "test_dataset =  dataset(\"006\",20,25,60)\n",
    "\n",
    "# 这个提取出来有2个维度，只保留经纬度了\n",
    "train_data = synthetic_data(train_dataset)\n",
    "test_data = synthetic_data(test_dataset)\n",
    "# concat()\n",
    "all_data =torch.concat([train_data,test_data],0)\n",
    "\n",
    "\n",
    "\n",
    "Train_h3_list  = generate_h3_list(train_data)\n",
    "# print(Train_h3_list)这个相当于是h3\n",
    "TESETLIST  = generate_h3_list(test_data)\n",
    "all_data_h3_list = generate_h3_list(all_data)\n",
    "# 这个all_data_h3_list可以先shuffle一下\n",
    "\n",
    "\n",
    "# 可以通过idnex找到对应的h3\n",
    "vocab_reverse  = dict(enumerate(all_data_h3_list))\n",
    "# 可以通过h3编码找到对应的index\n",
    "vocab ={h3:i for i ,h3 in vocab_reverse.items()}\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False).fit(all_data_h3_list.reshape(-1,1))\n",
    "\n",
    "#y是一个列表，k是步长\n",
    "def dataloader(y,k):\n",
    "    data =[]\n",
    "    for i in range(len(y)-k+1):\n",
    "        indata = y[i:i+k]\n",
    "        outdata = y[i+k:i+k+1]\n",
    "        data.append((indata,outdata))\n",
    "    return data\n",
    "train_dataloader = dataloader(Train_h3_list,10)\n",
    "test_dataloader =dataloader(test_data,10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 提升：\n",
    "# 1。如何生成能够进行批训练的dataloader\n",
    "# 2。修改学习率,步子长短,取样的时间达到更好的效果\n",
    "# 3。现在的预测只能预测下一个点，如果想预测轨迹，应当把预测的点也当作数据输入模型\n",
    "# 4.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.model =nn.LSTM(\n",
    "            input_size=vocab,\n",
    "            hidden_size=320,\n",
    "            batch_first=True,\n",
    "            bias=True\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(320,vocab),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        r_out,(h_out,c_out) = self.model(x.view(1,10,self.vocab) ,None)\n",
    "        outdata = self.output(r_out[:,-1,:])\n",
    "        return outdata\n",
    "net = RNN(len(all_data_h3_list))\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.1,momentum=0.8)\n",
    "optimizer_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in trange(1000):\n",
    "    loss_ =0\n",
    "    for i , k in train_dataloader[:-1]:\n",
    "        optimizer.zero_grad()\n",
    "        a = encoder.transform(i.reshape(-1,1))\n",
    "        k = encoder.transform(k.reshape(-1,1))\n",
    "        a =torch.tensor(a).to(torch.float32)\n",
    "        k =torch.tensor(k).to(torch.float32)\n",
    "        loss = loss_function(net(a),k)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ = loss_+loss\n",
    "    print(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "test_dataloader = dataloader(TESETLIST,10)\n",
    "\n",
    "# 能否根据当前的预测取进行下一步的预测\n",
    "lat_l =[]\n",
    "for i , k in test_dataloader[:-1]:\n",
    "        a = encoder.transform(i.reshape(-1,1))\n",
    "        k = encoder.transform(k.reshape(-1,1))\n",
    "        a =torch.tensor(a).to(torch.float32)\n",
    "        k =torch.tensor(k).to(torch.float32)\n",
    "        out = net(a)\n",
    "        out = out.detach().numpy()\n",
    "        index = np.argmax(out)\n",
    "        print(index)\n",
    "        d =vocab_reverse.get(index)\n",
    "        f = h3.h3_to_geo(str(d))\n",
    "        lat_l.append(f)\n",
    "\n",
    "draw(lat_l,150,10)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}