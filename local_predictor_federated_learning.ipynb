{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from model import LocalPredictor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/fan/UsersInOsakaProcessed/20121101_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121102_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121103_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121104_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121105_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121106_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121107_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121108_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121109_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121110_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121111_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121112_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121113_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121114_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121115_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121116_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121117_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121118_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121119_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121120_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121121_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121122_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121123_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121124_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121125_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121126_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121127_interp.pk\n",
      "/data/fan/UsersInOsakaProcessed/20121128_interp.pk\n"
     ]
    }
   ],
   "source": [
    "data = dict({})\n",
    "for d in range(1, 29):\n",
    "    filename = '/data/fan/UsersInOsakaProcessed/201211{:02d}_interp.pk'.format(d)\n",
    "    print(filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        data[d] = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_sets = dict({})\n",
    "for d in data:\n",
    "    uid_sets[d] = set(list(data[d].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_doc_set = set([])\n",
    "for d in range(1, 15):\n",
    "    uid_doc_set = uid_doc_set | uid_sets[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_doc = dict({})\n",
    "data_qry_train = dict({})\n",
    "data_qry_test = dict({})\n",
    "\n",
    "for d in range(1, 15):\n",
    "    for uid in data[d]:\n",
    "        if uid not in data_doc:\n",
    "            data_doc[uid] = [data[d][uid]]\n",
    "        else:\n",
    "            data_doc[uid].append(data[d][uid])\n",
    "\n",
    "for d in range(15, 22):\n",
    "    for uid in data[d]:\n",
    "        if uid not in data_qry_train:\n",
    "            data_qry_train[uid] = [data[d][uid]]\n",
    "        else:\n",
    "            data_qry_train[uid].append(data[d][uid])\n",
    "            \n",
    "for d in range(22, 29):\n",
    "    for uid in data[d]:\n",
    "        if uid not in data_qry_test:\n",
    "            data_qry_test[uid] = [data[d][uid]]\n",
    "        else:\n",
    "            data_qry_test[uid].append(data[d][uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in data_doc:\n",
    "    data_doc[uid] = torch.LongTensor(data_doc[uid]).cuda(1)\n",
    "\n",
    "for uid in data_qry_train:\n",
    "    data_qry_train[uid] = torch.LongTensor(data_qry_train[uid]).cuda(1)\n",
    "    \n",
    "for uid in data_qry_test:\n",
    "    data_qry_test[uid] = torch.LongTensor(data_qry_test[uid]).cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locs = 1600\n",
    "loc_embedding_dim = 128\n",
    "T = 96\n",
    "num_time = T\n",
    "time_embedding_dim = 32\n",
    "hidden_dim = 256\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor = LocalPredictor(num_locs, loc_embedding_dim, num_time, time_embedding_dim, hidden_dim, latent_dim).cuda(1)\n",
    "local_predictor_server = LocalPredictor(num_locs, loc_embedding_dim, num_time, time_embedding_dim, hidden_dim, latent_dim).cuda(1)\n",
    "optimizer = torch.optim.SGD(local_predictor.parameters(), lr=lr)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dT = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = dict({})\n",
    "validation_loss = dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list_train = list(data_qry_train.keys())\n",
    "time_list = list(range(T - 2 * dT + 1))\n",
    "\n",
    "# Initialize global SGD\n",
    "local_predictor_update = dict({})\n",
    "        \n",
    "for epoch in range(1, 4001):\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        lr *= 0.5\n",
    "    \n",
    "    update_user_list = random.sample(user_list_train, 2048)\n",
    "    random.shuffle(update_user_list)\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    cnt = 0\n",
    "    n = 0\n",
    "    \n",
    "    uidx = 0\n",
    "    \n",
    "    for uid in update_user_list:\n",
    "        uidx += 1\n",
    "        # loading server model to local\n",
    "        local_predictor.load_state_dict(local_predictor_server.state_dict())\n",
    "\n",
    "        nk = data_qry_train[uid].shape[0]\n",
    "        n += data_qry_train[uid].shape[0]\n",
    "\n",
    "        t = np.random.randint(T - 2 * dT + 1)\n",
    "        x_loc_qry = data_qry_train[uid][:, t: t + dT]\n",
    "        x_t_qry = torch.zeros_like(x_loc_qry) + t\n",
    "        y = data_qry_train[uid][:, t + 2 * dT - 1]\n",
    "\n",
    "        if uid not in data_doc:\n",
    "            loss = local_predictor(x_loc_qry, x_t_qry, None, None, y)\n",
    "        else:\n",
    "            x_loc_doc = data_doc[uid][:, t: t + 2 * dT]\n",
    "            x_t_doc = torch.zeros_like(x_loc_doc) + t\n",
    "            loss = local_predictor(x_loc_qry, x_t_qry, x_loc_doc, x_t_doc, y)\n",
    "\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        cnt += nk\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for name, para in local_predictor.named_parameters():\n",
    "                if para.grad is None:\n",
    "                    continue\n",
    "                elif name not in local_predictor_update:\n",
    "                    local_predictor_update[name] = (para.grad + torch.randn_like(para.grad) * 1e-2) * lr\n",
    "                else:\n",
    "                    local_predictor_update[name] += (para.grad + torch.randn_like(para.grad) * 1e-2) * lr\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Epoch {:02d}, {:.1f}%, avg_loss = {:.4f}'.format(epoch, uidx * 100 / len(update_user_list), avg_loss / cnt), end='\\r')\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        for name, para in local_predictor_server.named_parameters():\n",
    "            para -= local_predictor_update[name]\n",
    "            \n",
    "        for name in local_predictor_update:\n",
    "            local_predictor_update[name] *= momentum\n",
    "    \n",
    "    training_loss[epoch] = avg_loss / cnt\n",
    "    print('')\n",
    "    # testing\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            cnt = 0\n",
    "            avg_loss = 0.0\n",
    "\n",
    "            for uid in data_qry_test:\n",
    "\n",
    "                if np.random.ranf() > 0.05:\n",
    "                    continue\n",
    "\n",
    "                nk = data_qry_test[uid].shape[0]\n",
    "\n",
    "                t = np.random.randint(T - 2 * dT + 1)\n",
    "                x_loc_qry = data_qry_test[uid][:, t: t + dT]\n",
    "                x_t_qry = torch.zeros_like(x_loc_qry) + t\n",
    "                y = data_qry_test[uid][:, t + 2 * dT - 1]\n",
    "\n",
    "                if uid not in data_doc:\n",
    "                    loss = local_predictor_server(x_loc_qry, x_t_qry, None, None, y)\n",
    "                else:\n",
    "                    x_loc_doc = data_doc[uid][:, t: t + 2 * dT]\n",
    "                    x_t_doc = torch.zeros_like(x_loc_doc) + t\n",
    "                    loss = local_predictor_server(x_loc_qry, x_t_qry, x_loc_doc, x_t_doc, y)\n",
    "\n",
    "                avg_loss += loss.item()\n",
    "                cnt += nk\n",
    "\n",
    "            print('Validation Loss: {:.4f}'.format(avg_loss / cnt))\n",
    "            validation_loss[epoch] = avg_loss / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, 100.0%, avg_loss = 7.3795\n",
      "Epoch 02, 100.0%, avg_loss = 7.2845\n",
      "Epoch 03, 100.0%, avg_loss = 7.0945\n",
      "Epoch 04, 100.0%, avg_loss = 6.8151\n",
      "Epoch 05, 100.0%, avg_loss = 6.4295\n",
      "Validation Loss: 6.2226\n",
      "Epoch 06, 100.0%, avg_loss = 6.1004\n",
      "Epoch 07, 100.0%, avg_loss = 5.6692\n",
      "Epoch 08, 100.0%, avg_loss = 5.1676\n",
      "Epoch 09, 100.0%, avg_loss = 4.6220\n",
      "Epoch 10, 100.0%, avg_loss = 4.0262\n",
      "Validation Loss: 3.6390\n",
      "Epoch 11, 100.0%, avg_loss = 3.6241\n",
      "Epoch 12, 100.0%, avg_loss = 3.3216\n",
      "Epoch 13, 100.0%, avg_loss = 3.1746\n",
      "Epoch 14, 100.0%, avg_loss = 2.9315\n",
      "Epoch 15, 100.0%, avg_loss = 2.7485\n",
      "Validation Loss: 2.8675\n",
      "Epoch 16, 100.0%, avg_loss = 2.8898\n",
      "Epoch 17, 100.0%, avg_loss = 2.6990\n",
      "Epoch 18, 100.0%, avg_loss = 2.4582\n",
      "Epoch 19, 100.0%, avg_loss = 2.5521\n",
      "Epoch 20, 100.0%, avg_loss = 2.5039\n",
      "Validation Loss: 2.5392\n",
      "Epoch 21, 100.0%, avg_loss = 2.5431\n",
      "Epoch 22, 100.0%, avg_loss = 2.3621\n",
      "Epoch 23, 100.0%, avg_loss = 2.3590\n",
      "Epoch 24, 100.0%, avg_loss = 2.4526\n",
      "Epoch 25, 100.0%, avg_loss = 2.3812\n",
      "Validation Loss: 2.3947\n",
      "Epoch 26, 100.0%, avg_loss = 2.3320\n",
      "Epoch 27, 100.0%, avg_loss = 2.2847\n",
      "Epoch 28, 100.0%, avg_loss = 2.1923\n",
      "Epoch 29, 100.0%, avg_loss = 2.1593\n",
      "Epoch 30, 100.0%, avg_loss = 2.0997\n",
      "Validation Loss: 2.1897\n",
      "Epoch 31, 100.0%, avg_loss = 2.2111\n",
      "Epoch 32, 100.0%, avg_loss = 2.1207\n",
      "Epoch 33, 100.0%, avg_loss = 2.1393\n",
      "Epoch 34, 100.0%, avg_loss = 2.1066\n",
      "Epoch 35, 100.0%, avg_loss = 2.0969\n",
      "Validation Loss: 2.1984\n",
      "Epoch 36, 100.0%, avg_loss = 2.1217\n",
      "Epoch 37, 100.0%, avg_loss = 2.0577\n",
      "Epoch 38, 100.0%, avg_loss = 1.9893\n",
      "Epoch 39, 100.0%, avg_loss = 2.0101\n",
      "Epoch 40, 100.0%, avg_loss = 2.0023\n",
      "Validation Loss: 2.1553\n",
      "Epoch 41, 100.0%, avg_loss = 1.9291\n",
      "Epoch 42, 100.0%, avg_loss = 2.0065\n",
      "Epoch 43, 100.0%, avg_loss = 1.9813\n",
      "Epoch 44, 100.0%, avg_loss = 2.0962\n",
      "Epoch 45, 100.0%, avg_loss = 1.8779\n",
      "Validation Loss: 2.2206\n",
      "Epoch 46, 100.0%, avg_loss = 2.0106\n",
      "Epoch 47, 100.0%, avg_loss = 2.1271\n",
      "Epoch 48, 100.0%, avg_loss = 2.0470\n",
      "Epoch 49, 100.0%, avg_loss = 2.0519\n",
      "Epoch 50, 100.0%, avg_loss = 2.1352\n",
      "Validation Loss: 2.0995\n",
      "Epoch 51, 100.0%, avg_loss = 2.0386\n",
      "Epoch 52, 100.0%, avg_loss = 2.0483\n",
      "Epoch 53, 100.0%, avg_loss = 2.0507\n",
      "Epoch 54, 100.0%, avg_loss = 1.9562\n",
      "Epoch 55, 100.0%, avg_loss = 1.9356\n",
      "Validation Loss: 2.1709\n",
      "Epoch 56, 100.0%, avg_loss = 1.9687\n",
      "Epoch 57, 100.0%, avg_loss = 1.9697\n",
      "Epoch 58, 100.0%, avg_loss = 1.9542\n",
      "Epoch 59, 100.0%, avg_loss = 1.8585\n",
      "Epoch 60, 100.0%, avg_loss = 1.8730\n",
      "Validation Loss: 2.0029\n",
      "Epoch 61, 100.0%, avg_loss = 1.8460\n",
      "Epoch 62, 100.0%, avg_loss = 1.8756\n",
      "Epoch 63, 100.0%, avg_loss = 1.8879\n",
      "Epoch 64, 100.0%, avg_loss = 1.8176\n",
      "Epoch 65, 100.0%, avg_loss = 1.7666\n",
      "Validation Loss: 1.8721\n",
      "Epoch 66, 100.0%, avg_loss = 1.8145\n",
      "Epoch 67, 100.0%, avg_loss = 1.7934\n",
      "Epoch 68, 100.0%, avg_loss = 1.7879\n",
      "Epoch 69, 100.0%, avg_loss = 1.8559\n",
      "Epoch 70, 100.0%, avg_loss = 1.7776\n",
      "Validation Loss: 1.8694\n",
      "Epoch 71, 100.0%, avg_loss = 1.7440\n",
      "Epoch 72, 100.0%, avg_loss = 1.7486\n",
      "Epoch 73, 100.0%, avg_loss = 1.8031\n",
      "Epoch 74, 100.0%, avg_loss = 1.7994\n",
      "Epoch 75, 100.0%, avg_loss = 1.7814\n",
      "Validation Loss: 1.8006\n",
      "Epoch 76, 100.0%, avg_loss = 1.7679\n",
      "Epoch 77, 100.0%, avg_loss = 1.7597\n",
      "Epoch 78, 100.0%, avg_loss = 1.7800\n",
      "Epoch 79, 100.0%, avg_loss = 1.7194\n",
      "Epoch 80, 100.0%, avg_loss = 1.7013\n",
      "Validation Loss: 1.8231\n",
      "Epoch 81, 100.0%, avg_loss = 1.7345\n",
      "Epoch 82, 100.0%, avg_loss = 1.7111\n",
      "Epoch 83, 100.0%, avg_loss = 1.5902\n",
      "Epoch 84, 100.0%, avg_loss = 1.7229\n",
      "Epoch 85, 100.0%, avg_loss = 1.7880\n",
      "Validation Loss: 1.8500\n",
      "Epoch 86, 100.0%, avg_loss = 1.7647\n",
      "Epoch 87, 100.0%, avg_loss = 1.6744\n",
      "Epoch 88, 100.0%, avg_loss = 1.6684\n",
      "Epoch 89, 100.0%, avg_loss = 1.7203\n",
      "Epoch 90, 100.0%, avg_loss = 1.6602\n",
      "Validation Loss: 1.7749\n",
      "Epoch 91, 100.0%, avg_loss = 1.6189\n",
      "Epoch 92, 100.0%, avg_loss = 1.7077\n",
      "Epoch 93, 100.0%, avg_loss = 1.6867\n",
      "Epoch 94, 100.0%, avg_loss = 1.7239\n",
      "Epoch 95, 100.0%, avg_loss = 1.6942\n",
      "Validation Loss: 1.7751\n",
      "Epoch 96, 100.0%, avg_loss = 1.7093\n",
      "Epoch 97, 100.0%, avg_loss = 1.6756\n",
      "Epoch 98, 100.0%, avg_loss = 1.6907\n",
      "Epoch 99, 100.0%, avg_loss = 1.5981\n",
      "Epoch 100, 100.0%, avg_loss = 1.6467\n",
      "Validation Loss: 1.7154\n",
      "Epoch 101, 100.0%, avg_loss = 1.6240\n",
      "Epoch 102, 100.0%, avg_loss = 1.6383\n",
      "Epoch 103, 100.0%, avg_loss = 1.6472\n",
      "Epoch 104, 100.0%, avg_loss = 1.6493\n",
      "Epoch 105, 100.0%, avg_loss = 1.7059\n",
      "Validation Loss: 1.7378\n",
      "Epoch 106, 100.0%, avg_loss = 1.6333\n",
      "Epoch 107, 100.0%, avg_loss = 1.6679\n",
      "Epoch 108, 100.0%, avg_loss = 1.5955\n",
      "Epoch 109, 100.0%, avg_loss = 1.5938\n",
      "Epoch 110, 100.0%, avg_loss = 1.5568\n",
      "Validation Loss: 1.7652\n",
      "Epoch 111, 100.0%, avg_loss = 1.6381\n",
      "Epoch 112, 100.0%, avg_loss = 1.5565\n",
      "Epoch 113, 100.0%, avg_loss = 1.6332\n",
      "Epoch 114, 100.0%, avg_loss = 1.6273\n",
      "Epoch 115, 100.0%, avg_loss = 1.6499\n",
      "Validation Loss: 1.7253\n",
      "Epoch 116, 100.0%, avg_loss = 1.6072\n",
      "Epoch 117, 100.0%, avg_loss = 1.6282\n",
      "Epoch 118, 100.0%, avg_loss = 1.6384\n",
      "Epoch 119, 100.0%, avg_loss = 1.5881\n",
      "Epoch 120, 100.0%, avg_loss = 1.5318\n",
      "Validation Loss: 1.7118\n",
      "Epoch 121, 100.0%, avg_loss = 1.6169\n",
      "Epoch 122, 100.0%, avg_loss = 1.5671\n",
      "Epoch 123, 100.0%, avg_loss = 1.5873\n",
      "Epoch 124, 100.0%, avg_loss = 1.5544\n",
      "Epoch 125, 100.0%, avg_loss = 1.5486\n",
      "Validation Loss: 1.6851\n",
      "Epoch 126, 100.0%, avg_loss = 1.5919\n",
      "Epoch 127, 100.0%, avg_loss = 1.5984\n",
      "Epoch 128, 100.0%, avg_loss = 1.5457\n",
      "Epoch 129, 100.0%, avg_loss = 1.5928\n",
      "Epoch 130, 100.0%, avg_loss = 1.4722\n",
      "Validation Loss: 1.7087\n",
      "Epoch 131, 100.0%, avg_loss = 1.5624\n",
      "Epoch 132, 100.0%, avg_loss = 1.6418\n",
      "Epoch 133, 100.0%, avg_loss = 1.5934\n",
      "Epoch 134, 100.0%, avg_loss = 1.5201\n",
      "Epoch 135, 100.0%, avg_loss = 1.5770\n",
      "Validation Loss: 1.6935\n",
      "Epoch 136, 100.0%, avg_loss = 1.6212\n",
      "Epoch 137, 100.0%, avg_loss = 1.5601\n",
      "Epoch 138, 100.0%, avg_loss = 1.5898\n",
      "Epoch 139, 100.0%, avg_loss = 1.5594\n",
      "Epoch 140, 100.0%, avg_loss = 1.5119\n",
      "Validation Loss: 1.6320\n",
      "Epoch 141, 100.0%, avg_loss = 1.5786\n",
      "Epoch 142, 100.0%, avg_loss = 1.5136\n",
      "Epoch 143, 100.0%, avg_loss = 1.5520\n",
      "Epoch 144, 100.0%, avg_loss = 1.5934\n",
      "Epoch 145, 100.0%, avg_loss = 1.6164\n",
      "Validation Loss: 1.6531\n",
      "Epoch 146, 100.0%, avg_loss = 1.6205\n",
      "Epoch 147, 100.0%, avg_loss = 1.6000\n",
      "Epoch 148, 100.0%, avg_loss = 1.5007\n",
      "Epoch 149, 100.0%, avg_loss = 1.5722\n",
      "Epoch 150, 100.0%, avg_loss = 1.5657\n",
      "Validation Loss: 1.6623\n",
      "Epoch 151, 100.0%, avg_loss = 1.5731\n",
      "Epoch 152, 100.0%, avg_loss = 1.4990\n",
      "Epoch 153, 100.0%, avg_loss = 1.5508\n",
      "Epoch 154, 100.0%, avg_loss = 1.5253\n",
      "Epoch 155, 100.0%, avg_loss = 1.4997\n",
      "Validation Loss: 1.6410\n",
      "Epoch 156, 100.0%, avg_loss = 1.5084\n",
      "Epoch 157, 100.0%, avg_loss = 1.5689\n",
      "Epoch 158, 100.0%, avg_loss = 1.5096\n",
      "Epoch 159, 100.0%, avg_loss = 1.5134\n",
      "Epoch 160, 100.0%, avg_loss = 1.4435\n",
      "Validation Loss: 1.6301\n",
      "Epoch 161, 100.0%, avg_loss = 1.5967\n",
      "Epoch 162, 100.0%, avg_loss = 1.5555\n",
      "Epoch 163, 100.0%, avg_loss = 1.5206\n",
      "Epoch 164, 100.0%, avg_loss = 1.5060\n",
      "Epoch 165, 100.0%, avg_loss = 1.4691\n",
      "Validation Loss: 1.5886\n",
      "Epoch 166, 100.0%, avg_loss = 1.5322\n",
      "Epoch 167, 100.0%, avg_loss = 1.4680\n",
      "Epoch 168, 100.0%, avg_loss = 1.5061\n",
      "Epoch 169, 100.0%, avg_loss = 1.5161\n",
      "Epoch 170, 100.0%, avg_loss = 1.5407\n",
      "Validation Loss: 1.6154\n",
      "Epoch 171, 100.0%, avg_loss = 1.4589\n",
      "Epoch 172, 100.0%, avg_loss = 1.5874\n",
      "Epoch 173, 100.0%, avg_loss = 1.4772\n",
      "Epoch 174, 100.0%, avg_loss = 1.4717\n",
      "Epoch 175, 100.0%, avg_loss = 1.5462\n",
      "Validation Loss: 1.5837\n",
      "Epoch 176, 100.0%, avg_loss = 1.4684\n",
      "Epoch 177, 100.0%, avg_loss = 1.5366\n",
      "Epoch 178, 100.0%, avg_loss = 1.4637\n",
      "Epoch 179, 100.0%, avg_loss = 1.4923\n",
      "Epoch 180, 100.0%, avg_loss = 1.5576\n",
      "Validation Loss: 1.5954\n",
      "Epoch 181, 100.0%, avg_loss = 1.4390\n",
      "Epoch 182, 100.0%, avg_loss = 1.5193\n",
      "Epoch 183, 100.0%, avg_loss = 1.4594\n",
      "Epoch 184, 100.0%, avg_loss = 1.4791\n",
      "Epoch 185, 100.0%, avg_loss = 1.4927\n",
      "Validation Loss: 1.6043\n",
      "Epoch 186, 100.0%, avg_loss = 1.5344\n",
      "Epoch 187, 100.0%, avg_loss = 1.5203\n",
      "Epoch 188, 100.0%, avg_loss = 1.5173\n",
      "Epoch 189, 100.0%, avg_loss = 1.5802\n",
      "Epoch 190, 100.0%, avg_loss = 1.4928\n",
      "Validation Loss: 1.6484\n",
      "Epoch 191, 100.0%, avg_loss = 1.4506\n",
      "Epoch 192, 100.0%, avg_loss = 1.5041\n",
      "Epoch 193, 100.0%, avg_loss = 1.4652\n",
      "Epoch 194, 100.0%, avg_loss = 1.4873\n",
      "Epoch 195, 100.0%, avg_loss = 1.4548\n",
      "Validation Loss: 1.6119\n",
      "Epoch 196, 100.0%, avg_loss = 1.4754\n",
      "Epoch 197, 100.0%, avg_loss = 1.5106\n",
      "Epoch 198, 100.0%, avg_loss = 1.5103\n",
      "Epoch 199, 100.0%, avg_loss = 1.4568\n",
      "Epoch 200, 100.0%, avg_loss = 1.5038\n",
      "Validation Loss: 1.5883\n",
      "Epoch 201, 100.0%, avg_loss = 1.4876\n",
      "Epoch 202, 100.0%, avg_loss = 1.4336\n",
      "Epoch 203, 100.0%, avg_loss = 1.4961\n",
      "Epoch 204, 100.0%, avg_loss = 1.4146\n",
      "Epoch 205, 100.0%, avg_loss = 1.4847\n",
      "Validation Loss: 1.6001\n",
      "Epoch 206, 100.0%, avg_loss = 1.5271\n",
      "Epoch 207, 100.0%, avg_loss = 1.4661\n",
      "Epoch 208, 100.0%, avg_loss = 1.4163\n",
      "Epoch 209, 100.0%, avg_loss = 1.4678\n",
      "Epoch 210, 100.0%, avg_loss = 1.4148\n",
      "Validation Loss: 1.5955\n",
      "Epoch 211, 100.0%, avg_loss = 1.4539\n",
      "Epoch 212, 100.0%, avg_loss = 1.4786\n",
      "Epoch 213, 100.0%, avg_loss = 1.5024\n",
      "Epoch 214, 100.0%, avg_loss = 1.4857\n",
      "Epoch 215, 100.0%, avg_loss = 1.4213\n",
      "Validation Loss: 1.5741\n",
      "Epoch 216, 100.0%, avg_loss = 1.3937\n",
      "Epoch 217, 100.0%, avg_loss = 1.4750\n",
      "Epoch 218, 100.0%, avg_loss = 1.4978\n",
      "Epoch 219, 100.0%, avg_loss = 1.4961\n",
      "Epoch 220, 100.0%, avg_loss = 1.4527\n",
      "Validation Loss: 1.5854\n",
      "Epoch 221, 100.0%, avg_loss = 1.4878\n",
      "Epoch 222, 100.0%, avg_loss = 1.4766\n",
      "Epoch 223, 100.0%, avg_loss = 1.4814\n",
      "Epoch 224, 100.0%, avg_loss = 1.4777\n",
      "Epoch 225, 100.0%, avg_loss = 1.4910\n",
      "Validation Loss: 1.5542\n",
      "Epoch 226, 100.0%, avg_loss = 1.4152\n",
      "Epoch 227, 100.0%, avg_loss = 1.4571\n",
      "Epoch 228, 100.0%, avg_loss = 1.5064\n",
      "Epoch 229, 100.0%, avg_loss = 1.4498\n",
      "Epoch 230, 100.0%, avg_loss = 1.4141\n",
      "Validation Loss: 1.5776\n",
      "Epoch 231, 100.0%, avg_loss = 1.4319\n",
      "Epoch 232, 100.0%, avg_loss = 1.4571\n",
      "Epoch 233, 100.0%, avg_loss = 1.4833\n",
      "Epoch 234, 100.0%, avg_loss = 1.5098\n",
      "Epoch 235, 100.0%, avg_loss = 1.4076\n",
      "Validation Loss: 1.6016\n",
      "Epoch 236, 100.0%, avg_loss = 1.4329\n",
      "Epoch 237, 100.0%, avg_loss = 1.4863\n",
      "Epoch 238, 100.0%, avg_loss = 1.5085\n",
      "Epoch 239, 100.0%, avg_loss = 1.4584\n",
      "Epoch 240, 100.0%, avg_loss = 1.4079\n",
      "Validation Loss: 1.5049\n",
      "Epoch 241, 100.0%, avg_loss = 1.4653\n",
      "Epoch 242, 100.0%, avg_loss = 1.5044\n",
      "Epoch 243, 100.0%, avg_loss = 1.4287\n",
      "Epoch 244, 100.0%, avg_loss = 1.4948\n",
      "Epoch 245, 100.0%, avg_loss = 1.4640\n",
      "Validation Loss: 1.5911\n",
      "Epoch 246, 100.0%, avg_loss = 1.4153\n",
      "Epoch 247, 100.0%, avg_loss = 1.4756\n",
      "Epoch 248, 100.0%, avg_loss = 1.4361\n",
      "Epoch 249, 100.0%, avg_loss = 1.4206\n",
      "Epoch 250, 100.0%, avg_loss = 1.4137\n",
      "Validation Loss: 1.5177\n",
      "Epoch 251, 100.0%, avg_loss = 1.3628\n",
      "Epoch 252, 100.0%, avg_loss = 1.4479\n",
      "Epoch 253, 100.0%, avg_loss = 1.4752\n",
      "Epoch 254, 100.0%, avg_loss = 1.5119\n",
      "Epoch 255, 100.0%, avg_loss = 1.4433\n",
      "Validation Loss: 1.5017\n",
      "Epoch 256, 100.0%, avg_loss = 1.4743\n",
      "Epoch 257, 100.0%, avg_loss = 1.4447\n",
      "Epoch 258, 100.0%, avg_loss = 1.4468\n",
      "Epoch 259, 100.0%, avg_loss = 1.4307\n",
      "Epoch 260, 100.0%, avg_loss = 1.4668\n",
      "Validation Loss: 1.5800\n",
      "Epoch 261, 100.0%, avg_loss = 1.4748\n",
      "Epoch 262, 100.0%, avg_loss = 1.4275\n",
      "Epoch 263, 100.0%, avg_loss = 1.4093\n",
      "Epoch 264, 100.0%, avg_loss = 1.4008\n",
      "Epoch 265, 100.0%, avg_loss = 1.4992\n",
      "Validation Loss: 1.5413\n",
      "Epoch 266, 100.0%, avg_loss = 1.4991\n",
      "Epoch 267, 100.0%, avg_loss = 1.3666\n",
      "Epoch 268, 100.0%, avg_loss = 1.4713\n",
      "Epoch 269, 100.0%, avg_loss = 1.4139\n",
      "Epoch 270, 100.0%, avg_loss = 1.4475\n",
      "Validation Loss: 1.5374\n",
      "Epoch 271, 100.0%, avg_loss = 1.4874\n",
      "Epoch 272, 100.0%, avg_loss = 1.4450\n",
      "Epoch 273, 100.0%, avg_loss = 1.4725\n",
      "Epoch 274, 100.0%, avg_loss = 1.3622\n",
      "Epoch 275, 100.0%, avg_loss = 1.4890\n",
      "Validation Loss: 1.5450\n",
      "Epoch 276, 100.0%, avg_loss = 1.4462\n",
      "Epoch 277, 100.0%, avg_loss = 1.4628\n",
      "Epoch 278, 100.0%, avg_loss = 1.4536\n",
      "Epoch 279, 100.0%, avg_loss = 1.4379\n",
      "Epoch 280, 100.0%, avg_loss = 1.4108\n",
      "Validation Loss: 1.5734\n",
      "Epoch 281, 100.0%, avg_loss = 1.4189\n",
      "Epoch 282, 100.0%, avg_loss = 1.4013\n",
      "Epoch 283, 100.0%, avg_loss = 1.3935\n",
      "Epoch 284, 100.0%, avg_loss = 1.4196\n",
      "Epoch 285, 100.0%, avg_loss = 1.4947\n",
      "Validation Loss: 1.5049\n",
      "Epoch 286, 100.0%, avg_loss = 1.4538\n",
      "Epoch 287, 100.0%, avg_loss = 1.3978\n",
      "Epoch 288, 100.0%, avg_loss = 1.4765\n",
      "Epoch 289, 100.0%, avg_loss = 1.4398\n",
      "Epoch 290, 100.0%, avg_loss = 1.4315\n",
      "Validation Loss: 1.4972\n",
      "Epoch 291, 100.0%, avg_loss = 1.4820\n",
      "Epoch 292, 100.0%, avg_loss = 1.4515\n",
      "Epoch 293, 100.0%, avg_loss = 1.4218\n",
      "Epoch 294, 100.0%, avg_loss = 1.4011\n",
      "Epoch 295, 100.0%, avg_loss = 1.4386\n",
      "Validation Loss: 1.4491\n",
      "Epoch 296, 100.0%, avg_loss = 1.4227\n",
      "Epoch 297, 100.0%, avg_loss = 1.5456\n",
      "Epoch 298, 100.0%, avg_loss = 1.3980\n",
      "Epoch 299, 100.0%, avg_loss = 1.4233\n",
      "Epoch 300, 100.0%, avg_loss = 1.4737\n",
      "Validation Loss: 1.4789\n",
      "Epoch 301, 100.0%, avg_loss = 1.4071\n",
      "Epoch 302, 100.0%, avg_loss = 1.3967\n",
      "Epoch 303, 100.0%, avg_loss = 1.3796\n",
      "Epoch 304, 100.0%, avg_loss = 1.4159\n",
      "Epoch 305, 100.0%, avg_loss = 1.4119\n",
      "Validation Loss: 1.5143\n",
      "Epoch 306, 100.0%, avg_loss = 1.3848\n",
      "Epoch 307, 100.0%, avg_loss = 1.4066\n",
      "Epoch 308, 100.0%, avg_loss = 1.3871\n",
      "Epoch 309, 100.0%, avg_loss = 1.4505\n",
      "Epoch 310, 100.0%, avg_loss = 1.4476\n",
      "Validation Loss: 1.4829\n",
      "Epoch 311, 100.0%, avg_loss = 1.3858\n",
      "Epoch 312, 100.0%, avg_loss = 1.4447\n",
      "Epoch 313, 100.0%, avg_loss = 1.3502\n",
      "Epoch 314, 100.0%, avg_loss = 1.4445\n",
      "Epoch 315, 100.0%, avg_loss = 1.4608\n",
      "Validation Loss: 1.4600\n",
      "Epoch 316, 100.0%, avg_loss = 1.3799\n",
      "Epoch 317, 100.0%, avg_loss = 1.4763\n",
      "Epoch 318, 100.0%, avg_loss = 1.4207\n",
      "Epoch 319, 100.0%, avg_loss = 1.4154\n",
      "Epoch 320, 100.0%, avg_loss = 1.3605\n",
      "Validation Loss: 1.4575\n",
      "Epoch 321, 100.0%, avg_loss = 1.4805\n",
      "Epoch 322, 100.0%, avg_loss = 1.4270\n",
      "Epoch 323, 100.0%, avg_loss = 1.4120\n",
      "Epoch 324, 100.0%, avg_loss = 1.4270\n",
      "Epoch 325, 100.0%, avg_loss = 1.4437\n",
      "Validation Loss: 1.4771\n",
      "Epoch 326, 100.0%, avg_loss = 1.2898\n",
      "Epoch 327, 100.0%, avg_loss = 1.4053\n",
      "Epoch 328, 100.0%, avg_loss = 1.3434\n",
      "Epoch 329, 100.0%, avg_loss = 1.3567\n",
      "Epoch 330, 100.0%, avg_loss = 1.3956\n",
      "Validation Loss: 1.4803\n",
      "Epoch 331, 100.0%, avg_loss = 1.4543\n",
      "Epoch 332, 100.0%, avg_loss = 1.3177\n",
      "Epoch 333, 100.0%, avg_loss = 1.4452\n",
      "Epoch 334, 100.0%, avg_loss = 1.4087\n",
      "Epoch 335, 100.0%, avg_loss = 1.3837\n",
      "Validation Loss: 1.4906\n",
      "Epoch 336, 100.0%, avg_loss = 1.3430\n",
      "Epoch 337, 100.0%, avg_loss = 1.3975\n",
      "Epoch 338, 100.0%, avg_loss = 1.4048\n",
      "Epoch 339, 100.0%, avg_loss = 1.3938\n",
      "Epoch 340, 100.0%, avg_loss = 1.3225\n",
      "Validation Loss: 1.5155\n",
      "Epoch 341, 100.0%, avg_loss = 1.4742\n",
      "Epoch 342, 100.0%, avg_loss = 1.3246\n",
      "Epoch 343, 100.0%, avg_loss = 1.4117\n",
      "Epoch 344, 100.0%, avg_loss = 1.3879\n",
      "Epoch 345, 100.0%, avg_loss = 1.4075\n",
      "Validation Loss: 1.5213\n",
      "Epoch 346, 100.0%, avg_loss = 1.4072\n",
      "Epoch 347, 100.0%, avg_loss = 1.3783\n",
      "Epoch 348, 100.0%, avg_loss = 1.3784\n",
      "Epoch 349, 100.0%, avg_loss = 1.3945\n",
      "Epoch 350, 100.0%, avg_loss = 1.4202\n",
      "Validation Loss: 1.5038\n",
      "Epoch 351, 100.0%, avg_loss = 1.3894\n",
      "Epoch 352, 100.0%, avg_loss = 1.3948\n",
      "Epoch 353, 100.0%, avg_loss = 1.4031\n",
      "Epoch 354, 100.0%, avg_loss = 1.4207\n",
      "Epoch 355, 100.0%, avg_loss = 1.3549\n",
      "Validation Loss: 1.4945\n",
      "Epoch 356, 100.0%, avg_loss = 1.3709\n",
      "Epoch 357, 100.0%, avg_loss = 1.3709\n",
      "Epoch 358, 100.0%, avg_loss = 1.4440\n",
      "Epoch 359, 100.0%, avg_loss = 1.4230\n",
      "Epoch 360, 100.0%, avg_loss = 1.4178\n",
      "Validation Loss: 1.4919\n",
      "Epoch 361, 100.0%, avg_loss = 1.3962\n",
      "Epoch 362, 100.0%, avg_loss = 1.3608\n",
      "Epoch 363, 100.0%, avg_loss = 1.4384\n",
      "Epoch 364, 100.0%, avg_loss = 1.3125\n",
      "Epoch 365, 100.0%, avg_loss = 1.4059\n",
      "Validation Loss: 1.4152\n",
      "Epoch 366, 100.0%, avg_loss = 1.4023\n",
      "Epoch 367, 100.0%, avg_loss = 1.3851\n",
      "Epoch 368, 100.0%, avg_loss = 1.3989\n",
      "Epoch 369, 100.0%, avg_loss = 1.3627\n",
      "Epoch 370, 100.0%, avg_loss = 1.3849\n",
      "Validation Loss: 1.4486\n",
      "Epoch 371, 100.0%, avg_loss = 1.4255\n",
      "Epoch 372, 100.0%, avg_loss = 1.3606\n",
      "Epoch 373, 100.0%, avg_loss = 1.3369\n",
      "Epoch 374, 100.0%, avg_loss = 1.3564\n",
      "Epoch 375, 100.0%, avg_loss = 1.4209\n",
      "Validation Loss: 1.4673\n",
      "Epoch 376, 100.0%, avg_loss = 1.4760\n",
      "Epoch 377, 100.0%, avg_loss = 1.3571\n",
      "Epoch 378, 100.0%, avg_loss = 1.4043\n",
      "Epoch 379, 100.0%, avg_loss = 1.3973\n",
      "Epoch 380, 100.0%, avg_loss = 1.4460\n",
      "Validation Loss: 1.4805\n",
      "Epoch 381, 100.0%, avg_loss = 1.3752\n",
      "Epoch 382, 100.0%, avg_loss = 1.3598\n",
      "Epoch 383, 100.0%, avg_loss = 1.4227\n",
      "Epoch 384, 100.0%, avg_loss = 1.3772\n",
      "Epoch 385, 100.0%, avg_loss = 1.4472\n",
      "Validation Loss: 1.4949\n",
      "Epoch 386, 100.0%, avg_loss = 1.3354\n",
      "Epoch 387, 100.0%, avg_loss = 1.3823\n",
      "Epoch 388, 100.0%, avg_loss = 1.4534\n",
      "Epoch 389, 100.0%, avg_loss = 1.4009\n",
      "Epoch 390, 100.0%, avg_loss = 1.4322\n",
      "Validation Loss: 1.4972\n",
      "Epoch 391, 100.0%, avg_loss = 1.3932\n",
      "Epoch 392, 100.0%, avg_loss = 1.3588\n",
      "Epoch 393, 100.0%, avg_loss = 1.3926\n",
      "Epoch 394, 100.0%, avg_loss = 1.3217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395, 100.0%, avg_loss = 1.4057\n",
      "Validation Loss: 1.4092\n",
      "Epoch 396, 100.0%, avg_loss = 1.3064\n",
      "Epoch 397, 100.0%, avg_loss = 1.4039\n",
      "Epoch 398, 100.0%, avg_loss = 1.3944\n",
      "Epoch 399, 100.0%, avg_loss = 1.3503\n",
      "Epoch 400, 100.0%, avg_loss = 1.4623\n",
      "Validation Loss: 1.5816\n",
      "Epoch 401, 100.0%, avg_loss = 1.3510\n",
      "Epoch 402, 100.0%, avg_loss = 1.3711\n",
      "Epoch 403, 100.0%, avg_loss = 1.4255\n",
      "Epoch 404, 100.0%, avg_loss = 1.3563\n",
      "Epoch 405, 100.0%, avg_loss = 1.3539\n",
      "Validation Loss: 1.5343\n",
      "Epoch 406, 100.0%, avg_loss = 1.4452\n",
      "Epoch 407, 100.0%, avg_loss = 1.3553\n",
      "Epoch 408, 100.0%, avg_loss = 1.4289\n",
      "Epoch 409, 100.0%, avg_loss = 1.4356\n",
      "Epoch 410, 100.0%, avg_loss = 1.3561\n",
      "Validation Loss: 1.4788\n",
      "Epoch 411, 100.0%, avg_loss = 1.3404\n",
      "Epoch 412, 100.0%, avg_loss = 1.3970\n",
      "Epoch 413, 100.0%, avg_loss = 1.3426\n",
      "Epoch 414, 100.0%, avg_loss = 1.4584\n",
      "Epoch 415, 100.0%, avg_loss = 1.3622\n",
      "Validation Loss: 1.5212\n",
      "Epoch 416, 100.0%, avg_loss = 1.4012\n",
      "Epoch 417, 100.0%, avg_loss = 1.3927\n",
      "Epoch 418, 100.0%, avg_loss = 1.3824\n",
      "Epoch 419, 100.0%, avg_loss = 1.4153\n",
      "Epoch 420, 100.0%, avg_loss = 1.3805\n",
      "Validation Loss: 1.4788\n",
      "Epoch 421, 100.0%, avg_loss = 1.3777\n",
      "Epoch 422, 100.0%, avg_loss = 1.3554\n",
      "Epoch 423, 100.0%, avg_loss = 1.3989\n",
      "Epoch 424, 100.0%, avg_loss = 1.4231\n",
      "Epoch 425, 100.0%, avg_loss = 1.3454\n",
      "Validation Loss: 1.4919\n",
      "Epoch 426, 100.0%, avg_loss = 1.3233\n",
      "Epoch 427, 100.0%, avg_loss = 1.3905\n",
      "Epoch 428, 100.0%, avg_loss = 1.4355\n",
      "Epoch 429, 100.0%, avg_loss = 1.3887\n",
      "Epoch 430, 100.0%, avg_loss = 1.3760\n",
      "Validation Loss: 1.4737\n",
      "Epoch 431, 100.0%, avg_loss = 1.4129\n",
      "Epoch 432, 100.0%, avg_loss = 1.3699\n",
      "Epoch 433, 100.0%, avg_loss = 1.3570\n",
      "Epoch 434, 100.0%, avg_loss = 1.3866\n",
      "Epoch 435, 100.0%, avg_loss = 1.3559\n",
      "Validation Loss: 1.5005\n",
      "Epoch 436, 100.0%, avg_loss = 1.3848\n",
      "Epoch 437, 100.0%, avg_loss = 1.4328\n",
      "Epoch 438, 100.0%, avg_loss = 1.2845\n",
      "Epoch 439, 100.0%, avg_loss = 1.3684\n",
      "Epoch 440, 100.0%, avg_loss = 1.4369\n",
      "Validation Loss: 1.4339\n",
      "Epoch 441, 100.0%, avg_loss = 1.3753\n",
      "Epoch 442, 100.0%, avg_loss = 1.3733\n",
      "Epoch 443, 100.0%, avg_loss = 1.4185\n",
      "Epoch 444, 100.0%, avg_loss = 1.3408\n",
      "Epoch 445, 100.0%, avg_loss = 1.3376\n",
      "Validation Loss: 1.4741\n",
      "Epoch 446, 100.0%, avg_loss = 1.3513\n",
      "Epoch 447, 100.0%, avg_loss = 1.3629\n",
      "Epoch 448, 100.0%, avg_loss = 1.4105\n",
      "Epoch 449, 100.0%, avg_loss = 1.4394\n",
      "Epoch 450, 100.0%, avg_loss = 1.4334\n",
      "Validation Loss: 1.4716\n",
      "Epoch 451, 100.0%, avg_loss = 1.4534\n",
      "Epoch 452, 100.0%, avg_loss = 1.4032\n",
      "Epoch 453, 100.0%, avg_loss = 1.4413\n",
      "Epoch 454, 100.0%, avg_loss = 1.3631\n",
      "Epoch 455, 100.0%, avg_loss = 1.4093\n",
      "Validation Loss: 1.5081\n",
      "Epoch 456, 100.0%, avg_loss = 1.3211\n",
      "Epoch 457, 100.0%, avg_loss = 1.3852\n",
      "Epoch 458, 100.0%, avg_loss = 1.3640\n",
      "Epoch 459, 100.0%, avg_loss = 1.3761\n",
      "Epoch 460, 100.0%, avg_loss = 1.3937\n",
      "Validation Loss: 1.4380\n",
      "Epoch 461, 100.0%, avg_loss = 1.3935\n",
      "Epoch 462, 100.0%, avg_loss = 1.4463\n",
      "Epoch 463, 100.0%, avg_loss = 1.4006\n",
      "Epoch 464, 100.0%, avg_loss = 1.3843\n",
      "Epoch 465, 100.0%, avg_loss = 1.3715\n",
      "Validation Loss: 1.4538\n",
      "Epoch 466, 100.0%, avg_loss = 1.4390\n",
      "Epoch 467, 100.0%, avg_loss = 1.3665\n",
      "Epoch 468, 100.0%, avg_loss = 1.4064\n",
      "Epoch 469, 100.0%, avg_loss = 1.3316\n",
      "Epoch 470, 100.0%, avg_loss = 1.3222\n",
      "Validation Loss: 1.4253\n",
      "Epoch 471, 100.0%, avg_loss = 1.3467\n",
      "Epoch 472, 100.0%, avg_loss = 1.3472\n",
      "Epoch 473, 100.0%, avg_loss = 1.3744\n",
      "Epoch 474, 100.0%, avg_loss = 1.3977\n",
      "Epoch 475, 100.0%, avg_loss = 1.4816\n",
      "Validation Loss: 1.4718\n",
      "Epoch 476, 100.0%, avg_loss = 1.3938\n",
      "Epoch 477, 100.0%, avg_loss = 1.3501\n",
      "Epoch 478, 100.0%, avg_loss = 1.3493\n",
      "Epoch 479, 100.0%, avg_loss = 1.4049\n",
      "Epoch 480, 100.0%, avg_loss = 1.3807\n",
      "Validation Loss: 1.4580\n",
      "Epoch 481, 100.0%, avg_loss = 1.3137\n",
      "Epoch 482, 100.0%, avg_loss = 1.3597\n",
      "Epoch 483, 100.0%, avg_loss = 1.3757\n",
      "Epoch 484, 100.0%, avg_loss = 1.3709\n",
      "Epoch 485, 100.0%, avg_loss = 1.4203\n",
      "Validation Loss: 1.5322\n",
      "Epoch 486, 100.0%, avg_loss = 1.3309\n",
      "Epoch 487, 100.0%, avg_loss = 1.3584\n",
      "Epoch 488, 100.0%, avg_loss = 1.3838\n",
      "Epoch 489, 100.0%, avg_loss = 1.3845\n",
      "Epoch 490, 100.0%, avg_loss = 1.3842\n",
      "Validation Loss: 1.4497\n",
      "Epoch 491, 100.0%, avg_loss = 1.3350\n",
      "Epoch 492, 100.0%, avg_loss = 1.4294\n",
      "Epoch 493, 100.0%, avg_loss = 1.4042\n",
      "Epoch 494, 100.0%, avg_loss = 1.4091\n",
      "Epoch 495, 100.0%, avg_loss = 1.4024\n",
      "Validation Loss: 1.4688\n",
      "Epoch 496, 100.0%, avg_loss = 1.3863\n",
      "Epoch 497, 100.0%, avg_loss = 1.3448\n",
      "Epoch 498, 100.0%, avg_loss = 1.3728\n",
      "Epoch 499, 100.0%, avg_loss = 1.4012\n",
      "Epoch 500, 100.0%, avg_loss = 1.3722\n",
      "Validation Loss: 1.4706\n",
      "Epoch 501, 100.0%, avg_loss = 1.3674\n",
      "Epoch 502, 100.0%, avg_loss = 1.3665\n",
      "Epoch 503, 100.0%, avg_loss = 1.3776\n",
      "Epoch 504, 100.0%, avg_loss = 1.4218\n",
      "Epoch 505, 100.0%, avg_loss = 1.3529\n",
      "Validation Loss: 1.4606\n",
      "Epoch 506, 100.0%, avg_loss = 1.3621\n",
      "Epoch 507, 100.0%, avg_loss = 1.3552\n",
      "Epoch 508, 100.0%, avg_loss = 1.3872\n",
      "Epoch 509, 100.0%, avg_loss = 1.3086\n",
      "Epoch 510, 100.0%, avg_loss = 1.4342\n",
      "Validation Loss: 1.3856\n",
      "Epoch 511, 100.0%, avg_loss = 1.3028\n",
      "Epoch 512, 100.0%, avg_loss = 1.3129\n",
      "Epoch 513, 100.0%, avg_loss = 1.3431\n",
      "Epoch 514, 100.0%, avg_loss = 1.3227\n",
      "Epoch 515, 100.0%, avg_loss = 1.2943\n",
      "Validation Loss: 1.3665\n",
      "Epoch 516, 100.0%, avg_loss = 1.3556\n",
      "Epoch 517, 100.0%, avg_loss = 1.2893\n",
      "Epoch 518, 100.0%, avg_loss = 1.3617\n",
      "Epoch 519, 100.0%, avg_loss = 1.2747\n",
      "Epoch 520, 100.0%, avg_loss = 1.2438\n",
      "Validation Loss: 1.4079\n",
      "Epoch 521, 100.0%, avg_loss = 1.3741\n",
      "Epoch 522, 100.0%, avg_loss = 1.3449\n",
      "Epoch 523, 100.0%, avg_loss = 1.3476\n",
      "Epoch 524, 100.0%, avg_loss = 1.3240\n",
      "Epoch 525, 100.0%, avg_loss = 1.3477\n",
      "Validation Loss: 1.3756\n",
      "Epoch 526, 100.0%, avg_loss = 1.3475\n",
      "Epoch 527, 100.0%, avg_loss = 1.3432\n",
      "Epoch 528, 100.0%, avg_loss = 1.3263\n",
      "Epoch 529, 100.0%, avg_loss = 1.3458\n",
      "Epoch 530, 100.0%, avg_loss = 1.3544\n",
      "Validation Loss: 1.4043\n",
      "Epoch 531, 100.0%, avg_loss = 1.3372\n",
      "Epoch 532, 100.0%, avg_loss = 1.2885\n",
      "Epoch 533, 100.0%, avg_loss = 1.3465\n",
      "Epoch 534, 100.0%, avg_loss = 1.2796\n",
      "Epoch 535, 100.0%, avg_loss = 1.2825\n",
      "Validation Loss: 1.3682\n",
      "Epoch 536, 100.0%, avg_loss = 1.2748\n",
      "Epoch 537, 100.0%, avg_loss = 1.2877\n",
      "Epoch 538, 100.0%, avg_loss = 1.3110\n",
      "Epoch 539, 100.0%, avg_loss = 1.3177\n",
      "Epoch 540, 100.0%, avg_loss = 1.2968\n",
      "Validation Loss: 1.4513\n",
      "Epoch 541, 100.0%, avg_loss = 1.2961\n",
      "Epoch 542, 100.0%, avg_loss = 1.3622\n",
      "Epoch 543, 100.0%, avg_loss = 1.2604\n",
      "Epoch 544, 100.0%, avg_loss = 1.2687\n",
      "Epoch 545, 100.0%, avg_loss = 1.3449\n",
      "Validation Loss: 1.3677\n",
      "Epoch 546, 100.0%, avg_loss = 1.3324\n",
      "Epoch 547, 100.0%, avg_loss = 1.3133\n",
      "Epoch 548, 100.0%, avg_loss = 1.3253\n",
      "Epoch 549, 100.0%, avg_loss = 1.3004\n",
      "Epoch 550, 100.0%, avg_loss = 1.3095\n",
      "Validation Loss: 1.3694\n",
      "Epoch 551, 100.0%, avg_loss = 1.3195\n",
      "Epoch 552, 100.0%, avg_loss = 1.2422\n",
      "Epoch 553, 100.0%, avg_loss = 1.2928\n",
      "Epoch 554, 100.0%, avg_loss = 1.3609\n",
      "Epoch 555, 100.0%, avg_loss = 1.3247\n",
      "Validation Loss: 1.4291\n",
      "Epoch 556, 100.0%, avg_loss = 1.3208\n",
      "Epoch 557, 100.0%, avg_loss = 1.2875\n",
      "Epoch 558, 100.0%, avg_loss = 1.2946\n",
      "Epoch 559, 100.0%, avg_loss = 1.3433\n",
      "Epoch 560, 100.0%, avg_loss = 1.3228\n",
      "Validation Loss: 1.4700\n",
      "Epoch 561, 100.0%, avg_loss = 1.2959\n",
      "Epoch 562, 100.0%, avg_loss = 1.2758\n",
      "Epoch 563, 100.0%, avg_loss = 1.3355\n",
      "Epoch 564, 100.0%, avg_loss = 1.2967\n",
      "Epoch 565, 100.0%, avg_loss = 1.3304\n",
      "Validation Loss: 1.3646\n",
      "Epoch 566, 100.0%, avg_loss = 1.3487\n",
      "Epoch 567, 100.0%, avg_loss = 1.2680\n",
      "Epoch 568, 100.0%, avg_loss = 1.2967\n",
      "Epoch 569, 100.0%, avg_loss = 1.2553\n",
      "Epoch 570, 100.0%, avg_loss = 1.2860\n",
      "Validation Loss: 1.3490\n",
      "Epoch 571, 100.0%, avg_loss = 1.2885\n",
      "Epoch 572, 100.0%, avg_loss = 1.3384\n",
      "Epoch 573, 100.0%, avg_loss = 1.2629\n",
      "Epoch 574, 100.0%, avg_loss = 1.3424\n",
      "Epoch 575, 100.0%, avg_loss = 1.3425\n",
      "Validation Loss: 1.3267\n",
      "Epoch 576, 100.0%, avg_loss = 1.2997\n",
      "Epoch 577, 100.0%, avg_loss = 1.3077\n",
      "Epoch 578, 100.0%, avg_loss = 1.2781\n",
      "Epoch 579, 100.0%, avg_loss = 1.2413\n",
      "Epoch 580, 100.0%, avg_loss = 1.3974\n",
      "Validation Loss: 1.3951\n",
      "Epoch 581, 100.0%, avg_loss = 1.3334\n",
      "Epoch 582, 100.0%, avg_loss = 1.2161\n",
      "Epoch 583, 100.0%, avg_loss = 1.2863\n",
      "Epoch 584, 100.0%, avg_loss = 1.3443\n",
      "Epoch 585, 100.0%, avg_loss = 1.2903\n",
      "Validation Loss: 1.3650\n",
      "Epoch 586, 100.0%, avg_loss = 1.2776\n",
      "Epoch 587, 100.0%, avg_loss = 1.2832\n",
      "Epoch 588, 100.0%, avg_loss = 1.2944\n",
      "Epoch 589, 100.0%, avg_loss = 1.2874\n",
      "Epoch 590, 100.0%, avg_loss = 1.2777\n",
      "Validation Loss: 1.4113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591, 100.0%, avg_loss = 1.2875\n",
      "Epoch 592, 100.0%, avg_loss = 1.2661\n",
      "Epoch 593, 100.0%, avg_loss = 1.2996\n",
      "Epoch 594, 100.0%, avg_loss = 1.2833\n",
      "Epoch 595, 100.0%, avg_loss = 1.2960\n",
      "Validation Loss: 1.3589\n",
      "Epoch 596, 100.0%, avg_loss = 1.3104\n",
      "Epoch 597, 100.0%, avg_loss = 1.2924\n",
      "Epoch 598, 100.0%, avg_loss = 1.3050\n",
      "Epoch 599, 100.0%, avg_loss = 1.3361\n",
      "Epoch 600, 100.0%, avg_loss = 1.3043\n",
      "Validation Loss: 1.4089\n",
      "Epoch 601, 100.0%, avg_loss = 1.2698\n",
      "Epoch 602, 100.0%, avg_loss = 1.2801\n",
      "Epoch 603, 100.0%, avg_loss = 1.3178\n",
      "Epoch 604, 100.0%, avg_loss = 1.2584\n",
      "Epoch 605, 100.0%, avg_loss = 1.3624\n",
      "Validation Loss: 1.3398\n",
      "Epoch 606, 100.0%, avg_loss = 1.2950\n",
      "Epoch 607, 100.0%, avg_loss = 1.2881\n",
      "Epoch 608, 100.0%, avg_loss = 1.3246\n",
      "Epoch 609, 100.0%, avg_loss = 1.2869\n",
      "Epoch 610, 100.0%, avg_loss = 1.3117\n",
      "Validation Loss: 1.3802\n",
      "Epoch 611, 100.0%, avg_loss = 1.1984\n",
      "Epoch 612, 100.0%, avg_loss = 1.2866\n",
      "Epoch 613, 100.0%, avg_loss = 1.3049\n",
      "Epoch 614, 100.0%, avg_loss = 1.2946\n",
      "Epoch 615, 100.0%, avg_loss = 1.2875\n",
      "Validation Loss: 1.3831\n",
      "Epoch 616, 100.0%, avg_loss = 1.3620\n",
      "Epoch 617, 100.0%, avg_loss = 1.2756\n",
      "Epoch 618, 100.0%, avg_loss = 1.2723\n",
      "Epoch 619, 100.0%, avg_loss = 1.2483\n",
      "Epoch 620, 100.0%, avg_loss = 1.2801\n",
      "Validation Loss: 1.4004\n",
      "Epoch 621, 100.0%, avg_loss = 1.2349\n",
      "Epoch 622, 100.0%, avg_loss = 1.3042\n",
      "Epoch 623, 100.0%, avg_loss = 1.2917\n",
      "Epoch 624, 100.0%, avg_loss = 1.2267\n",
      "Epoch 625, 100.0%, avg_loss = 1.2800\n",
      "Validation Loss: 1.4086\n",
      "Epoch 626, 100.0%, avg_loss = 1.2635\n",
      "Epoch 627, 100.0%, avg_loss = 1.2655\n",
      "Epoch 628, 100.0%, avg_loss = 1.3162\n",
      "Epoch 629, 100.0%, avg_loss = 1.3335\n",
      "Epoch 630, 100.0%, avg_loss = 1.3325\n",
      "Validation Loss: 1.3101\n",
      "Epoch 631, 100.0%, avg_loss = 1.2720\n",
      "Epoch 632, 100.0%, avg_loss = 1.3166\n",
      "Epoch 633, 100.0%, avg_loss = 1.3177\n",
      "Epoch 634, 100.0%, avg_loss = 1.2934\n",
      "Epoch 635, 100.0%, avg_loss = 1.3305\n",
      "Validation Loss: 1.3401\n",
      "Epoch 636, 100.0%, avg_loss = 1.2602\n",
      "Epoch 637, 100.0%, avg_loss = 1.2817\n",
      "Epoch 638, 100.0%, avg_loss = 1.2216\n",
      "Epoch 639, 100.0%, avg_loss = 1.2871\n",
      "Epoch 640, 100.0%, avg_loss = 1.2512\n",
      "Validation Loss: 1.4391\n",
      "Epoch 641, 100.0%, avg_loss = 1.2907\n",
      "Epoch 642, 100.0%, avg_loss = 1.2496\n",
      "Epoch 643, 100.0%, avg_loss = 1.2731\n",
      "Epoch 644, 100.0%, avg_loss = 1.2607\n",
      "Epoch 645, 100.0%, avg_loss = 1.2513\n",
      "Validation Loss: 1.3367\n",
      "Epoch 646, 100.0%, avg_loss = 1.2725\n",
      "Epoch 647, 100.0%, avg_loss = 1.2498\n",
      "Epoch 648, 100.0%, avg_loss = 1.3102\n",
      "Epoch 649, 100.0%, avg_loss = 1.2613\n",
      "Epoch 650, 100.0%, avg_loss = 1.3027\n",
      "Validation Loss: 1.3626\n",
      "Epoch 651, 100.0%, avg_loss = 1.2602\n",
      "Epoch 652, 100.0%, avg_loss = 1.3155\n",
      "Epoch 653, 100.0%, avg_loss = 1.3302\n",
      "Epoch 654, 100.0%, avg_loss = 1.2533\n",
      "Epoch 655, 100.0%, avg_loss = 1.2701\n",
      "Validation Loss: 1.3707\n",
      "Epoch 656, 100.0%, avg_loss = 1.2501\n",
      "Epoch 657, 100.0%, avg_loss = 1.3167\n",
      "Epoch 658, 100.0%, avg_loss = 1.2294\n",
      "Epoch 659, 100.0%, avg_loss = 1.2640\n",
      "Epoch 660, 100.0%, avg_loss = 1.2739\n",
      "Validation Loss: 1.3454\n",
      "Epoch 661, 100.0%, avg_loss = 1.3304\n",
      "Epoch 662, 100.0%, avg_loss = 1.2737\n",
      "Epoch 663, 100.0%, avg_loss = 1.3247\n",
      "Epoch 664, 100.0%, avg_loss = 1.3067\n",
      "Epoch 665, 100.0%, avg_loss = 1.2904\n",
      "Validation Loss: 1.3421\n",
      "Epoch 666, 100.0%, avg_loss = 1.2668\n",
      "Epoch 667, 100.0%, avg_loss = 1.2786\n",
      "Epoch 668, 100.0%, avg_loss = 1.3242\n",
      "Epoch 669, 100.0%, avg_loss = 1.3483\n",
      "Epoch 670, 100.0%, avg_loss = 1.2241\n",
      "Validation Loss: 1.3350\n",
      "Epoch 671, 100.0%, avg_loss = 1.2977\n",
      "Epoch 672, 100.0%, avg_loss = 1.3372\n",
      "Epoch 673, 100.0%, avg_loss = 1.3351\n",
      "Epoch 674, 100.0%, avg_loss = 1.3095\n",
      "Epoch 675, 100.0%, avg_loss = 1.2642\n",
      "Validation Loss: 1.3740\n",
      "Epoch 676, 100.0%, avg_loss = 1.3199\n",
      "Epoch 677, 100.0%, avg_loss = 1.3304\n",
      "Epoch 678, 100.0%, avg_loss = 1.2570\n",
      "Epoch 679, 100.0%, avg_loss = 1.2586\n",
      "Epoch 680, 100.0%, avg_loss = 1.2609\n",
      "Validation Loss: 1.4292\n",
      "Epoch 681, 100.0%, avg_loss = 1.2551\n",
      "Epoch 682, 100.0%, avg_loss = 1.2426\n",
      "Epoch 683, 100.0%, avg_loss = 1.2776\n",
      "Epoch 684, 100.0%, avg_loss = 1.2956\n",
      "Epoch 685, 100.0%, avg_loss = 1.2587\n",
      "Validation Loss: 1.3523\n",
      "Epoch 686, 100.0%, avg_loss = 1.2728\n",
      "Epoch 687, 100.0%, avg_loss = 1.2683\n",
      "Epoch 688, 100.0%, avg_loss = 1.2671\n",
      "Epoch 689, 100.0%, avg_loss = 1.3183\n",
      "Epoch 690, 100.0%, avg_loss = 1.2974\n",
      "Validation Loss: 1.3720\n",
      "Epoch 691, 100.0%, avg_loss = 1.3350\n",
      "Epoch 692, 100.0%, avg_loss = 1.3052\n",
      "Epoch 693, 100.0%, avg_loss = 1.2436\n",
      "Epoch 694, 100.0%, avg_loss = 1.2887\n",
      "Epoch 695, 100.0%, avg_loss = 1.2349\n",
      "Validation Loss: 1.3835\n",
      "Epoch 696, 100.0%, avg_loss = 1.3105\n",
      "Epoch 697, 100.0%, avg_loss = 1.2677\n",
      "Epoch 698, 100.0%, avg_loss = 1.2634\n",
      "Epoch 699, 100.0%, avg_loss = 1.3144\n",
      "Epoch 700, 100.0%, avg_loss = 1.3331\n",
      "Validation Loss: 1.4099\n",
      "Epoch 701, 100.0%, avg_loss = 1.2833\n",
      "Epoch 702, 100.0%, avg_loss = 1.2596\n",
      "Epoch 703, 100.0%, avg_loss = 1.3365\n",
      "Epoch 704, 100.0%, avg_loss = 1.2810\n",
      "Epoch 705, 100.0%, avg_loss = 1.2968\n",
      "Validation Loss: 1.3627\n",
      "Epoch 706, 100.0%, avg_loss = 1.2364\n",
      "Epoch 707, 100.0%, avg_loss = 1.2673\n",
      "Epoch 708, 100.0%, avg_loss = 1.2800\n",
      "Epoch 709, 100.0%, avg_loss = 1.2176\n",
      "Epoch 710, 100.0%, avg_loss = 1.2885\n",
      "Validation Loss: 1.3842\n",
      "Epoch 711, 100.0%, avg_loss = 1.2539\n",
      "Epoch 712, 100.0%, avg_loss = 1.2766\n",
      "Epoch 713, 100.0%, avg_loss = 1.3182\n",
      "Epoch 714, 100.0%, avg_loss = 1.3168\n",
      "Epoch 715, 100.0%, avg_loss = 1.2924\n",
      "Validation Loss: 1.3129\n",
      "Epoch 716, 100.0%, avg_loss = 1.2603\n",
      "Epoch 717, 100.0%, avg_loss = 1.3399\n",
      "Epoch 718, 100.0%, avg_loss = 1.2823\n",
      "Epoch 719, 100.0%, avg_loss = 1.3226\n",
      "Epoch 720, 100.0%, avg_loss = 1.2575\n",
      "Validation Loss: 1.3832\n",
      "Epoch 721, 100.0%, avg_loss = 1.3162\n",
      "Epoch 722, 100.0%, avg_loss = 1.2437\n",
      "Epoch 723, 100.0%, avg_loss = 1.2575\n",
      "Epoch 724, 100.0%, avg_loss = 1.2504\n",
      "Epoch 725, 100.0%, avg_loss = 1.2683\n",
      "Validation Loss: 1.3322\n",
      "Epoch 726, 100.0%, avg_loss = 1.2628\n",
      "Epoch 727, 100.0%, avg_loss = 1.2969\n",
      "Epoch 728, 100.0%, avg_loss = 1.2292\n",
      "Epoch 729, 100.0%, avg_loss = 1.2128\n",
      "Epoch 730, 100.0%, avg_loss = 1.2454\n",
      "Validation Loss: 1.3690\n",
      "Epoch 731, 100.0%, avg_loss = 1.3003\n",
      "Epoch 732, 100.0%, avg_loss = 1.2465\n",
      "Epoch 733, 100.0%, avg_loss = 1.2462\n",
      "Epoch 734, 100.0%, avg_loss = 1.2476\n",
      "Epoch 735, 100.0%, avg_loss = 1.2989\n",
      "Validation Loss: 1.3946\n",
      "Epoch 736, 100.0%, avg_loss = 1.2629\n",
      "Epoch 737, 100.0%, avg_loss = 1.3056\n",
      "Epoch 738, 100.0%, avg_loss = 1.2661\n",
      "Epoch 739, 100.0%, avg_loss = 1.2851\n",
      "Epoch 740, 100.0%, avg_loss = 1.2625\n",
      "Validation Loss: 1.3779\n",
      "Epoch 741, 100.0%, avg_loss = 1.2694\n",
      "Epoch 742, 100.0%, avg_loss = 1.2888\n",
      "Epoch 743, 100.0%, avg_loss = 1.3008\n",
      "Epoch 744, 100.0%, avg_loss = 1.3132\n",
      "Epoch 745, 100.0%, avg_loss = 1.2740\n",
      "Validation Loss: 1.3977\n",
      "Epoch 746, 100.0%, avg_loss = 1.3134\n",
      "Epoch 747, 100.0%, avg_loss = 1.2415\n",
      "Epoch 748, 100.0%, avg_loss = 1.2816\n",
      "Epoch 749, 100.0%, avg_loss = 1.2920\n",
      "Epoch 750, 100.0%, avg_loss = 1.2664\n",
      "Validation Loss: 1.3825\n",
      "Epoch 751, 100.0%, avg_loss = 1.2862\n",
      "Epoch 752, 100.0%, avg_loss = 1.2311\n",
      "Epoch 753, 100.0%, avg_loss = 1.2727\n",
      "Epoch 754, 100.0%, avg_loss = 1.3170\n",
      "Epoch 755, 100.0%, avg_loss = 1.3086\n",
      "Validation Loss: 1.3654\n",
      "Epoch 756, 100.0%, avg_loss = 1.2418\n",
      "Epoch 757, 100.0%, avg_loss = 1.2624\n",
      "Epoch 758, 100.0%, avg_loss = 1.2406\n",
      "Epoch 759, 100.0%, avg_loss = 1.2510\n",
      "Epoch 760, 100.0%, avg_loss = 1.3388\n",
      "Validation Loss: 1.3893\n",
      "Epoch 761, 100.0%, avg_loss = 1.2120\n",
      "Epoch 762, 100.0%, avg_loss = 1.2656\n",
      "Epoch 763, 100.0%, avg_loss = 1.2677\n",
      "Epoch 764, 100.0%, avg_loss = 1.2341\n",
      "Epoch 765, 100.0%, avg_loss = 1.2665\n",
      "Validation Loss: 1.3746\n",
      "Epoch 766, 100.0%, avg_loss = 1.2724\n",
      "Epoch 767, 100.0%, avg_loss = 1.2618\n",
      "Epoch 768, 100.0%, avg_loss = 1.2362\n",
      "Epoch 769, 100.0%, avg_loss = 1.2755\n",
      "Epoch 770, 100.0%, avg_loss = 1.3159\n",
      "Validation Loss: 1.3697\n",
      "Epoch 771, 100.0%, avg_loss = 1.3238\n",
      "Epoch 772, 100.0%, avg_loss = 1.3086\n",
      "Epoch 773, 100.0%, avg_loss = 1.2908\n",
      "Epoch 774, 100.0%, avg_loss = 1.2113\n",
      "Epoch 775, 100.0%, avg_loss = 1.2892\n",
      "Validation Loss: 1.3812\n",
      "Epoch 776, 100.0%, avg_loss = 1.2850\n",
      "Epoch 777, 100.0%, avg_loss = 1.3031\n",
      "Epoch 778, 100.0%, avg_loss = 1.3094\n",
      "Epoch 779, 100.0%, avg_loss = 1.2421\n",
      "Epoch 780, 100.0%, avg_loss = 1.3005\n",
      "Validation Loss: 1.3499\n",
      "Epoch 781, 100.0%, avg_loss = 1.3506\n",
      "Epoch 782, 100.0%, avg_loss = 1.3232\n",
      "Epoch 783, 100.0%, avg_loss = 1.2832\n",
      "Epoch 784, 100.0%, avg_loss = 1.2734\n",
      "Epoch 785, 100.0%, avg_loss = 1.2803\n",
      "Validation Loss: 1.3489\n",
      "Epoch 786, 100.0%, avg_loss = 1.2783\n",
      "Epoch 787, 100.0%, avg_loss = 1.2228\n",
      "Epoch 788, 100.0%, avg_loss = 1.2932\n",
      "Epoch 789, 100.0%, avg_loss = 1.3120\n",
      "Epoch 790, 100.0%, avg_loss = 1.2890\n",
      "Validation Loss: 1.3329\n",
      "Epoch 791, 100.0%, avg_loss = 1.2496\n",
      "Epoch 792, 100.0%, avg_loss = 1.2462\n",
      "Epoch 793, 100.0%, avg_loss = 1.2427\n",
      "Epoch 794, 100.0%, avg_loss = 1.2823\n",
      "Epoch 795, 100.0%, avg_loss = 1.2420\n",
      "Validation Loss: 1.3969\n",
      "Epoch 796, 100.0%, avg_loss = 1.2479\n",
      "Epoch 797, 100.0%, avg_loss = 1.3117\n",
      "Epoch 798, 100.0%, avg_loss = 1.2806\n",
      "Epoch 799, 100.0%, avg_loss = 1.2992\n",
      "Epoch 800, 100.0%, avg_loss = 1.2593\n",
      "Validation Loss: 1.3841\n",
      "Epoch 801, 100.0%, avg_loss = 1.2705\n",
      "Epoch 802, 100.0%, avg_loss = 1.2733\n",
      "Epoch 803, 100.0%, avg_loss = 1.2999\n",
      "Epoch 804, 100.0%, avg_loss = 1.2715\n",
      "Epoch 805, 100.0%, avg_loss = 1.2702\n",
      "Validation Loss: 1.3344\n",
      "Epoch 806, 100.0%, avg_loss = 1.2621\n",
      "Epoch 807, 100.0%, avg_loss = 1.2745\n",
      "Epoch 808, 100.0%, avg_loss = 1.2618\n",
      "Epoch 809, 100.0%, avg_loss = 1.3032\n",
      "Epoch 810, 100.0%, avg_loss = 1.2357\n",
      "Validation Loss: 1.3182\n",
      "Epoch 811, 100.0%, avg_loss = 1.2216\n",
      "Epoch 812, 100.0%, avg_loss = 1.2532\n",
      "Epoch 813, 100.0%, avg_loss = 1.1947\n",
      "Epoch 814, 100.0%, avg_loss = 1.2745\n",
      "Epoch 815, 100.0%, avg_loss = 1.2638\n",
      "Validation Loss: 1.3822\n",
      "Epoch 816, 100.0%, avg_loss = 1.2856\n",
      "Epoch 817, 100.0%, avg_loss = 1.2935\n",
      "Epoch 818, 100.0%, avg_loss = 1.2982\n",
      "Epoch 819, 100.0%, avg_loss = 1.2544\n",
      "Epoch 820, 100.0%, avg_loss = 1.2913\n",
      "Validation Loss: 1.3862\n",
      "Epoch 821, 100.0%, avg_loss = 1.2628\n",
      "Epoch 822, 100.0%, avg_loss = 1.3277\n",
      "Epoch 823, 100.0%, avg_loss = 1.3371\n",
      "Epoch 824, 100.0%, avg_loss = 1.3292\n",
      "Epoch 825, 100.0%, avg_loss = 1.1934\n",
      "Validation Loss: 1.3495\n",
      "Epoch 826, 100.0%, avg_loss = 1.2941\n",
      "Epoch 827, 100.0%, avg_loss = 1.2620\n",
      "Epoch 828, 100.0%, avg_loss = 1.2577\n",
      "Epoch 829, 100.0%, avg_loss = 1.2188\n",
      "Epoch 830, 100.0%, avg_loss = 1.2703\n",
      "Validation Loss: 1.4194\n",
      "Epoch 831, 100.0%, avg_loss = 1.2516\n",
      "Epoch 832, 100.0%, avg_loss = 1.3035\n",
      "Epoch 833, 100.0%, avg_loss = 1.2439\n",
      "Epoch 834, 100.0%, avg_loss = 1.2648\n",
      "Epoch 835, 100.0%, avg_loss = 1.2542\n",
      "Validation Loss: 1.3227\n",
      "Epoch 836, 100.0%, avg_loss = 1.2652\n",
      "Epoch 837, 100.0%, avg_loss = 1.2171\n",
      "Epoch 838, 100.0%, avg_loss = 1.2626\n",
      "Epoch 839, 100.0%, avg_loss = 1.2088\n",
      "Epoch 840, 100.0%, avg_loss = 1.2974\n",
      "Validation Loss: 1.3905\n",
      "Epoch 841, 100.0%, avg_loss = 1.3138\n",
      "Epoch 842, 100.0%, avg_loss = 1.3043\n",
      "Epoch 843, 100.0%, avg_loss = 1.3062\n",
      "Epoch 844, 100.0%, avg_loss = 1.2540\n",
      "Epoch 845, 100.0%, avg_loss = 1.3161\n",
      "Validation Loss: 1.3003\n",
      "Epoch 846, 100.0%, avg_loss = 1.2915\n",
      "Epoch 847, 100.0%, avg_loss = 1.2356\n",
      "Epoch 848, 100.0%, avg_loss = 1.2833\n",
      "Epoch 849, 100.0%, avg_loss = 1.3294\n",
      "Epoch 850, 100.0%, avg_loss = 1.2890\n",
      "Validation Loss: 1.3312\n",
      "Epoch 851, 100.0%, avg_loss = 1.2793\n",
      "Epoch 852, 100.0%, avg_loss = 1.2814\n",
      "Epoch 853, 100.0%, avg_loss = 1.2385\n",
      "Epoch 854, 100.0%, avg_loss = 1.2966\n",
      "Epoch 855, 100.0%, avg_loss = 1.2533\n",
      "Validation Loss: 1.3679\n",
      "Epoch 856, 100.0%, avg_loss = 1.2902\n",
      "Epoch 857, 100.0%, avg_loss = 1.2978\n",
      "Epoch 858, 100.0%, avg_loss = 1.2454\n",
      "Epoch 859, 100.0%, avg_loss = 1.2478\n",
      "Epoch 860, 100.0%, avg_loss = 1.2739\n",
      "Validation Loss: 1.3342\n",
      "Epoch 861, 100.0%, avg_loss = 1.2213\n",
      "Epoch 862, 100.0%, avg_loss = 1.3227\n",
      "Epoch 863, 100.0%, avg_loss = 1.2387\n",
      "Epoch 864, 100.0%, avg_loss = 1.2942\n",
      "Epoch 865, 100.0%, avg_loss = 1.2811\n",
      "Validation Loss: 1.3476\n",
      "Epoch 866, 100.0%, avg_loss = 1.2692\n",
      "Epoch 867, 100.0%, avg_loss = 1.2296\n",
      "Epoch 868, 100.0%, avg_loss = 1.2816\n",
      "Epoch 869, 100.0%, avg_loss = 1.2679\n",
      "Epoch 870, 100.0%, avg_loss = 1.3042\n",
      "Validation Loss: 1.3981\n",
      "Epoch 871, 100.0%, avg_loss = 1.2736\n",
      "Epoch 872, 100.0%, avg_loss = 1.2759\n",
      "Epoch 873, 100.0%, avg_loss = 1.2645\n",
      "Epoch 874, 100.0%, avg_loss = 1.2196\n",
      "Epoch 875, 100.0%, avg_loss = 1.2171\n",
      "Validation Loss: 1.3649\n",
      "Epoch 876, 100.0%, avg_loss = 1.2616\n",
      "Epoch 877, 100.0%, avg_loss = 1.3052\n",
      "Epoch 878, 100.0%, avg_loss = 1.2921\n",
      "Epoch 879, 100.0%, avg_loss = 1.2612\n",
      "Epoch 880, 100.0%, avg_loss = 1.2573\n",
      "Validation Loss: 1.3354\n",
      "Epoch 881, 100.0%, avg_loss = 1.3065\n",
      "Epoch 882, 100.0%, avg_loss = 1.3163\n",
      "Epoch 883, 100.0%, avg_loss = 1.2344\n",
      "Epoch 884, 100.0%, avg_loss = 1.3021\n",
      "Epoch 885, 100.0%, avg_loss = 1.2766\n",
      "Validation Loss: 1.3543\n",
      "Epoch 886, 100.0%, avg_loss = 1.2307\n",
      "Epoch 887, 100.0%, avg_loss = 1.2311\n",
      "Epoch 888, 100.0%, avg_loss = 1.2493\n",
      "Epoch 889, 100.0%, avg_loss = 1.2585\n",
      "Epoch 890, 100.0%, avg_loss = 1.2532\n",
      "Validation Loss: 1.4009\n",
      "Epoch 891, 100.0%, avg_loss = 1.3278\n",
      "Epoch 892, 100.0%, avg_loss = 1.2561\n",
      "Epoch 893, 100.0%, avg_loss = 1.2880\n",
      "Epoch 894, 100.0%, avg_loss = 1.2340\n",
      "Epoch 895, 100.0%, avg_loss = 1.2576\n",
      "Validation Loss: 1.3776\n",
      "Epoch 896, 100.0%, avg_loss = 1.2418\n",
      "Epoch 897, 100.0%, avg_loss = 1.3291\n",
      "Epoch 898, 100.0%, avg_loss = 1.3290\n",
      "Epoch 899, 100.0%, avg_loss = 1.2400\n",
      "Epoch 900, 100.0%, avg_loss = 1.2807\n",
      "Validation Loss: 1.3760\n",
      "Epoch 901, 100.0%, avg_loss = 1.2161\n",
      "Epoch 902, 100.0%, avg_loss = 1.3071\n",
      "Epoch 903, 100.0%, avg_loss = 1.2578\n",
      "Epoch 904, 100.0%, avg_loss = 1.2295\n",
      "Epoch 905, 100.0%, avg_loss = 1.2552\n",
      "Validation Loss: 1.3176\n",
      "Epoch 906, 100.0%, avg_loss = 1.2870\n",
      "Epoch 907, 100.0%, avg_loss = 1.1872\n",
      "Epoch 908, 100.0%, avg_loss = 1.2472\n",
      "Epoch 909, 100.0%, avg_loss = 1.2698\n",
      "Epoch 910, 100.0%, avg_loss = 1.2063\n",
      "Validation Loss: 1.3786\n",
      "Epoch 911, 100.0%, avg_loss = 1.2368\n",
      "Epoch 912, 100.0%, avg_loss = 1.2201\n",
      "Epoch 913, 100.0%, avg_loss = 1.2229\n",
      "Epoch 914, 100.0%, avg_loss = 1.2910\n",
      "Epoch 915, 100.0%, avg_loss = 1.1921\n",
      "Validation Loss: 1.3037\n",
      "Epoch 916, 100.0%, avg_loss = 1.2140\n",
      "Epoch 917, 100.0%, avg_loss = 1.2796\n",
      "Epoch 918, 100.0%, avg_loss = 1.3175\n",
      "Epoch 919, 100.0%, avg_loss = 1.2572\n",
      "Epoch 920, 100.0%, avg_loss = 1.2962\n",
      "Validation Loss: 1.3396\n",
      "Epoch 921, 100.0%, avg_loss = 1.2508\n",
      "Epoch 922, 100.0%, avg_loss = 1.2454\n",
      "Epoch 923, 100.0%, avg_loss = 1.2662\n",
      "Epoch 924, 100.0%, avg_loss = 1.2602\n",
      "Epoch 925, 100.0%, avg_loss = 1.2801\n",
      "Validation Loss: 1.3186\n",
      "Epoch 926, 100.0%, avg_loss = 1.2833\n",
      "Epoch 927, 100.0%, avg_loss = 1.2623\n",
      "Epoch 928, 100.0%, avg_loss = 1.3409\n",
      "Epoch 929, 100.0%, avg_loss = 1.2799\n",
      "Epoch 930, 100.0%, avg_loss = 1.2942\n",
      "Validation Loss: 1.3637\n",
      "Epoch 931, 100.0%, avg_loss = 1.2480\n",
      "Epoch 932, 100.0%, avg_loss = 1.2175\n",
      "Epoch 933, 100.0%, avg_loss = 1.2943\n",
      "Epoch 934, 100.0%, avg_loss = 1.2351\n",
      "Epoch 935, 100.0%, avg_loss = 1.2767\n",
      "Validation Loss: 1.3447\n",
      "Epoch 936, 100.0%, avg_loss = 1.2235\n",
      "Epoch 937, 100.0%, avg_loss = 1.1841\n",
      "Epoch 938, 100.0%, avg_loss = 1.2255\n",
      "Epoch 939, 100.0%, avg_loss = 1.2274\n",
      "Epoch 940, 100.0%, avg_loss = 1.2205\n",
      "Validation Loss: 1.3806\n",
      "Epoch 941, 100.0%, avg_loss = 1.2601\n",
      "Epoch 942, 100.0%, avg_loss = 1.1995\n",
      "Epoch 943, 100.0%, avg_loss = 1.2821\n",
      "Epoch 944, 100.0%, avg_loss = 1.2720\n",
      "Epoch 945, 100.0%, avg_loss = 1.2295\n",
      "Validation Loss: 1.3518\n",
      "Epoch 946, 100.0%, avg_loss = 1.2583\n",
      "Epoch 947, 100.0%, avg_loss = 1.2998\n",
      "Epoch 948, 100.0%, avg_loss = 1.2369\n",
      "Epoch 949, 100.0%, avg_loss = 1.2473\n",
      "Epoch 950, 100.0%, avg_loss = 1.2938\n",
      "Validation Loss: 1.3466\n",
      "Epoch 951, 100.0%, avg_loss = 1.2379\n",
      "Epoch 952, 100.0%, avg_loss = 1.2368\n",
      "Epoch 953, 100.0%, avg_loss = 1.2387\n",
      "Epoch 954, 100.0%, avg_loss = 1.2558\n",
      "Epoch 955, 100.0%, avg_loss = 1.2691\n",
      "Validation Loss: 1.3332\n",
      "Epoch 956, 100.0%, avg_loss = 1.2421\n",
      "Epoch 957, 100.0%, avg_loss = 1.2924\n",
      "Epoch 958, 100.0%, avg_loss = 1.2988\n",
      "Epoch 959, 100.0%, avg_loss = 1.3154\n",
      "Epoch 960, 100.0%, avg_loss = 1.2239\n",
      "Validation Loss: 1.4074\n",
      "Epoch 961, 100.0%, avg_loss = 1.2741\n",
      "Epoch 962, 100.0%, avg_loss = 1.2293\n",
      "Epoch 963, 100.0%, avg_loss = 1.2627\n",
      "Epoch 964, 100.0%, avg_loss = 1.2810\n",
      "Epoch 965, 100.0%, avg_loss = 1.2601\n",
      "Validation Loss: 1.4153\n",
      "Epoch 966, 100.0%, avg_loss = 1.3387\n",
      "Epoch 967, 100.0%, avg_loss = 1.2748\n",
      "Epoch 968, 100.0%, avg_loss = 1.2775\n",
      "Epoch 969, 100.0%, avg_loss = 1.2536\n",
      "Epoch 970, 100.0%, avg_loss = 1.2876\n",
      "Validation Loss: 1.3342\n",
      "Epoch 971, 100.0%, avg_loss = 1.2450\n",
      "Epoch 972, 100.0%, avg_loss = 1.2492\n",
      "Epoch 973, 100.0%, avg_loss = 1.2711\n",
      "Epoch 974, 100.0%, avg_loss = 1.2349\n",
      "Epoch 975, 100.0%, avg_loss = 1.2340\n",
      "Validation Loss: 1.3540\n",
      "Epoch 976, 100.0%, avg_loss = 1.2253\n",
      "Epoch 977, 100.0%, avg_loss = 1.2464\n",
      "Epoch 978, 100.0%, avg_loss = 1.2411\n",
      "Epoch 979, 100.0%, avg_loss = 1.2734\n",
      "Epoch 980, 100.0%, avg_loss = 1.2871\n",
      "Validation Loss: 1.3285\n",
      "Epoch 981, 100.0%, avg_loss = 1.2395\n",
      "Epoch 982, 100.0%, avg_loss = 1.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983, 100.0%, avg_loss = 1.1876\n",
      "Epoch 984, 100.0%, avg_loss = 1.2671\n",
      "Epoch 985, 100.0%, avg_loss = 1.1893\n",
      "Validation Loss: 1.3720\n",
      "Epoch 986, 100.0%, avg_loss = 1.2440\n",
      "Epoch 987, 100.0%, avg_loss = 1.2440\n",
      "Epoch 988, 100.0%, avg_loss = 1.2135\n",
      "Epoch 989, 100.0%, avg_loss = 1.2088\n",
      "Epoch 990, 100.0%, avg_loss = 1.1938\n",
      "Validation Loss: 1.3775\n",
      "Epoch 991, 100.0%, avg_loss = 1.2609\n",
      "Epoch 992, 100.0%, avg_loss = 1.2485\n",
      "Epoch 993, 100.0%, avg_loss = 1.2475\n",
      "Epoch 994, 100.0%, avg_loss = 1.2055\n",
      "Epoch 995, 100.0%, avg_loss = 1.2045\n",
      "Validation Loss: 1.4022\n",
      "Epoch 996, 100.0%, avg_loss = 1.2897\n",
      "Epoch 997, 100.0%, avg_loss = 1.2271\n",
      "Epoch 998, 100.0%, avg_loss = 1.2637\n",
      "Epoch 999, 100.0%, avg_loss = 1.2980\n",
      "Epoch 1000, 100.0%, avg_loss = 1.2180\n",
      "Validation Loss: 1.3720\n",
      "Epoch 1001, 100.0%, avg_loss = 1.2401\n",
      "Epoch 1002, 100.0%, avg_loss = 1.2503\n",
      "Epoch 1003, 100.0%, avg_loss = 1.2551\n",
      "Epoch 1004, 100.0%, avg_loss = 1.2789\n",
      "Epoch 1005, 100.0%, avg_loss = 1.2428\n",
      "Validation Loss: 1.3565\n",
      "Epoch 1006, 100.0%, avg_loss = 1.2429\n",
      "Epoch 1007, 100.0%, avg_loss = 1.2451\n",
      "Epoch 1008, 100.0%, avg_loss = 1.2476\n",
      "Epoch 1009, 100.0%, avg_loss = 1.1787\n",
      "Epoch 1010, 100.0%, avg_loss = 1.2128\n",
      "Validation Loss: 1.3630\n",
      "Epoch 1011, 100.0%, avg_loss = 1.2385\n",
      "Epoch 1012, 100.0%, avg_loss = 1.2073\n",
      "Epoch 1013, 100.0%, avg_loss = 1.1919\n",
      "Epoch 1014, 100.0%, avg_loss = 1.2293\n",
      "Epoch 1015, 100.0%, avg_loss = 1.2279\n",
      "Validation Loss: 1.3751\n",
      "Epoch 1016, 100.0%, avg_loss = 1.2491\n",
      "Epoch 1017, 100.0%, avg_loss = 1.2014\n",
      "Epoch 1018, 100.0%, avg_loss = 1.2387\n",
      "Epoch 1019, 100.0%, avg_loss = 1.2707\n",
      "Epoch 1020, 100.0%, avg_loss = 1.2391\n",
      "Validation Loss: 1.3283\n",
      "Epoch 1021, 100.0%, avg_loss = 1.2377\n",
      "Epoch 1022, 100.0%, avg_loss = 1.2807\n",
      "Epoch 1023, 100.0%, avg_loss = 1.2727\n",
      "Epoch 1024, 100.0%, avg_loss = 1.2051\n",
      "Epoch 1025, 100.0%, avg_loss = 1.3042\n",
      "Validation Loss: 1.3789\n",
      "Epoch 1026, 100.0%, avg_loss = 1.2662\n",
      "Epoch 1027, 100.0%, avg_loss = 1.2391\n",
      "Epoch 1028, 100.0%, avg_loss = 1.2805\n",
      "Epoch 1029, 100.0%, avg_loss = 1.2329\n",
      "Epoch 1030, 100.0%, avg_loss = 1.2473\n",
      "Validation Loss: 1.3140\n",
      "Epoch 1031, 100.0%, avg_loss = 1.1881\n",
      "Epoch 1032, 100.0%, avg_loss = 1.2137\n",
      "Epoch 1033, 100.0%, avg_loss = 1.2346\n",
      "Epoch 1034, 100.0%, avg_loss = 1.2290\n",
      "Epoch 1035, 100.0%, avg_loss = 1.2299\n",
      "Validation Loss: 1.3597\n",
      "Epoch 1036, 100.0%, avg_loss = 1.2518\n",
      "Epoch 1037, 100.0%, avg_loss = 1.2522\n",
      "Epoch 1038, 100.0%, avg_loss = 1.2346\n",
      "Epoch 1039, 100.0%, avg_loss = 1.2507\n",
      "Epoch 1040, 100.0%, avg_loss = 1.1818\n",
      "Validation Loss: 1.3625\n",
      "Epoch 1041, 100.0%, avg_loss = 1.2223\n",
      "Epoch 1042, 100.0%, avg_loss = 1.2414\n",
      "Epoch 1043, 100.0%, avg_loss = 1.2915\n",
      "Epoch 1044, 100.0%, avg_loss = 1.1898\n",
      "Epoch 1045, 100.0%, avg_loss = 1.2599\n",
      "Validation Loss: 1.3242\n",
      "Epoch 1046, 100.0%, avg_loss = 1.2887\n",
      "Epoch 1047, 100.0%, avg_loss = 1.2235\n",
      "Epoch 1048, 100.0%, avg_loss = 1.2769\n",
      "Epoch 1049, 100.0%, avg_loss = 1.1840\n",
      "Epoch 1050, 100.0%, avg_loss = 1.1712\n",
      "Validation Loss: 1.2892\n",
      "Epoch 1051, 100.0%, avg_loss = 1.2402\n",
      "Epoch 1052, 100.0%, avg_loss = 1.2018\n",
      "Epoch 1053, 100.0%, avg_loss = 1.1956\n",
      "Epoch 1054, 100.0%, avg_loss = 1.2528\n",
      "Epoch 1055, 100.0%, avg_loss = 1.2581\n",
      "Validation Loss: 1.4002\n",
      "Epoch 1056, 100.0%, avg_loss = 1.2353\n",
      "Epoch 1057, 100.0%, avg_loss = 1.2483\n",
      "Epoch 1058, 100.0%, avg_loss = 1.2914\n",
      "Epoch 1059, 100.0%, avg_loss = 1.2480\n",
      "Epoch 1060, 100.0%, avg_loss = 1.2129\n",
      "Validation Loss: 1.3186\n",
      "Epoch 1061, 100.0%, avg_loss = 1.2549\n",
      "Epoch 1062, 100.0%, avg_loss = 1.2571\n",
      "Epoch 1063, 100.0%, avg_loss = 1.2553\n",
      "Epoch 1064, 100.0%, avg_loss = 1.2276\n",
      "Epoch 1065, 100.0%, avg_loss = 1.2818\n",
      "Validation Loss: 1.3388\n",
      "Epoch 1066, 100.0%, avg_loss = 1.2493\n",
      "Epoch 1067, 100.0%, avg_loss = 1.2178\n",
      "Epoch 1068, 100.0%, avg_loss = 1.2181\n",
      "Epoch 1069, 100.0%, avg_loss = 1.2492\n",
      "Epoch 1070, 100.0%, avg_loss = 1.2406\n",
      "Validation Loss: 1.3362\n",
      "Epoch 1071, 100.0%, avg_loss = 1.2076\n",
      "Epoch 1072, 100.0%, avg_loss = 1.2193\n",
      "Epoch 1073, 100.0%, avg_loss = 1.2548\n",
      "Epoch 1074, 100.0%, avg_loss = 1.2137\n",
      "Epoch 1075, 100.0%, avg_loss = 1.2427\n",
      "Validation Loss: 1.3125\n",
      "Epoch 1076, 100.0%, avg_loss = 1.1899\n",
      "Epoch 1077, 100.0%, avg_loss = 1.2264\n",
      "Epoch 1078, 100.0%, avg_loss = 1.1695\n",
      "Epoch 1079, 100.0%, avg_loss = 1.2315\n",
      "Epoch 1080, 100.0%, avg_loss = 1.2253\n",
      "Validation Loss: 1.3104\n",
      "Epoch 1081, 100.0%, avg_loss = 1.2609\n",
      "Epoch 1082, 100.0%, avg_loss = 1.1814\n",
      "Epoch 1083, 100.0%, avg_loss = 1.2279\n",
      "Epoch 1084, 100.0%, avg_loss = 1.1880\n",
      "Epoch 1085, 100.0%, avg_loss = 1.2508\n",
      "Validation Loss: 1.3858\n",
      "Epoch 1086, 100.0%, avg_loss = 1.2107\n",
      "Epoch 1087, 100.0%, avg_loss = 1.2348\n",
      "Epoch 1088, 100.0%, avg_loss = 1.1616\n",
      "Epoch 1089, 100.0%, avg_loss = 1.2652\n",
      "Epoch 1090, 100.0%, avg_loss = 1.2692\n",
      "Validation Loss: 1.3186\n",
      "Epoch 1091, 100.0%, avg_loss = 1.2419\n",
      "Epoch 1092, 100.0%, avg_loss = 1.1989\n",
      "Epoch 1093, 100.0%, avg_loss = 1.2678\n",
      "Epoch 1094, 100.0%, avg_loss = 1.2259\n",
      "Epoch 1095, 100.0%, avg_loss = 1.2640\n",
      "Validation Loss: 1.2903\n",
      "Epoch 1096, 100.0%, avg_loss = 1.3144\n",
      "Epoch 1097, 100.0%, avg_loss = 1.2683\n",
      "Epoch 1098, 100.0%, avg_loss = 1.1987\n",
      "Epoch 1099, 100.0%, avg_loss = 1.1911\n",
      "Epoch 1100, 100.0%, avg_loss = 1.2979\n",
      "Validation Loss: 1.2915\n",
      "Epoch 1101, 100.0%, avg_loss = 1.1966\n",
      "Epoch 1102, 100.0%, avg_loss = 1.2411\n",
      "Epoch 1103, 100.0%, avg_loss = 1.2617\n",
      "Epoch 1104, 100.0%, avg_loss = 1.2119\n",
      "Epoch 1105, 100.0%, avg_loss = 1.2587\n",
      "Validation Loss: 1.3339\n",
      "Epoch 1106, 100.0%, avg_loss = 1.2370\n",
      "Epoch 1107, 100.0%, avg_loss = 1.3067\n",
      "Epoch 1108, 100.0%, avg_loss = 1.1845\n",
      "Epoch 1109, 100.0%, avg_loss = 1.2241\n",
      "Epoch 1110, 100.0%, avg_loss = 1.2876\n",
      "Validation Loss: 1.3175\n",
      "Epoch 1111, 100.0%, avg_loss = 1.2448\n",
      "Epoch 1112, 100.0%, avg_loss = 1.2160\n",
      "Epoch 1113, 100.0%, avg_loss = 1.1819\n",
      "Epoch 1114, 100.0%, avg_loss = 1.2201\n",
      "Epoch 1115, 100.0%, avg_loss = 1.2434\n",
      "Validation Loss: 1.3524\n",
      "Epoch 1116, 100.0%, avg_loss = 1.2180\n",
      "Epoch 1117, 100.0%, avg_loss = 1.2335\n",
      "Epoch 1118, 100.0%, avg_loss = 1.2585\n",
      "Epoch 1119, 100.0%, avg_loss = 1.1850\n",
      "Epoch 1120, 100.0%, avg_loss = 1.2403\n",
      "Validation Loss: 1.3223\n",
      "Epoch 1121, 100.0%, avg_loss = 1.1890\n",
      "Epoch 1122, 100.0%, avg_loss = 1.2859\n",
      "Epoch 1123, 100.0%, avg_loss = 1.2042\n",
      "Epoch 1124, 100.0%, avg_loss = 1.2086\n",
      "Epoch 1125, 100.0%, avg_loss = 1.2636\n",
      "Validation Loss: 1.3518\n",
      "Epoch 1126, 100.0%, avg_loss = 1.2268\n",
      "Epoch 1127, 100.0%, avg_loss = 1.2265\n",
      "Epoch 1128, 100.0%, avg_loss = 1.2179\n",
      "Epoch 1129, 100.0%, avg_loss = 1.3102\n",
      "Epoch 1130, 100.0%, avg_loss = 1.1861\n",
      "Validation Loss: 1.3117\n",
      "Epoch 1131, 100.0%, avg_loss = 1.2668\n",
      "Epoch 1132, 100.0%, avg_loss = 1.2010\n",
      "Epoch 1133, 100.0%, avg_loss = 1.2614\n",
      "Epoch 1134, 100.0%, avg_loss = 1.2273\n",
      "Epoch 1135, 100.0%, avg_loss = 1.2457\n",
      "Validation Loss: 1.3530\n",
      "Epoch 1136, 100.0%, avg_loss = 1.2702\n",
      "Epoch 1137, 100.0%, avg_loss = 1.3004\n",
      "Epoch 1138, 100.0%, avg_loss = 1.2951\n",
      "Epoch 1139, 100.0%, avg_loss = 1.1956\n",
      "Epoch 1140, 100.0%, avg_loss = 1.2650\n",
      "Validation Loss: 1.3400\n",
      "Epoch 1141, 100.0%, avg_loss = 1.1882\n",
      "Epoch 1142, 100.0%, avg_loss = 1.2581\n",
      "Epoch 1143, 100.0%, avg_loss = 1.2779\n",
      "Epoch 1144, 100.0%, avg_loss = 1.2269\n",
      "Epoch 1145, 100.0%, avg_loss = 1.2204\n",
      "Validation Loss: 1.2798\n",
      "Epoch 1146, 100.0%, avg_loss = 1.2211\n",
      "Epoch 1147, 100.0%, avg_loss = 1.2417\n",
      "Epoch 1148, 100.0%, avg_loss = 1.2373\n",
      "Epoch 1149, 100.0%, avg_loss = 1.2603\n",
      "Epoch 1150, 100.0%, avg_loss = 1.2347\n",
      "Validation Loss: 1.3309\n",
      "Epoch 1151, 100.0%, avg_loss = 1.2335\n",
      "Epoch 1152, 100.0%, avg_loss = 1.2084\n",
      "Epoch 1153, 100.0%, avg_loss = 1.2367\n",
      "Epoch 1154, 100.0%, avg_loss = 1.2838\n",
      "Epoch 1155, 100.0%, avg_loss = 1.3004\n",
      "Validation Loss: 1.2795\n",
      "Epoch 1156, 100.0%, avg_loss = 1.2439\n",
      "Epoch 1157, 100.0%, avg_loss = 1.2594\n",
      "Epoch 1158, 100.0%, avg_loss = 1.2478\n",
      "Epoch 1159, 100.0%, avg_loss = 1.2226\n",
      "Epoch 1160, 100.0%, avg_loss = 1.1956\n",
      "Validation Loss: 1.3049\n",
      "Epoch 1161, 100.0%, avg_loss = 1.2001\n",
      "Epoch 1162, 100.0%, avg_loss = 1.2732\n",
      "Epoch 1163, 100.0%, avg_loss = 1.1883\n",
      "Epoch 1164, 100.0%, avg_loss = 1.1703\n",
      "Epoch 1165, 100.0%, avg_loss = 1.2056\n",
      "Validation Loss: 1.3036\n",
      "Epoch 1166, 100.0%, avg_loss = 1.2049\n",
      "Epoch 1167, 100.0%, avg_loss = 1.2233\n",
      "Epoch 1168, 100.0%, avg_loss = 1.1664\n",
      "Epoch 1169, 100.0%, avg_loss = 1.2243\n",
      "Epoch 1170, 100.0%, avg_loss = 1.2054\n",
      "Validation Loss: 1.3626\n",
      "Epoch 1171, 100.0%, avg_loss = 1.2187\n",
      "Epoch 1172, 100.0%, avg_loss = 1.2146\n",
      "Epoch 1173, 100.0%, avg_loss = 1.2030\n",
      "Epoch 1174, 100.0%, avg_loss = 1.2408\n",
      "Epoch 1175, 100.0%, avg_loss = 1.2353\n",
      "Validation Loss: 1.3966\n",
      "Epoch 1176, 100.0%, avg_loss = 1.2442\n",
      "Epoch 1177, 100.0%, avg_loss = 1.2676\n",
      "Epoch 1178, 100.0%, avg_loss = 1.1768\n",
      "Epoch 1179, 100.0%, avg_loss = 1.2375\n",
      "Epoch 1180, 100.0%, avg_loss = 1.2215\n",
      "Validation Loss: 1.3391\n",
      "Epoch 1181, 100.0%, avg_loss = 1.2008\n",
      "Epoch 1182, 100.0%, avg_loss = 1.2488\n",
      "Epoch 1183, 100.0%, avg_loss = 1.1974\n",
      "Epoch 1184, 100.0%, avg_loss = 1.2000\n",
      "Epoch 1185, 100.0%, avg_loss = 1.2615\n",
      "Validation Loss: 1.3344\n",
      "Epoch 1186, 100.0%, avg_loss = 1.2058\n",
      "Epoch 1187, 100.0%, avg_loss = 1.2181\n",
      "Epoch 1188, 100.0%, avg_loss = 1.2462\n",
      "Epoch 1189, 100.0%, avg_loss = 1.2071\n",
      "Epoch 1190, 100.0%, avg_loss = 1.1738\n",
      "Validation Loss: 1.3439\n",
      "Epoch 1191, 100.0%, avg_loss = 1.2235\n",
      "Epoch 1192, 100.0%, avg_loss = 1.2477\n",
      "Epoch 1193, 100.0%, avg_loss = 1.2921\n",
      "Epoch 1194, 100.0%, avg_loss = 1.2007\n",
      "Epoch 1195, 100.0%, avg_loss = 1.2444\n",
      "Validation Loss: 1.2799\n",
      "Epoch 1196, 100.0%, avg_loss = 1.2295\n",
      "Epoch 1197, 100.0%, avg_loss = 1.2264\n",
      "Epoch 1198, 100.0%, avg_loss = 1.2233\n",
      "Epoch 1199, 100.0%, avg_loss = 1.1693\n",
      "Epoch 1200, 100.0%, avg_loss = 1.1846\n",
      "Validation Loss: 1.2948\n",
      "Epoch 1201, 100.0%, avg_loss = 1.2367\n",
      "Epoch 1202, 100.0%, avg_loss = 1.2827\n",
      "Epoch 1203, 100.0%, avg_loss = 1.3080\n",
      "Epoch 1204, 100.0%, avg_loss = 1.2266\n",
      "Epoch 1205, 100.0%, avg_loss = 1.2427\n",
      "Validation Loss: 1.3052\n",
      "Epoch 1206, 100.0%, avg_loss = 1.2197\n",
      "Epoch 1207, 100.0%, avg_loss = 1.2284\n",
      "Epoch 1208, 100.0%, avg_loss = 1.2460\n",
      "Epoch 1209, 100.0%, avg_loss = 1.2337\n",
      "Epoch 1210, 100.0%, avg_loss = 1.2535\n",
      "Validation Loss: 1.3418\n",
      "Epoch 1211, 100.0%, avg_loss = 1.1821\n",
      "Epoch 1212, 100.0%, avg_loss = 1.2155\n",
      "Epoch 1213, 100.0%, avg_loss = 1.2266\n",
      "Epoch 1214, 100.0%, avg_loss = 1.2044\n",
      "Epoch 1215, 100.0%, avg_loss = 1.2374\n",
      "Validation Loss: 1.3147\n",
      "Epoch 1216, 100.0%, avg_loss = 1.2440\n",
      "Epoch 1217, 100.0%, avg_loss = 1.3045\n",
      "Epoch 1218, 100.0%, avg_loss = 1.2940\n",
      "Epoch 1219, 100.0%, avg_loss = 1.2235\n",
      "Epoch 1220, 100.0%, avg_loss = 1.2504\n",
      "Validation Loss: 1.3921\n",
      "Epoch 1221, 100.0%, avg_loss = 1.1742\n",
      "Epoch 1222, 100.0%, avg_loss = 1.2409\n",
      "Epoch 1223, 100.0%, avg_loss = 1.2099\n",
      "Epoch 1224, 100.0%, avg_loss = 1.1705\n",
      "Epoch 1225, 100.0%, avg_loss = 1.2177\n",
      "Validation Loss: 1.2702\n",
      "Epoch 1226, 100.0%, avg_loss = 1.2300\n",
      "Epoch 1227, 100.0%, avg_loss = 1.2337\n",
      "Epoch 1228, 100.0%, avg_loss = 1.1825\n",
      "Epoch 1229, 100.0%, avg_loss = 1.2666\n",
      "Epoch 1230, 100.0%, avg_loss = 1.2521\n",
      "Validation Loss: 1.3368\n",
      "Epoch 1231, 100.0%, avg_loss = 1.2716\n",
      "Epoch 1232, 100.0%, avg_loss = 1.2742\n",
      "Epoch 1233, 100.0%, avg_loss = 1.2196\n",
      "Epoch 1234, 100.0%, avg_loss = 1.2147\n",
      "Epoch 1235, 100.0%, avg_loss = 1.2094\n",
      "Validation Loss: 1.3081\n",
      "Epoch 1236, 100.0%, avg_loss = 1.3205\n",
      "Epoch 1237, 100.0%, avg_loss = 1.2373\n",
      "Epoch 1238, 100.0%, avg_loss = 1.2230\n",
      "Epoch 1239, 100.0%, avg_loss = 1.1987\n",
      "Epoch 1240, 100.0%, avg_loss = 1.1728\n",
      "Validation Loss: 1.3553\n",
      "Epoch 1241, 100.0%, avg_loss = 1.2216\n",
      "Epoch 1242, 100.0%, avg_loss = 1.2271\n",
      "Epoch 1243, 100.0%, avg_loss = 1.2468\n",
      "Epoch 1244, 100.0%, avg_loss = 1.2337\n",
      "Epoch 1245, 100.0%, avg_loss = 1.2563\n",
      "Validation Loss: 1.3418\n",
      "Epoch 1246, 100.0%, avg_loss = 1.2725\n",
      "Epoch 1247, 100.0%, avg_loss = 1.1220\n",
      "Epoch 1248, 100.0%, avg_loss = 1.2574\n",
      "Epoch 1249, 100.0%, avg_loss = 1.2209\n",
      "Epoch 1250, 100.0%, avg_loss = 1.1903\n",
      "Validation Loss: 1.3251\n",
      "Epoch 1251, 100.0%, avg_loss = 1.1999\n",
      "Epoch 1252, 100.0%, avg_loss = 1.2301\n",
      "Epoch 1253, 100.0%, avg_loss = 1.2298\n",
      "Epoch 1254, 100.0%, avg_loss = 1.2594\n",
      "Epoch 1255, 100.0%, avg_loss = 1.2147\n",
      "Validation Loss: 1.3051\n",
      "Epoch 1256, 100.0%, avg_loss = 1.2398\n",
      "Epoch 1257, 100.0%, avg_loss = 1.2884\n",
      "Epoch 1258, 100.0%, avg_loss = 1.2727\n",
      "Epoch 1259, 100.0%, avg_loss = 1.1907\n",
      "Epoch 1260, 100.0%, avg_loss = 1.2194\n",
      "Validation Loss: 1.3410\n",
      "Epoch 1261, 100.0%, avg_loss = 1.2489\n",
      "Epoch 1262, 100.0%, avg_loss = 1.1665\n",
      "Epoch 1263, 100.0%, avg_loss = 1.2354\n",
      "Epoch 1264, 100.0%, avg_loss = 1.2406\n",
      "Epoch 1265, 100.0%, avg_loss = 1.2309\n",
      "Validation Loss: 1.3093\n",
      "Epoch 1266, 100.0%, avg_loss = 1.2588\n",
      "Epoch 1267, 100.0%, avg_loss = 1.2413\n",
      "Epoch 1268, 100.0%, avg_loss = 1.2275\n",
      "Epoch 1269, 100.0%, avg_loss = 1.2352\n",
      "Epoch 1270, 100.0%, avg_loss = 1.2239\n",
      "Validation Loss: 1.2948\n",
      "Epoch 1271, 100.0%, avg_loss = 1.2224\n",
      "Epoch 1272, 100.0%, avg_loss = 1.1483\n",
      "Epoch 1273, 100.0%, avg_loss = 1.2329\n",
      "Epoch 1274, 100.0%, avg_loss = 1.2814\n",
      "Epoch 1275, 100.0%, avg_loss = 1.1788\n",
      "Validation Loss: 1.3650\n",
      "Epoch 1276, 100.0%, avg_loss = 1.2536\n",
      "Epoch 1277, 100.0%, avg_loss = 1.2559\n",
      "Epoch 1278, 100.0%, avg_loss = 1.2491\n",
      "Epoch 1279, 100.0%, avg_loss = 1.2238\n",
      "Epoch 1280, 100.0%, avg_loss = 1.1915\n",
      "Validation Loss: 1.3151\n",
      "Epoch 1281, 100.0%, avg_loss = 1.1989\n",
      "Epoch 1282, 100.0%, avg_loss = 1.2401\n",
      "Epoch 1283, 100.0%, avg_loss = 1.2519\n",
      "Epoch 1284, 100.0%, avg_loss = 1.1948\n",
      "Epoch 1285, 100.0%, avg_loss = 1.2342\n",
      "Validation Loss: 1.3250\n",
      "Epoch 1286, 100.0%, avg_loss = 1.2350\n",
      "Epoch 1287, 100.0%, avg_loss = 1.2666\n",
      "Epoch 1288, 100.0%, avg_loss = 1.1952\n",
      "Epoch 1289, 100.0%, avg_loss = 1.2558\n",
      "Epoch 1290, 100.0%, avg_loss = 1.2317\n",
      "Validation Loss: 1.3026\n",
      "Epoch 1291, 100.0%, avg_loss = 1.1956\n",
      "Epoch 1292, 100.0%, avg_loss = 1.2254\n",
      "Epoch 1293, 100.0%, avg_loss = 1.2298\n",
      "Epoch 1294, 100.0%, avg_loss = 1.1924\n",
      "Epoch 1295, 100.0%, avg_loss = 1.2381\n",
      "Validation Loss: 1.3600\n",
      "Epoch 1296, 100.0%, avg_loss = 1.2250\n",
      "Epoch 1297, 100.0%, avg_loss = 1.2546\n",
      "Epoch 1298, 100.0%, avg_loss = 1.2599\n",
      "Epoch 1299, 100.0%, avg_loss = 1.2104\n",
      "Epoch 1300, 100.0%, avg_loss = 1.2043\n",
      "Validation Loss: 1.3303\n",
      "Epoch 1301, 100.0%, avg_loss = 1.2129\n",
      "Epoch 1302, 100.0%, avg_loss = 1.2693\n",
      "Epoch 1303, 100.0%, avg_loss = 1.2409\n",
      "Epoch 1304, 100.0%, avg_loss = 1.2903\n",
      "Epoch 1305, 100.0%, avg_loss = 1.1892\n",
      "Validation Loss: 1.2884\n",
      "Epoch 1306, 100.0%, avg_loss = 1.2014\n",
      "Epoch 1307, 100.0%, avg_loss = 1.2331\n",
      "Epoch 1308, 100.0%, avg_loss = 1.1984\n",
      "Epoch 1309, 100.0%, avg_loss = 1.2085\n",
      "Epoch 1310, 100.0%, avg_loss = 1.1384\n",
      "Validation Loss: 1.3315\n",
      "Epoch 1311, 100.0%, avg_loss = 1.2228\n",
      "Epoch 1312, 100.0%, avg_loss = 1.2424\n",
      "Epoch 1313, 100.0%, avg_loss = 1.1579\n",
      "Epoch 1314, 100.0%, avg_loss = 1.2202\n",
      "Epoch 1315, 100.0%, avg_loss = 1.2313\n",
      "Validation Loss: 1.3384\n",
      "Epoch 1316, 100.0%, avg_loss = 1.2260\n",
      "Epoch 1317, 100.0%, avg_loss = 1.2192\n",
      "Epoch 1318, 100.0%, avg_loss = 1.2359\n",
      "Epoch 1319, 100.0%, avg_loss = 1.1857\n",
      "Epoch 1320, 100.0%, avg_loss = 1.2766\n",
      "Validation Loss: 1.3351\n",
      "Epoch 1321, 100.0%, avg_loss = 1.2379\n",
      "Epoch 1322, 100.0%, avg_loss = 1.1824\n",
      "Epoch 1323, 100.0%, avg_loss = 1.2522\n",
      "Epoch 1324, 100.0%, avg_loss = 1.2324\n",
      "Epoch 1325, 100.0%, avg_loss = 1.1852\n",
      "Validation Loss: 1.3238\n",
      "Epoch 1326, 100.0%, avg_loss = 1.2423\n",
      "Epoch 1327, 100.0%, avg_loss = 1.2553\n",
      "Epoch 1328, 100.0%, avg_loss = 1.1974\n",
      "Epoch 1329, 100.0%, avg_loss = 1.2583\n",
      "Epoch 1330, 100.0%, avg_loss = 1.2265\n",
      "Validation Loss: 1.3639\n",
      "Epoch 1331, 100.0%, avg_loss = 1.2291\n",
      "Epoch 1332, 100.0%, avg_loss = 1.2746\n",
      "Epoch 1333, 100.0%, avg_loss = 1.2459\n",
      "Epoch 1334, 100.0%, avg_loss = 1.2198\n",
      "Epoch 1335, 100.0%, avg_loss = 1.2320\n",
      "Validation Loss: 1.2600\n",
      "Epoch 1336, 100.0%, avg_loss = 1.2280\n",
      "Epoch 1337, 100.0%, avg_loss = 1.2482\n",
      "Epoch 1338, 100.0%, avg_loss = 1.2073\n",
      "Epoch 1339, 100.0%, avg_loss = 1.2423\n",
      "Epoch 1340, 100.0%, avg_loss = 1.2059\n",
      "Validation Loss: 1.3136\n",
      "Epoch 1341, 100.0%, avg_loss = 1.2065\n",
      "Epoch 1342, 100.0%, avg_loss = 1.1786\n",
      "Epoch 1343, 100.0%, avg_loss = 1.2755\n",
      "Epoch 1344, 100.0%, avg_loss = 1.1874\n",
      "Epoch 1345, 100.0%, avg_loss = 1.2522\n",
      "Validation Loss: 1.3698\n",
      "Epoch 1346, 100.0%, avg_loss = 1.2015\n",
      "Epoch 1347, 100.0%, avg_loss = 1.2546\n",
      "Epoch 1348, 100.0%, avg_loss = 1.2845\n",
      "Epoch 1349, 100.0%, avg_loss = 1.2142\n",
      "Epoch 1350, 100.0%, avg_loss = 1.2289\n",
      "Validation Loss: 1.3152\n",
      "Epoch 1351, 100.0%, avg_loss = 1.2330\n",
      "Epoch 1352, 100.0%, avg_loss = 1.2101\n",
      "Epoch 1353, 100.0%, avg_loss = 1.2262\n",
      "Epoch 1354, 100.0%, avg_loss = 1.2678\n",
      "Epoch 1355, 100.0%, avg_loss = 1.2089\n",
      "Validation Loss: 1.2839\n",
      "Epoch 1356, 100.0%, avg_loss = 1.2067\n",
      "Epoch 1357, 100.0%, avg_loss = 1.1586\n",
      "Epoch 1358, 100.0%, avg_loss = 1.2329\n",
      "Epoch 1359, 100.0%, avg_loss = 1.2447\n",
      "Epoch 1360, 100.0%, avg_loss = 1.2029\n",
      "Validation Loss: 1.2866\n",
      "Epoch 1361, 100.0%, avg_loss = 1.1847\n",
      "Epoch 1362, 100.0%, avg_loss = 1.2108\n",
      "Epoch 1363, 100.0%, avg_loss = 1.2320\n",
      "Epoch 1364, 100.0%, avg_loss = 1.2425\n",
      "Epoch 1365, 100.0%, avg_loss = 1.2082\n",
      "Validation Loss: 1.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1366, 100.0%, avg_loss = 1.2285\n",
      "Epoch 1367, 100.0%, avg_loss = 1.2376\n",
      "Epoch 1368, 100.0%, avg_loss = 1.1705\n",
      "Epoch 1369, 100.0%, avg_loss = 1.2350\n",
      "Epoch 1370, 100.0%, avg_loss = 1.1745\n",
      "Validation Loss: 1.3574\n",
      "Epoch 1371, 100.0%, avg_loss = 1.2365\n",
      "Epoch 1372, 100.0%, avg_loss = 1.2423\n",
      "Epoch 1373, 100.0%, avg_loss = 1.2293\n",
      "Epoch 1374, 100.0%, avg_loss = 1.2388\n",
      "Epoch 1375, 100.0%, avg_loss = 1.1881\n",
      "Validation Loss: 1.2935\n",
      "Epoch 1376, 100.0%, avg_loss = 1.2321\n",
      "Epoch 1377, 100.0%, avg_loss = 1.2024\n",
      "Epoch 1378, 100.0%, avg_loss = 1.2641\n",
      "Epoch 1379, 100.0%, avg_loss = 1.1927\n",
      "Epoch 1380, 100.0%, avg_loss = 1.2380\n",
      "Validation Loss: 1.2974\n",
      "Epoch 1381, 100.0%, avg_loss = 1.2434\n",
      "Epoch 1382, 100.0%, avg_loss = 1.1899\n",
      "Epoch 1383, 100.0%, avg_loss = 1.2242\n",
      "Epoch 1384, 100.0%, avg_loss = 1.2086\n",
      "Epoch 1385, 100.0%, avg_loss = 1.2707\n",
      "Validation Loss: 1.3219\n",
      "Epoch 1386, 100.0%, avg_loss = 1.1939\n",
      "Epoch 1387, 100.0%, avg_loss = 1.2434\n",
      "Epoch 1388, 100.0%, avg_loss = 1.1535\n",
      "Epoch 1389, 100.0%, avg_loss = 1.2032\n",
      "Epoch 1390, 100.0%, avg_loss = 1.2168\n",
      "Validation Loss: 1.2919\n",
      "Epoch 1391, 100.0%, avg_loss = 1.1901\n",
      "Epoch 1392, 100.0%, avg_loss = 1.2507\n",
      "Epoch 1393, 100.0%, avg_loss = 1.2090\n",
      "Epoch 1394, 100.0%, avg_loss = 1.2749\n",
      "Epoch 1395, 100.0%, avg_loss = 1.1926\n",
      "Validation Loss: 1.3486\n",
      "Epoch 1396, 100.0%, avg_loss = 1.1944\n",
      "Epoch 1397, 100.0%, avg_loss = 1.2748\n",
      "Epoch 1398, 100.0%, avg_loss = 1.1608\n",
      "Epoch 1399, 100.0%, avg_loss = 1.1628\n",
      "Epoch 1400, 100.0%, avg_loss = 1.1659\n",
      "Validation Loss: 1.3289\n",
      "Epoch 1401, 100.0%, avg_loss = 1.2245\n",
      "Epoch 1402, 100.0%, avg_loss = 1.2006\n",
      "Epoch 1403, 100.0%, avg_loss = 1.1847\n",
      "Epoch 1404, 100.0%, avg_loss = 1.2148\n",
      "Epoch 1405, 100.0%, avg_loss = 1.2655\n",
      "Validation Loss: 1.2973\n",
      "Epoch 1406, 100.0%, avg_loss = 1.2311\n",
      "Epoch 1407, 100.0%, avg_loss = 1.2504\n",
      "Epoch 1408, 100.0%, avg_loss = 1.2035\n",
      "Epoch 1409, 100.0%, avg_loss = 1.2415\n",
      "Epoch 1410, 100.0%, avg_loss = 1.2036\n",
      "Validation Loss: 1.3240\n",
      "Epoch 1411, 100.0%, avg_loss = 1.2070\n",
      "Epoch 1412, 100.0%, avg_loss = 1.2333\n",
      "Epoch 1413, 100.0%, avg_loss = 1.2198\n",
      "Epoch 1414, 100.0%, avg_loss = 1.1933\n",
      "Epoch 1415, 100.0%, avg_loss = 1.2293\n",
      "Validation Loss: 1.3289\n",
      "Epoch 1416, 100.0%, avg_loss = 1.2199\n",
      "Epoch 1417, 100.0%, avg_loss = 1.1959\n",
      "Epoch 1418, 100.0%, avg_loss = 1.1817\n",
      "Epoch 1419, 100.0%, avg_loss = 1.1739\n",
      "Epoch 1420, 100.0%, avg_loss = 1.2196\n",
      "Validation Loss: 1.2663\n",
      "Epoch 1421, 100.0%, avg_loss = 1.2428\n",
      "Epoch 1422, 100.0%, avg_loss = 1.2537\n",
      "Epoch 1423, 100.0%, avg_loss = 1.1565\n",
      "Epoch 1424, 100.0%, avg_loss = 1.1916\n",
      "Epoch 1425, 100.0%, avg_loss = 1.2594\n",
      "Validation Loss: 1.3181\n",
      "Epoch 1426, 100.0%, avg_loss = 1.2757\n",
      "Epoch 1427, 100.0%, avg_loss = 1.2176\n",
      "Epoch 1428, 100.0%, avg_loss = 1.2596\n",
      "Epoch 1429, 100.0%, avg_loss = 1.2298\n",
      "Epoch 1430, 100.0%, avg_loss = 1.1830\n",
      "Validation Loss: 1.3222\n",
      "Epoch 1431, 100.0%, avg_loss = 1.2305\n",
      "Epoch 1432, 100.0%, avg_loss = 1.1958\n",
      "Epoch 1433, 100.0%, avg_loss = 1.2465\n",
      "Epoch 1434, 100.0%, avg_loss = 1.1900\n",
      "Epoch 1435, 100.0%, avg_loss = 1.2097\n",
      "Validation Loss: 1.3097\n",
      "Epoch 1436, 100.0%, avg_loss = 1.1803\n",
      "Epoch 1437, 100.0%, avg_loss = 1.2061\n",
      "Epoch 1438, 100.0%, avg_loss = 1.2334\n",
      "Epoch 1439, 100.0%, avg_loss = 1.1947\n",
      "Epoch 1440, 100.0%, avg_loss = 1.2533\n",
      "Validation Loss: 1.3231\n",
      "Epoch 1441, 100.0%, avg_loss = 1.2263\n",
      "Epoch 1442, 100.0%, avg_loss = 1.1664\n",
      "Epoch 1443, 100.0%, avg_loss = 1.1862\n",
      "Epoch 1444, 100.0%, avg_loss = 1.1656\n",
      "Epoch 1445, 100.0%, avg_loss = 1.2384\n",
      "Validation Loss: 1.3787\n",
      "Epoch 1446, 100.0%, avg_loss = 1.2329\n",
      "Epoch 1447, 100.0%, avg_loss = 1.1784\n",
      "Epoch 1448, 100.0%, avg_loss = 1.2882\n",
      "Epoch 1449, 100.0%, avg_loss = 1.2188\n",
      "Epoch 1450, 100.0%, avg_loss = 1.2169\n",
      "Validation Loss: 1.3063\n",
      "Epoch 1451, 100.0%, avg_loss = 1.1970\n",
      "Epoch 1452, 100.0%, avg_loss = 1.2268\n",
      "Epoch 1453, 100.0%, avg_loss = 1.1827\n",
      "Epoch 1454, 100.0%, avg_loss = 1.2190\n",
      "Epoch 1455, 100.0%, avg_loss = 1.1709\n",
      "Validation Loss: 1.3295\n",
      "Epoch 1456, 100.0%, avg_loss = 1.2339\n",
      "Epoch 1457, 100.0%, avg_loss = 1.1593\n",
      "Epoch 1458, 100.0%, avg_loss = 1.1846\n",
      "Epoch 1459, 100.0%, avg_loss = 1.2007\n",
      "Epoch 1460, 100.0%, avg_loss = 1.1590\n",
      "Validation Loss: 1.2770\n",
      "Epoch 1461, 100.0%, avg_loss = 1.1739\n",
      "Epoch 1462, 100.0%, avg_loss = 1.1980\n",
      "Epoch 1463, 100.0%, avg_loss = 1.1723\n",
      "Epoch 1464, 100.0%, avg_loss = 1.2160\n",
      "Epoch 1465, 100.0%, avg_loss = 1.1461\n",
      "Validation Loss: 1.3185\n",
      "Epoch 1466, 100.0%, avg_loss = 1.2476\n",
      "Epoch 1467, 100.0%, avg_loss = 1.1921\n",
      "Epoch 1468, 100.0%, avg_loss = 1.2547\n",
      "Epoch 1469, 100.0%, avg_loss = 1.2564\n",
      "Epoch 1470, 100.0%, avg_loss = 1.2248\n",
      "Validation Loss: 1.2749\n",
      "Epoch 1471, 100.0%, avg_loss = 1.2035\n",
      "Epoch 1472, 100.0%, avg_loss = 1.2263\n",
      "Epoch 1473, 100.0%, avg_loss = 1.2155\n",
      "Epoch 1474, 100.0%, avg_loss = 1.2068\n",
      "Epoch 1475, 100.0%, avg_loss = 1.2560\n",
      "Validation Loss: 1.3207\n",
      "Epoch 1476, 100.0%, avg_loss = 1.2274\n",
      "Epoch 1477, 100.0%, avg_loss = 1.2124\n",
      "Epoch 1478, 100.0%, avg_loss = 1.1683\n",
      "Epoch 1479, 100.0%, avg_loss = 1.2725\n",
      "Epoch 1480, 100.0%, avg_loss = 1.1984\n",
      "Validation Loss: 1.3029\n",
      "Epoch 1481, 100.0%, avg_loss = 1.2030\n",
      "Epoch 1482, 100.0%, avg_loss = 1.2568\n",
      "Epoch 1483, 100.0%, avg_loss = 1.2028\n",
      "Epoch 1484, 100.0%, avg_loss = 1.2120\n",
      "Epoch 1485, 100.0%, avg_loss = 1.1858\n",
      "Validation Loss: 1.3201\n",
      "Epoch 1486, 100.0%, avg_loss = 1.2302\n",
      "Epoch 1487, 100.0%, avg_loss = 1.2494\n",
      "Epoch 1488, 100.0%, avg_loss = 1.2060\n",
      "Epoch 1489, 100.0%, avg_loss = 1.1929\n",
      "Epoch 1490, 100.0%, avg_loss = 1.2400\n",
      "Validation Loss: 1.2935\n",
      "Epoch 1491, 100.0%, avg_loss = 1.1847\n",
      "Epoch 1492, 100.0%, avg_loss = 1.2300\n",
      "Epoch 1493, 100.0%, avg_loss = 1.2328\n",
      "Epoch 1494, 100.0%, avg_loss = 1.2056\n",
      "Epoch 1495, 100.0%, avg_loss = 1.2398\n",
      "Validation Loss: 1.3142\n",
      "Epoch 1496, 100.0%, avg_loss = 1.2203\n",
      "Epoch 1497, 100.0%, avg_loss = 1.2027\n",
      "Epoch 1498, 100.0%, avg_loss = 1.2168\n",
      "Epoch 1499, 100.0%, avg_loss = 1.2282\n",
      "Epoch 1500, 100.0%, avg_loss = 1.2386\n",
      "Validation Loss: 1.2748\n",
      "Epoch 1501, 100.0%, avg_loss = 1.2160\n",
      "Epoch 1502, 100.0%, avg_loss = 1.2026\n",
      "Epoch 1503, 100.0%, avg_loss = 1.1943\n",
      "Epoch 1504, 100.0%, avg_loss = 1.2182\n",
      "Epoch 1505, 100.0%, avg_loss = 1.2135\n",
      "Validation Loss: 1.3069\n",
      "Epoch 1506, 100.0%, avg_loss = 1.1939\n",
      "Epoch 1507, 100.0%, avg_loss = 1.2052\n",
      "Epoch 1508, 100.0%, avg_loss = 1.2043\n",
      "Epoch 1509, 100.0%, avg_loss = 1.2348\n",
      "Epoch 1510, 100.0%, avg_loss = 1.1870\n",
      "Validation Loss: 1.2930\n",
      "Epoch 1511, 100.0%, avg_loss = 1.1961\n",
      "Epoch 1512, 100.0%, avg_loss = 1.1769\n",
      "Epoch 1513, 100.0%, avg_loss = 1.2578\n",
      "Epoch 1514, 100.0%, avg_loss = 1.2091\n",
      "Epoch 1515, 100.0%, avg_loss = 1.2488\n",
      "Validation Loss: 1.3635\n",
      "Epoch 1516, 100.0%, avg_loss = 1.1950\n",
      "Epoch 1517, 100.0%, avg_loss = 1.2028\n",
      "Epoch 1518, 100.0%, avg_loss = 1.2047\n",
      "Epoch 1519, 100.0%, avg_loss = 1.2107\n",
      "Epoch 1520, 100.0%, avg_loss = 1.1530\n",
      "Validation Loss: 1.3086\n",
      "Epoch 1521, 100.0%, avg_loss = 1.2036\n",
      "Epoch 1522, 100.0%, avg_loss = 1.2371\n",
      "Epoch 1523, 100.0%, avg_loss = 1.1560\n",
      "Epoch 1524, 100.0%, avg_loss = 1.2307\n",
      "Epoch 1525, 100.0%, avg_loss = 1.2119\n",
      "Validation Loss: 1.2649\n",
      "Epoch 1526, 100.0%, avg_loss = 1.1704\n",
      "Epoch 1527, 100.0%, avg_loss = 1.2243\n",
      "Epoch 1528, 100.0%, avg_loss = 1.1536\n",
      "Epoch 1529, 100.0%, avg_loss = 1.2483\n",
      "Epoch 1530, 100.0%, avg_loss = 1.1679\n",
      "Validation Loss: 1.3259\n",
      "Epoch 1531, 100.0%, avg_loss = 1.2079\n",
      "Epoch 1532, 100.0%, avg_loss = 1.1855\n",
      "Epoch 1533, 100.0%, avg_loss = 1.2947\n",
      "Epoch 1534, 100.0%, avg_loss = 1.1815\n",
      "Epoch 1535, 100.0%, avg_loss = 1.2134\n",
      "Validation Loss: 1.3106\n",
      "Epoch 1536, 100.0%, avg_loss = 1.2264\n",
      "Epoch 1537, 100.0%, avg_loss = 1.1787\n",
      "Epoch 1538, 100.0%, avg_loss = 1.1760\n",
      "Epoch 1539, 100.0%, avg_loss = 1.2201\n",
      "Epoch 1540, 100.0%, avg_loss = 1.1678\n",
      "Validation Loss: 1.2921\n",
      "Epoch 1541, 100.0%, avg_loss = 1.1851\n",
      "Epoch 1542, 100.0%, avg_loss = 1.2339\n",
      "Epoch 1543, 100.0%, avg_loss = 1.1614\n",
      "Epoch 1544, 100.0%, avg_loss = 1.2373\n",
      "Epoch 1545, 100.0%, avg_loss = 1.2442\n",
      "Validation Loss: 1.3703\n",
      "Epoch 1546, 100.0%, avg_loss = 1.2203\n",
      "Epoch 1547, 100.0%, avg_loss = 1.2337\n",
      "Epoch 1548, 100.0%, avg_loss = 1.1967\n",
      "Epoch 1549, 100.0%, avg_loss = 1.1868\n",
      "Epoch 1550, 100.0%, avg_loss = 1.2264\n",
      "Validation Loss: 1.2977\n",
      "Epoch 1551, 100.0%, avg_loss = 1.2380\n",
      "Epoch 1552, 100.0%, avg_loss = 1.1776\n",
      "Epoch 1553, 100.0%, avg_loss = 1.2504\n",
      "Epoch 1554, 100.0%, avg_loss = 1.2516\n",
      "Epoch 1555, 100.0%, avg_loss = 1.2358\n",
      "Validation Loss: 1.2879\n",
      "Epoch 1556, 100.0%, avg_loss = 1.1680\n",
      "Epoch 1557, 100.0%, avg_loss = 1.1569\n",
      "Epoch 1558, 100.0%, avg_loss = 1.1879\n",
      "Epoch 1559, 100.0%, avg_loss = 1.2106\n",
      "Epoch 1560, 100.0%, avg_loss = 1.1984\n",
      "Validation Loss: 1.2789\n",
      "Epoch 1561, 100.0%, avg_loss = 1.2517\n",
      "Epoch 1562, 100.0%, avg_loss = 1.1531\n",
      "Epoch 1563, 100.0%, avg_loss = 1.1862\n",
      "Epoch 1564, 100.0%, avg_loss = 1.2489\n",
      "Epoch 1565, 100.0%, avg_loss = 1.1988\n",
      "Validation Loss: 1.3039\n",
      "Epoch 1566, 100.0%, avg_loss = 1.2089\n",
      "Epoch 1567, 100.0%, avg_loss = 1.2029\n",
      "Epoch 1568, 100.0%, avg_loss = 1.1988\n",
      "Epoch 1569, 100.0%, avg_loss = 1.1814\n",
      "Epoch 1570, 100.0%, avg_loss = 1.2056\n",
      "Validation Loss: 1.3334\n",
      "Epoch 1571, 100.0%, avg_loss = 1.1615\n",
      "Epoch 1572, 100.0%, avg_loss = 1.2311\n",
      "Epoch 1573, 100.0%, avg_loss = 1.1487\n",
      "Epoch 1574, 100.0%, avg_loss = 1.1947\n",
      "Epoch 1575, 100.0%, avg_loss = 1.2944\n",
      "Validation Loss: 1.2804\n",
      "Epoch 1576, 100.0%, avg_loss = 1.2063\n",
      "Epoch 1577, 100.0%, avg_loss = 1.1652\n",
      "Epoch 1578, 100.0%, avg_loss = 1.2488\n",
      "Epoch 1579, 100.0%, avg_loss = 1.2047\n",
      "Epoch 1580, 100.0%, avg_loss = 1.2262\n",
      "Validation Loss: 1.2744\n",
      "Epoch 1581, 100.0%, avg_loss = 1.2028\n",
      "Epoch 1582, 100.0%, avg_loss = 1.1599\n",
      "Epoch 1583, 100.0%, avg_loss = 1.1843\n",
      "Epoch 1584, 100.0%, avg_loss = 1.1773\n",
      "Epoch 1585, 100.0%, avg_loss = 1.1710\n",
      "Validation Loss: 1.3010\n",
      "Epoch 1586, 100.0%, avg_loss = 1.2700\n",
      "Epoch 1587, 100.0%, avg_loss = 1.2146\n",
      "Epoch 1588, 100.0%, avg_loss = 1.2562\n",
      "Epoch 1589, 100.0%, avg_loss = 1.1859\n",
      "Epoch 1590, 100.0%, avg_loss = 1.1888\n",
      "Validation Loss: 1.2890\n",
      "Epoch 1591, 100.0%, avg_loss = 1.2143\n",
      "Epoch 1592, 100.0%, avg_loss = 1.2316\n",
      "Epoch 1593, 100.0%, avg_loss = 1.2338\n",
      "Epoch 1594, 100.0%, avg_loss = 1.2002\n",
      "Epoch 1595, 100.0%, avg_loss = 1.1835\n",
      "Validation Loss: 1.2663\n",
      "Epoch 1596, 100.0%, avg_loss = 1.1966\n",
      "Epoch 1597, 100.0%, avg_loss = 1.2045\n",
      "Epoch 1598, 100.0%, avg_loss = 1.2178\n",
      "Epoch 1599, 100.0%, avg_loss = 1.1647\n",
      "Epoch 1600, 100.0%, avg_loss = 1.2212\n",
      "Validation Loss: 1.3166\n",
      "Epoch 1601, 100.0%, avg_loss = 1.2034\n",
      "Epoch 1602, 100.0%, avg_loss = 1.2524\n",
      "Epoch 1603, 100.0%, avg_loss = 1.1672\n",
      "Epoch 1604, 100.0%, avg_loss = 1.1861\n",
      "Epoch 1605, 100.0%, avg_loss = 1.2282\n",
      "Validation Loss: 1.2582\n",
      "Epoch 1606, 100.0%, avg_loss = 1.2127\n",
      "Epoch 1607, 100.0%, avg_loss = 1.2229\n",
      "Epoch 1608, 100.0%, avg_loss = 1.1916\n",
      "Epoch 1609, 100.0%, avg_loss = 1.2169\n",
      "Epoch 1610, 100.0%, avg_loss = 1.1632\n",
      "Validation Loss: 1.3015\n",
      "Epoch 1611, 100.0%, avg_loss = 1.1970\n",
      "Epoch 1612, 100.0%, avg_loss = 1.1734\n",
      "Epoch 1613, 100.0%, avg_loss = 1.1422\n",
      "Epoch 1614, 100.0%, avg_loss = 1.1701\n",
      "Epoch 1615, 100.0%, avg_loss = 1.2051\n",
      "Validation Loss: 1.3249\n",
      "Epoch 1616, 100.0%, avg_loss = 1.2171\n",
      "Epoch 1617, 100.0%, avg_loss = 1.2274\n",
      "Epoch 1618, 100.0%, avg_loss = 1.1776\n",
      "Epoch 1619, 100.0%, avg_loss = 1.1785\n",
      "Epoch 1620, 100.0%, avg_loss = 1.1565\n",
      "Validation Loss: 1.2710\n",
      "Epoch 1621, 100.0%, avg_loss = 1.1855\n",
      "Epoch 1622, 100.0%, avg_loss = 1.1847\n",
      "Epoch 1623, 100.0%, avg_loss = 1.2461\n",
      "Epoch 1624, 100.0%, avg_loss = 1.1763\n",
      "Epoch 1625, 100.0%, avg_loss = 1.2289\n",
      "Validation Loss: 1.2761\n",
      "Epoch 1626, 100.0%, avg_loss = 1.2160\n",
      "Epoch 1627, 100.0%, avg_loss = 1.2101\n",
      "Epoch 1628, 100.0%, avg_loss = 1.1875\n",
      "Epoch 1629, 100.0%, avg_loss = 1.2187\n",
      "Epoch 1630, 100.0%, avg_loss = 1.2486\n",
      "Validation Loss: 1.2898\n",
      "Epoch 1631, 100.0%, avg_loss = 1.1615\n",
      "Epoch 1632, 100.0%, avg_loss = 1.2031\n",
      "Epoch 1633, 100.0%, avg_loss = 1.2298\n",
      "Epoch 1634, 100.0%, avg_loss = 1.2850\n",
      "Epoch 1635, 100.0%, avg_loss = 1.1297\n",
      "Validation Loss: 1.3746\n",
      "Epoch 1636, 100.0%, avg_loss = 1.2259\n",
      "Epoch 1637, 100.0%, avg_loss = 1.1874\n",
      "Epoch 1638, 100.0%, avg_loss = 1.2186\n",
      "Epoch 1639, 100.0%, avg_loss = 1.2639\n",
      "Epoch 1640, 100.0%, avg_loss = 1.2062\n",
      "Validation Loss: 1.2713\n",
      "Epoch 1641, 100.0%, avg_loss = 1.2185\n",
      "Epoch 1642, 100.0%, avg_loss = 1.1988\n",
      "Epoch 1643, 100.0%, avg_loss = 1.2336\n",
      "Epoch 1644, 100.0%, avg_loss = 1.2352\n",
      "Epoch 1645, 100.0%, avg_loss = 1.1739\n",
      "Validation Loss: 1.3018\n",
      "Epoch 1646, 100.0%, avg_loss = 1.1766\n",
      "Epoch 1647, 100.0%, avg_loss = 1.1610\n",
      "Epoch 1648, 100.0%, avg_loss = 1.2091\n",
      "Epoch 1649, 100.0%, avg_loss = 1.1665\n",
      "Epoch 1650, 100.0%, avg_loss = 1.2569\n",
      "Validation Loss: 1.2995\n",
      "Epoch 1651, 100.0%, avg_loss = 1.1939\n",
      "Epoch 1652, 100.0%, avg_loss = 1.2559\n",
      "Epoch 1653, 100.0%, avg_loss = 1.2577\n",
      "Epoch 1654, 100.0%, avg_loss = 1.1666\n",
      "Epoch 1655, 100.0%, avg_loss = 1.2516\n",
      "Validation Loss: 1.3392\n",
      "Epoch 1656, 100.0%, avg_loss = 1.2005\n",
      "Epoch 1657, 100.0%, avg_loss = 1.2476\n",
      "Epoch 1658, 100.0%, avg_loss = 1.2054\n",
      "Epoch 1659, 100.0%, avg_loss = 1.1863\n",
      "Epoch 1660, 100.0%, avg_loss = 1.1875\n",
      "Validation Loss: 1.3488\n",
      "Epoch 1661, 100.0%, avg_loss = 1.2591\n",
      "Epoch 1662, 100.0%, avg_loss = 1.1896\n",
      "Epoch 1663, 100.0%, avg_loss = 1.2265\n",
      "Epoch 1664, 100.0%, avg_loss = 1.2121\n",
      "Epoch 1665, 100.0%, avg_loss = 1.1762\n",
      "Validation Loss: 1.2837\n",
      "Epoch 1666, 100.0%, avg_loss = 1.1565\n",
      "Epoch 1667, 100.0%, avg_loss = 1.2184\n",
      "Epoch 1668, 100.0%, avg_loss = 1.2360\n",
      "Epoch 1669, 100.0%, avg_loss = 1.1776\n",
      "Epoch 1670, 100.0%, avg_loss = 1.1759\n",
      "Validation Loss: 1.3236\n",
      "Epoch 1671, 100.0%, avg_loss = 1.2633\n",
      "Epoch 1672, 100.0%, avg_loss = 1.2462\n",
      "Epoch 1673, 100.0%, avg_loss = 1.2237\n",
      "Epoch 1674, 100.0%, avg_loss = 1.2457\n",
      "Epoch 1675, 100.0%, avg_loss = 1.1904\n",
      "Validation Loss: 1.2953\n",
      "Epoch 1676, 100.0%, avg_loss = 1.1598\n",
      "Epoch 1677, 100.0%, avg_loss = 1.2785\n",
      "Epoch 1678, 100.0%, avg_loss = 1.2033\n",
      "Epoch 1679, 100.0%, avg_loss = 1.2105\n",
      "Epoch 1680, 100.0%, avg_loss = 1.1275\n",
      "Validation Loss: 1.3470\n",
      "Epoch 1681, 100.0%, avg_loss = 1.1199\n",
      "Epoch 1682, 100.0%, avg_loss = 1.1775\n",
      "Epoch 1683, 100.0%, avg_loss = 1.1790\n",
      "Epoch 1684, 100.0%, avg_loss = 1.1829\n",
      "Epoch 1685, 100.0%, avg_loss = 1.2095\n",
      "Validation Loss: 1.3001\n",
      "Epoch 1686, 100.0%, avg_loss = 1.2147\n",
      "Epoch 1687, 100.0%, avg_loss = 1.1815\n",
      "Epoch 1688, 100.0%, avg_loss = 1.1756\n",
      "Epoch 1689, 100.0%, avg_loss = 1.1681\n",
      "Epoch 1690, 100.0%, avg_loss = 1.2049\n",
      "Validation Loss: 1.3112\n",
      "Epoch 1691, 100.0%, avg_loss = 1.1690\n",
      "Epoch 1692, 100.0%, avg_loss = 1.2698\n",
      "Epoch 1693, 100.0%, avg_loss = 1.1943\n",
      "Epoch 1694, 100.0%, avg_loss = 1.2127\n",
      "Epoch 1695, 100.0%, avg_loss = 1.1654\n",
      "Validation Loss: 1.2792\n",
      "Epoch 1696, 100.0%, avg_loss = 1.1509\n",
      "Epoch 1697, 100.0%, avg_loss = 1.2252\n",
      "Epoch 1698, 100.0%, avg_loss = 1.1927\n",
      "Epoch 1699, 100.0%, avg_loss = 1.1451\n",
      "Epoch 1700, 100.0%, avg_loss = 1.2231\n",
      "Validation Loss: 1.2856\n",
      "Epoch 1701, 100.0%, avg_loss = 1.1166\n",
      "Epoch 1702, 100.0%, avg_loss = 1.1596\n",
      "Epoch 1703, 100.0%, avg_loss = 1.1812\n",
      "Epoch 1704, 100.0%, avg_loss = 1.1076\n",
      "Epoch 1705, 100.0%, avg_loss = 1.2762\n",
      "Validation Loss: 1.2868\n",
      "Epoch 1706, 100.0%, avg_loss = 1.1622\n",
      "Epoch 1707, 100.0%, avg_loss = 1.2433\n",
      "Epoch 1708, 100.0%, avg_loss = 1.1743\n",
      "Epoch 1709, 100.0%, avg_loss = 1.2250\n",
      "Epoch 1710, 100.0%, avg_loss = 1.2094\n",
      "Validation Loss: 1.3304\n",
      "Epoch 1711, 100.0%, avg_loss = 1.2345\n",
      "Epoch 1712, 100.0%, avg_loss = 1.2068\n",
      "Epoch 1713, 100.0%, avg_loss = 1.1890\n",
      "Epoch 1714, 100.0%, avg_loss = 1.1864\n",
      "Epoch 1715, 100.0%, avg_loss = 1.2453\n",
      "Validation Loss: 1.3190\n",
      "Epoch 1716, 100.0%, avg_loss = 1.2042\n",
      "Epoch 1717, 100.0%, avg_loss = 1.2599\n",
      "Epoch 1718, 100.0%, avg_loss = 1.2365\n",
      "Epoch 1719, 100.0%, avg_loss = 1.1964\n",
      "Epoch 1720, 100.0%, avg_loss = 1.1471\n",
      "Validation Loss: 1.2614\n",
      "Epoch 1721, 100.0%, avg_loss = 1.1885\n",
      "Epoch 1722, 100.0%, avg_loss = 1.2154\n",
      "Epoch 1723, 100.0%, avg_loss = 1.1819\n",
      "Epoch 1724, 100.0%, avg_loss = 1.2287\n",
      "Epoch 1725, 100.0%, avg_loss = 1.1985\n",
      "Validation Loss: 1.3171\n",
      "Epoch 1726, 100.0%, avg_loss = 1.2139\n",
      "Epoch 1727, 100.0%, avg_loss = 1.2073\n",
      "Epoch 1728, 100.0%, avg_loss = 1.2344\n",
      "Epoch 1729, 100.0%, avg_loss = 1.2113\n",
      "Epoch 1730, 100.0%, avg_loss = 1.1566\n",
      "Validation Loss: 1.2916\n",
      "Epoch 1731, 100.0%, avg_loss = 1.1959\n",
      "Epoch 1732, 100.0%, avg_loss = 1.2109\n",
      "Epoch 1733, 100.0%, avg_loss = 1.1496\n",
      "Epoch 1734, 100.0%, avg_loss = 1.1844\n",
      "Epoch 1735, 100.0%, avg_loss = 1.2417\n",
      "Validation Loss: 1.3984\n",
      "Epoch 1736, 100.0%, avg_loss = 1.2125\n",
      "Epoch 1737, 100.0%, avg_loss = 1.2118\n",
      "Epoch 1738, 100.0%, avg_loss = 1.2349\n",
      "Epoch 1739, 100.0%, avg_loss = 1.2124\n",
      "Epoch 1740, 100.0%, avg_loss = 1.1853\n",
      "Validation Loss: 1.2923\n",
      "Epoch 1741, 100.0%, avg_loss = 1.1708\n",
      "Epoch 1742, 100.0%, avg_loss = 1.1516\n",
      "Epoch 1743, 100.0%, avg_loss = 1.2082\n",
      "Epoch 1744, 100.0%, avg_loss = 1.2312\n",
      "Epoch 1745, 100.0%, avg_loss = 1.2032\n",
      "Validation Loss: 1.2470\n",
      "Epoch 1746, 100.0%, avg_loss = 1.1742\n",
      "Epoch 1747, 100.0%, avg_loss = 1.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1748, 100.0%, avg_loss = 1.1910\n",
      "Epoch 1749, 100.0%, avg_loss = 1.2647\n",
      "Epoch 1750, 100.0%, avg_loss = 1.2155\n",
      "Validation Loss: 1.2682\n",
      "Epoch 1751, 100.0%, avg_loss = 1.1618\n",
      "Epoch 1752, 100.0%, avg_loss = 1.1956\n",
      "Epoch 1753, 100.0%, avg_loss = 1.1596\n",
      "Epoch 1754, 100.0%, avg_loss = 1.1998\n",
      "Epoch 1755, 100.0%, avg_loss = 1.2106\n",
      "Validation Loss: 1.2924\n",
      "Epoch 1756, 100.0%, avg_loss = 1.1527\n",
      "Epoch 1757, 100.0%, avg_loss = 1.2522\n",
      "Epoch 1758, 100.0%, avg_loss = 1.1869\n",
      "Epoch 1759, 100.0%, avg_loss = 1.2320\n",
      "Epoch 1760, 100.0%, avg_loss = 1.2105\n",
      "Validation Loss: 1.2821\n",
      "Epoch 1761, 100.0%, avg_loss = 1.2350\n",
      "Epoch 1762, 100.0%, avg_loss = 1.2270\n",
      "Epoch 1763, 100.0%, avg_loss = 1.2238\n",
      "Epoch 1764, 100.0%, avg_loss = 1.2133\n",
      "Epoch 1765, 100.0%, avg_loss = 1.2047\n",
      "Validation Loss: 1.3127\n",
      "Epoch 1766, 100.0%, avg_loss = 1.1847\n",
      "Epoch 1767, 100.0%, avg_loss = 1.1392\n",
      "Epoch 1768, 100.0%, avg_loss = 1.2507\n",
      "Epoch 1769, 100.0%, avg_loss = 1.1781\n",
      "Epoch 1770, 100.0%, avg_loss = 1.1879\n",
      "Validation Loss: 1.2605\n",
      "Epoch 1771, 100.0%, avg_loss = 1.2357\n",
      "Epoch 1772, 100.0%, avg_loss = 1.2421\n",
      "Epoch 1773, 100.0%, avg_loss = 1.2082\n",
      "Epoch 1774, 100.0%, avg_loss = 1.1700\n",
      "Epoch 1775, 100.0%, avg_loss = 1.1659\n",
      "Validation Loss: 1.3044\n",
      "Epoch 1776, 100.0%, avg_loss = 1.2078\n",
      "Epoch 1777, 100.0%, avg_loss = 1.2181\n",
      "Epoch 1778, 100.0%, avg_loss = 1.1744\n",
      "Epoch 1779, 100.0%, avg_loss = 1.1654\n",
      "Epoch 1780, 100.0%, avg_loss = 1.1870\n",
      "Validation Loss: 1.3144\n",
      "Epoch 1781, 100.0%, avg_loss = 1.1718\n",
      "Epoch 1782, 100.0%, avg_loss = 1.2046\n",
      "Epoch 1783, 100.0%, avg_loss = 1.1308\n",
      "Epoch 1784, 100.0%, avg_loss = 1.1682\n",
      "Epoch 1785, 100.0%, avg_loss = 1.1986\n",
      "Validation Loss: 1.2659\n",
      "Epoch 1786, 100.0%, avg_loss = 1.2625\n",
      "Epoch 1787, 100.0%, avg_loss = 1.2702\n",
      "Epoch 1788, 100.0%, avg_loss = 1.1486\n",
      "Epoch 1789, 100.0%, avg_loss = 1.1786\n",
      "Epoch 1790, 100.0%, avg_loss = 1.1362\n",
      "Validation Loss: 1.2921\n",
      "Epoch 1791, 100.0%, avg_loss = 1.2084\n",
      "Epoch 1792, 100.0%, avg_loss = 1.1764\n",
      "Epoch 1793, 100.0%, avg_loss = 1.1594\n",
      "Epoch 1794, 100.0%, avg_loss = 1.2187\n",
      "Epoch 1795, 100.0%, avg_loss = 1.2165\n",
      "Validation Loss: 1.2875\n",
      "Epoch 1796, 100.0%, avg_loss = 1.1631\n",
      "Epoch 1797, 100.0%, avg_loss = 1.2341\n",
      "Epoch 1798, 100.0%, avg_loss = 1.1809\n",
      "Epoch 1799, 100.0%, avg_loss = 1.2537\n",
      "Epoch 1800, 100.0%, avg_loss = 1.1855\n",
      "Validation Loss: 1.2758\n",
      "Epoch 1801, 100.0%, avg_loss = 1.2235\n",
      "Epoch 1802, 100.0%, avg_loss = 1.2292\n",
      "Epoch 1803, 100.0%, avg_loss = 1.1635\n",
      "Epoch 1804, 100.0%, avg_loss = 1.2377\n",
      "Epoch 1805, 100.0%, avg_loss = 1.1739\n",
      "Validation Loss: 1.2859\n",
      "Epoch 1806, 100.0%, avg_loss = 1.2294\n",
      "Epoch 1807, 100.0%, avg_loss = 1.1678\n",
      "Epoch 1808, 100.0%, avg_loss = 1.2583\n",
      "Epoch 1809, 100.0%, avg_loss = 1.1869\n",
      "Epoch 1810, 100.0%, avg_loss = 1.2245\n",
      "Validation Loss: 1.3145\n",
      "Epoch 1811, 100.0%, avg_loss = 1.2341\n",
      "Epoch 1812, 100.0%, avg_loss = 1.2183\n",
      "Epoch 1813, 100.0%, avg_loss = 1.1458\n",
      "Epoch 1814, 100.0%, avg_loss = 1.1414\n",
      "Epoch 1815, 100.0%, avg_loss = 1.2356\n",
      "Validation Loss: 1.3308\n",
      "Epoch 1816, 100.0%, avg_loss = 1.1484\n",
      "Epoch 1817, 100.0%, avg_loss = 1.2114\n",
      "Epoch 1818, 100.0%, avg_loss = 1.2491\n",
      "Epoch 1819, 100.0%, avg_loss = 1.1423\n",
      "Epoch 1820, 100.0%, avg_loss = 1.1999\n",
      "Validation Loss: 1.2868\n",
      "Epoch 1821, 100.0%, avg_loss = 1.2015\n",
      "Epoch 1822, 100.0%, avg_loss = 1.2003\n",
      "Epoch 1823, 100.0%, avg_loss = 1.2417\n",
      "Epoch 1824, 100.0%, avg_loss = 1.2048\n",
      "Epoch 1825, 100.0%, avg_loss = 1.2284\n",
      "Validation Loss: 1.2819\n",
      "Epoch 1826, 100.0%, avg_loss = 1.2148\n",
      "Epoch 1827, 100.0%, avg_loss = 1.2094\n",
      "Epoch 1828, 100.0%, avg_loss = 1.2453\n",
      "Epoch 1829, 100.0%, avg_loss = 1.1822\n",
      "Epoch 1830, 100.0%, avg_loss = 1.1816\n",
      "Validation Loss: 1.3396\n",
      "Epoch 1831, 100.0%, avg_loss = 1.1879\n",
      "Epoch 1832, 100.0%, avg_loss = 1.2378\n",
      "Epoch 1833, 100.0%, avg_loss = 1.1882\n",
      "Epoch 1834, 100.0%, avg_loss = 1.1573\n",
      "Epoch 1835, 100.0%, avg_loss = 1.2058\n",
      "Validation Loss: 1.3287\n",
      "Epoch 1836, 100.0%, avg_loss = 1.2178\n",
      "Epoch 1837, 100.0%, avg_loss = 1.2013\n",
      "Epoch 1838, 100.0%, avg_loss = 1.2184\n",
      "Epoch 1839, 100.0%, avg_loss = 1.1644\n",
      "Epoch 1840, 100.0%, avg_loss = 1.2229\n",
      "Validation Loss: 1.2879\n",
      "Epoch 1841, 100.0%, avg_loss = 1.2100\n",
      "Epoch 1842, 100.0%, avg_loss = 1.1826\n",
      "Epoch 1843, 100.0%, avg_loss = 1.1669\n",
      "Epoch 1844, 100.0%, avg_loss = 1.1841\n",
      "Epoch 1845, 100.0%, avg_loss = 1.2074\n",
      "Validation Loss: 1.2709\n",
      "Epoch 1846, 100.0%, avg_loss = 1.1895\n",
      "Epoch 1847, 100.0%, avg_loss = 1.2244\n",
      "Epoch 1848, 100.0%, avg_loss = 1.2339\n",
      "Epoch 1849, 100.0%, avg_loss = 1.1710\n",
      "Epoch 1850, 100.0%, avg_loss = 1.1997\n",
      "Validation Loss: 1.3168\n",
      "Epoch 1851, 100.0%, avg_loss = 1.1663\n",
      "Epoch 1852, 100.0%, avg_loss = 1.1451\n",
      "Epoch 1853, 100.0%, avg_loss = 1.2368\n",
      "Epoch 1854, 100.0%, avg_loss = 1.1512\n",
      "Epoch 1855, 100.0%, avg_loss = 1.1842\n",
      "Validation Loss: 1.2734\n",
      "Epoch 1856, 100.0%, avg_loss = 1.2297\n",
      "Epoch 1857, 100.0%, avg_loss = 1.1968\n",
      "Epoch 1858, 100.0%, avg_loss = 1.1355\n",
      "Epoch 1859, 100.0%, avg_loss = 1.1781\n",
      "Epoch 1860, 100.0%, avg_loss = 1.1904\n",
      "Validation Loss: 1.2608\n",
      "Epoch 1861, 100.0%, avg_loss = 1.1816\n",
      "Epoch 1862, 100.0%, avg_loss = 1.2380\n",
      "Epoch 1863, 100.0%, avg_loss = 1.2561\n",
      "Epoch 1864, 100.0%, avg_loss = 1.2103\n",
      "Epoch 1865, 100.0%, avg_loss = 1.2091\n",
      "Validation Loss: 1.2549\n",
      "Epoch 1866, 100.0%, avg_loss = 1.1940\n",
      "Epoch 1867, 100.0%, avg_loss = 1.1520\n",
      "Epoch 1868, 100.0%, avg_loss = 1.1875\n",
      "Epoch 1869, 100.0%, avg_loss = 1.2124\n",
      "Epoch 1870, 100.0%, avg_loss = 1.1968\n",
      "Validation Loss: 1.2567\n",
      "Epoch 1871, 100.0%, avg_loss = 1.1799\n",
      "Epoch 1872, 100.0%, avg_loss = 1.1339\n",
      "Epoch 1873, 100.0%, avg_loss = 1.1770\n",
      "Epoch 1874, 100.0%, avg_loss = 1.1964\n",
      "Epoch 1875, 100.0%, avg_loss = 1.2173\n",
      "Validation Loss: 1.3135\n",
      "Epoch 1876, 100.0%, avg_loss = 1.1755\n",
      "Epoch 1877, 100.0%, avg_loss = 1.1447\n",
      "Epoch 1878, 100.0%, avg_loss = 1.1868\n",
      "Epoch 1879, 100.0%, avg_loss = 1.2177\n",
      "Epoch 1880, 100.0%, avg_loss = 1.1817\n",
      "Validation Loss: 1.2744\n",
      "Epoch 1881, 100.0%, avg_loss = 1.1879\n",
      "Epoch 1882, 100.0%, avg_loss = 1.1917\n",
      "Epoch 1883, 100.0%, avg_loss = 1.2425\n",
      "Epoch 1884, 100.0%, avg_loss = 1.1757\n",
      "Epoch 1885, 100.0%, avg_loss = 1.1841\n",
      "Validation Loss: 1.3141\n",
      "Epoch 1886, 100.0%, avg_loss = 1.1860\n",
      "Epoch 1887, 100.0%, avg_loss = 1.2257\n",
      "Epoch 1888, 100.0%, avg_loss = 1.2015\n",
      "Epoch 1889, 100.0%, avg_loss = 1.2383\n",
      "Epoch 1890, 100.0%, avg_loss = 1.1691\n",
      "Validation Loss: 1.3700\n",
      "Epoch 1891, 100.0%, avg_loss = 1.2423\n",
      "Epoch 1892, 100.0%, avg_loss = 1.2035\n",
      "Epoch 1893, 100.0%, avg_loss = 1.2097\n",
      "Epoch 1894, 100.0%, avg_loss = 1.2064\n",
      "Epoch 1895, 100.0%, avg_loss = 1.2552\n",
      "Validation Loss: 1.2980\n",
      "Epoch 1896, 100.0%, avg_loss = 1.2046\n",
      "Epoch 1897, 100.0%, avg_loss = 1.2514\n",
      "Epoch 1898, 100.0%, avg_loss = 1.1940\n",
      "Epoch 1899, 100.0%, avg_loss = 1.2251\n",
      "Epoch 1900, 100.0%, avg_loss = 1.2317\n",
      "Validation Loss: 1.3033\n",
      "Epoch 1901, 100.0%, avg_loss = 1.2119\n",
      "Epoch 1902, 100.0%, avg_loss = 1.1884\n",
      "Epoch 1903, 100.0%, avg_loss = 1.2218\n",
      "Epoch 1904, 100.0%, avg_loss = 1.2228\n",
      "Epoch 1905, 100.0%, avg_loss = 1.2020\n",
      "Validation Loss: 1.2642\n",
      "Epoch 1906, 100.0%, avg_loss = 1.2062\n",
      "Epoch 1907, 100.0%, avg_loss = 1.1327\n",
      "Epoch 1908, 100.0%, avg_loss = 1.1828\n",
      "Epoch 1909, 100.0%, avg_loss = 1.2124\n",
      "Epoch 1910, 100.0%, avg_loss = 1.1891\n",
      "Validation Loss: 1.3239\n",
      "Epoch 1911, 100.0%, avg_loss = 1.1981\n",
      "Epoch 1912, 100.0%, avg_loss = 1.1965\n",
      "Epoch 1913, 100.0%, avg_loss = 1.2231\n",
      "Epoch 1914, 100.0%, avg_loss = 1.2181\n",
      "Epoch 1915, 100.0%, avg_loss = 1.1628\n",
      "Validation Loss: 1.3182\n",
      "Epoch 1916, 100.0%, avg_loss = 1.2079\n",
      "Epoch 1917, 100.0%, avg_loss = 1.2508\n",
      "Epoch 1918, 100.0%, avg_loss = 1.2353\n",
      "Epoch 1919, 100.0%, avg_loss = 1.2107\n",
      "Epoch 1920, 100.0%, avg_loss = 1.1784\n",
      "Validation Loss: 1.2889\n",
      "Epoch 1921, 100.0%, avg_loss = 1.2752\n",
      "Epoch 1922, 100.0%, avg_loss = 1.1928\n",
      "Epoch 1923, 100.0%, avg_loss = 1.1855\n",
      "Epoch 1924, 100.0%, avg_loss = 1.1769\n",
      "Epoch 1925, 100.0%, avg_loss = 1.1479\n",
      "Validation Loss: 1.2659\n",
      "Epoch 1926, 100.0%, avg_loss = 1.2214\n",
      "Epoch 1927, 100.0%, avg_loss = 1.1807\n",
      "Epoch 1928, 100.0%, avg_loss = 1.1518\n",
      "Epoch 1929, 100.0%, avg_loss = 1.1951\n",
      "Epoch 1930, 100.0%, avg_loss = 1.2103\n",
      "Validation Loss: 1.2897\n",
      "Epoch 1931, 100.0%, avg_loss = 1.1307\n",
      "Epoch 1932, 100.0%, avg_loss = 1.1645\n",
      "Epoch 1933, 100.0%, avg_loss = 1.2041\n",
      "Epoch 1934, 100.0%, avg_loss = 1.1621\n",
      "Epoch 1935, 100.0%, avg_loss = 1.1435\n",
      "Validation Loss: 1.2681\n",
      "Epoch 1936, 100.0%, avg_loss = 1.2061\n",
      "Epoch 1937, 100.0%, avg_loss = 1.1821\n",
      "Epoch 1938, 100.0%, avg_loss = 1.2177\n",
      "Epoch 1939, 100.0%, avg_loss = 1.1610\n",
      "Epoch 1940, 100.0%, avg_loss = 1.2059\n",
      "Validation Loss: 1.2866\n",
      "Epoch 1941, 100.0%, avg_loss = 1.2227\n",
      "Epoch 1942, 100.0%, avg_loss = 1.1274\n",
      "Epoch 1943, 100.0%, avg_loss = 1.1784\n",
      "Epoch 1944, 100.0%, avg_loss = 1.1903\n",
      "Epoch 1945, 100.0%, avg_loss = 1.1977\n",
      "Validation Loss: 1.3141\n",
      "Epoch 1946, 100.0%, avg_loss = 1.1872\n",
      "Epoch 1947, 100.0%, avg_loss = 1.2349\n",
      "Epoch 1948, 100.0%, avg_loss = 1.1924\n",
      "Epoch 1949, 100.0%, avg_loss = 1.2079\n",
      "Epoch 1950, 100.0%, avg_loss = 1.1550\n",
      "Validation Loss: 1.2461\n",
      "Epoch 1951, 100.0%, avg_loss = 1.1997\n",
      "Epoch 1952, 100.0%, avg_loss = 1.2577\n",
      "Epoch 1953, 100.0%, avg_loss = 1.2319\n",
      "Epoch 1954, 100.0%, avg_loss = 1.1935\n",
      "Epoch 1955, 100.0%, avg_loss = 1.1806\n",
      "Validation Loss: 1.3006\n",
      "Epoch 1956, 100.0%, avg_loss = 1.1892\n",
      "Epoch 1957, 100.0%, avg_loss = 1.1772\n",
      "Epoch 1958, 100.0%, avg_loss = 1.2005\n",
      "Epoch 1959, 100.0%, avg_loss = 1.1230\n",
      "Epoch 1960, 100.0%, avg_loss = 1.1411\n",
      "Validation Loss: 1.2860\n",
      "Epoch 1961, 100.0%, avg_loss = 1.2532\n",
      "Epoch 1962, 100.0%, avg_loss = 1.1599\n",
      "Epoch 1963, 100.0%, avg_loss = 1.1985\n",
      "Epoch 1964, 100.0%, avg_loss = 1.1306\n",
      "Epoch 1965, 100.0%, avg_loss = 1.2172\n",
      "Validation Loss: 1.3278\n",
      "Epoch 1966, 100.0%, avg_loss = 1.1582\n",
      "Epoch 1967, 100.0%, avg_loss = 1.2535\n",
      "Epoch 1968, 100.0%, avg_loss = 1.1746\n",
      "Epoch 1969, 100.0%, avg_loss = 1.1801\n",
      "Epoch 1970, 100.0%, avg_loss = 1.2100\n",
      "Validation Loss: 1.3324\n",
      "Epoch 1971, 100.0%, avg_loss = 1.2533\n",
      "Epoch 1972, 100.0%, avg_loss = 1.1592\n",
      "Epoch 1973, 100.0%, avg_loss = 1.1786\n",
      "Epoch 1974, 100.0%, avg_loss = 1.1793\n",
      "Epoch 1975, 100.0%, avg_loss = 1.1543\n",
      "Validation Loss: 1.2647\n",
      "Epoch 1976, 100.0%, avg_loss = 1.1968\n",
      "Epoch 1977, 100.0%, avg_loss = 1.2004\n",
      "Epoch 1978, 100.0%, avg_loss = 1.2051\n",
      "Epoch 1979, 100.0%, avg_loss = 1.1665\n",
      "Epoch 1980, 100.0%, avg_loss = 1.2738\n",
      "Validation Loss: 1.2777\n",
      "Epoch 1981, 100.0%, avg_loss = 1.2126\n",
      "Epoch 1982, 100.0%, avg_loss = 1.1794\n",
      "Epoch 1983, 100.0%, avg_loss = 1.1876\n",
      "Epoch 1984, 100.0%, avg_loss = 1.2654\n",
      "Epoch 1985, 100.0%, avg_loss = 1.2971\n",
      "Validation Loss: 1.2845\n",
      "Epoch 1986, 100.0%, avg_loss = 1.1837\n",
      "Epoch 1987, 100.0%, avg_loss = 1.2228\n",
      "Epoch 1988, 100.0%, avg_loss = 1.1983\n",
      "Epoch 1989, 100.0%, avg_loss = 1.2362\n",
      "Epoch 1990, 100.0%, avg_loss = 1.1939\n",
      "Validation Loss: 1.2819\n",
      "Epoch 1991, 100.0%, avg_loss = 1.2334\n",
      "Epoch 1992, 100.0%, avg_loss = 1.1970\n",
      "Epoch 1993, 100.0%, avg_loss = 1.2159\n",
      "Epoch 1994, 100.0%, avg_loss = 1.1680\n",
      "Epoch 1995, 100.0%, avg_loss = 1.1660\n",
      "Validation Loss: 1.3348\n",
      "Epoch 1996, 100.0%, avg_loss = 1.2217\n",
      "Epoch 1997, 100.0%, avg_loss = 1.1540\n",
      "Epoch 1998, 100.0%, avg_loss = 1.1575\n",
      "Epoch 1999, 100.0%, avg_loss = 1.2425\n",
      "Epoch 2000, 100.0%, avg_loss = 1.2609\n",
      "Validation Loss: 1.3267\n",
      "Epoch 2001, 20.3%, avg_loss = 1.1140\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fa3b9f93a686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_loc_qry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t_qry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_loc_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_list_train = list(data_qry_train.keys())\n",
    "time_list = list(range(T - 2 * dT + 1))\n",
    "\n",
    "# Initialize global SGD\n",
    "local_predictor_update = dict({})\n",
    "        \n",
    "for epoch in range(1, 4001):\n",
    "    \n",
    "    if epoch % 500 == 0:\n",
    "        lr *= 0.5\n",
    "    \n",
    "    update_user_list = random.sample(user_list_train, 2048)\n",
    "    random.shuffle(update_user_list)\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    cnt = 0\n",
    "    n = 0\n",
    "    \n",
    "    uidx = 0\n",
    "    \n",
    "    for uid in update_user_list:\n",
    "        uidx += 1\n",
    "        # loading server model to local\n",
    "        local_predictor.load_state_dict(local_predictor_server.state_dict())\n",
    "\n",
    "        nk = data_qry_train[uid].shape[0]\n",
    "        n += data_qry_train[uid].shape[0]\n",
    "\n",
    "        t = np.random.randint(T - 2 * dT + 1)\n",
    "        x_loc_qry = data_qry_train[uid][:, t: t + dT]\n",
    "        x_t_qry = torch.zeros_like(x_loc_qry) + t\n",
    "        y = data_qry_train[uid][:, t + 2 * dT - 1]\n",
    "\n",
    "        if uid not in data_doc:\n",
    "            loss = local_predictor(x_loc_qry, x_t_qry, None, None, y)\n",
    "        else:\n",
    "            x_loc_doc = data_doc[uid][:, t: t + 2 * dT]\n",
    "            x_t_doc = torch.zeros_like(x_loc_doc) + t\n",
    "            loss = local_predictor(x_loc_qry, x_t_qry, x_loc_doc, x_t_doc, y)\n",
    "\n",
    "        loss.backward()\n",
    "        avg_loss += loss.item()\n",
    "        cnt += nk\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for name, para in local_predictor.named_parameters():\n",
    "                if para.grad is None:\n",
    "                    continue\n",
    "                elif name not in local_predictor_update:\n",
    "                    local_predictor_update[name] = (para.grad + torch.randn_like(para.grad) * 1e-2) * lr\n",
    "                else:\n",
    "                    local_predictor_update[name] += (para.grad + torch.randn_like(para.grad) * 1e-2) * lr\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Epoch {:02d}, {:.1f}%, avg_loss = {:.4f}'.format(epoch, uidx * 100 / len(update_user_list), avg_loss / cnt), end='\\r')\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        for name, para in local_predictor_server.named_parameters():\n",
    "            para -= local_predictor_update[name]\n",
    "            \n",
    "        for name in local_predictor_update:\n",
    "            local_predictor_update[name] *= momentum\n",
    "    \n",
    "    training_loss[epoch] = avg_loss / cnt\n",
    "    print('')\n",
    "    # testing\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            cnt = 0\n",
    "            avg_loss = 0.0\n",
    "\n",
    "            for uid in data_qry_test:\n",
    "\n",
    "                if np.random.ranf() > 0.05:\n",
    "                    continue\n",
    "\n",
    "                nk = data_qry_test[uid].shape[0]\n",
    "\n",
    "                t = np.random.randint(T - 2 * dT + 1)\n",
    "                x_loc_qry = data_qry_test[uid][:, t: t + dT]\n",
    "                x_t_qry = torch.zeros_like(x_loc_qry) + t\n",
    "                y = data_qry_test[uid][:, t + 2 * dT - 1]\n",
    "\n",
    "                if uid not in data_doc:\n",
    "                    loss = local_predictor_server(x_loc_qry, x_t_qry, None, None, y)\n",
    "                else:\n",
    "                    x_loc_doc = data_doc[uid][:, t: t + 2 * dT]\n",
    "                    x_t_doc = torch.zeros_like(x_loc_doc) + t\n",
    "                    loss = local_predictor_server(x_loc_qry, x_t_qry, x_loc_doc, x_t_doc, y)\n",
    "\n",
    "                avg_loss += loss.item()\n",
    "                cnt += nk\n",
    "\n",
    "            print('Validation Loss: {:.4f}'.format(avg_loss / cnt))\n",
    "            validation_loss[epoch] = avg_loss / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(local_predictor, './results_osaka/local_predictor_fl_scratch_noise001.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results_osaka/federated_local_predictor_noise001_training_loss.pk', 'wb') as f:\n",
    "    pk.dump(training_loss, f)\n",
    "with open('./results_osaka/federated_local_predictor_noise001_validation_loss.pk', 'wb') as f:\n",
    "    pk.dump(validation_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
