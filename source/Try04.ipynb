{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import gmplot\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import time\n",
    "from tqdm import trange\n",
    "import h3\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "def geo_t_h3(data):\n",
    "    h3_list =OrderedDict()\n",
    "\n",
    "    for i in data:\n",
    "        a = h3.geo_to_h3(i[0], i[1], 10)\n",
    "        h3_list.setdefault(a)\n",
    "    return h3_list\n",
    "def h3_t_geo(data):\n",
    "    new_list = []\n",
    "    for i in data:\n",
    "        i =h3.h3_to_geo(i)\n",
    "        new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "# draw(,130,10)\n",
    "# list,文件名，放大率\n",
    "def draw(list,number,b):\n",
    "    new_list = torch.tensor(list)\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for i in new_list:\n",
    "        lat.append(i[0])\n",
    "        lng.append(i[1])\n",
    "    lat = torch.stack(lat)\n",
    "    lng =torch.stack(lng)\n",
    "    gmap = gmplot.GoogleMapPlotter(lat[0], lng[0], b)\n",
    "    gmap.plot(lat, lng,color='r',lw=10)  #描绘轨迹点\n",
    "    gmap.draw(\"user{}.html\".format(number))   #显示图\n",
    "    print(\"over\")\n",
    "# 这个提取出来有5个维度\n",
    "def dataset(user,start,end,step):\n",
    "    # user:第几个用户\n",
    "    # filenumber:取前面几天数据\n",
    "    # step：隔了多少步取一次\n",
    "    userdata =  '/Users/zhuhe/PycharmProjects/python_spring01/Geolife Trajectories 1.3/Data/' + user + '/Trajectory/'\n",
    "    filelist = os.listdir(userdata)  #返回指定路径下所有文件和文件夹的名字，并存放于一个列表中\n",
    "    filelist.sort()\n",
    "    names = ['lat','lng','zero','alt','days','date','time']\n",
    "    df_list = [# f为文件索引号，header为列数，names为列表列名，index_col为行索引的列编号或列名\n",
    "    pd.read_csv(userdata + f,header=6,names=names,index_col=False)\n",
    "    for f in filelist[start:end]]\n",
    "    df = pd.concat(df_list, ignore_index=True) #表格列字段不同的表合并\n",
    "    df.drop(['zero', 'days'], axis=1, inplace=True) #drop函数默认删除行，列需要加axis = 1\n",
    "    df_min = df.iloc[::step, :]\n",
    "    return df_min\n",
    "# 这个提取出来有2个维度\n",
    "def synthetic_data(df_min):\n",
    "    a =df_min['lat'].tolist()\n",
    "    b = df_min['lng'].tolist()\n",
    "    a = torch.tensor(a,dtype=torch.float,requires_grad=True).reshape((-1, 1))\n",
    "    b = torch.tensor(b,dtype=torch.float,requires_grad=True).reshape((-1, 1))\n",
    "    features = torch.concat([a,b],1)\n",
    "    return features\n",
    "# 将(lat,lng)变成哈希值\n",
    "def generate_h3_list(data):\n",
    "    alist = geo_t_h3(data)\n",
    "    LIST = list(alist.keys())\n",
    "    return np.array(LIST)\n",
    "\n",
    "\n",
    "# 这个提取出来有5个维度\n",
    "train_dataset = dataset(\"006\",0,20,60)\n",
    "test_dataset =  dataset(\"006\",20,25,60)\n",
    "\n",
    "# 这个提取出来有2个维度\n",
    "train_data = synthetic_data(train_dataset)\n",
    "test_data = synthetic_data(test_dataset)\n",
    "# concat()\n",
    "all_data =torch.concat([train_data,test_data],0)\n",
    "\n",
    "\n",
    "\n",
    "Train_h3_list  = generate_h3_list(train_data)\n",
    "TESETLIST  = generate_h3_list(test_data)\n",
    "all_data_h3_list = generate_h3_list(all_data)\n",
    "# 这个all_data_h3_list可以先shuffle一下\n",
    "\n",
    "\n",
    "# 可以通过idnex找到对应的h3\n",
    "vocab_reverse  = dict(enumerate(all_data_h3_list))\n",
    "# 可以通过h3编码找到对应的index\n",
    "vocab ={h3:i for i ,h3 in vocab_reverse.items()}\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False).fit(all_data_h3_list.reshape(-1,1))\n",
    "\n",
    "#y是一个列表，k是步长\n",
    "def dataloader(y,k):\n",
    "    data =[]\n",
    "    for i in range(len(y)-k+1):\n",
    "        indata = y[i:i+k]\n",
    "        outdata = y[i+k:i+k+1]\n",
    "        data.append((indata,outdata))\n",
    "    return data\n",
    "train_dataloader = dataloader(Train_h3_list,10)\n",
    "test_dataloader =dataloader(test_data,10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 提升：\n",
    "# 1。如何生成能够进行批训练的dataloader\n",
    "# 2。修改学习率,步子长短,取样的时间达到更好的效果\n",
    "# 3。现在的预测只能预测下一个点，如果想预测轨迹，应当把预测的点也当作数据输入模型\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.model =nn.LSTM(\n",
    "            input_size=vocab,\n",
    "            hidden_size=320,\n",
    "            batch_first=True,\n",
    "            bias=True\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(320,vocab),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        r_out,(h_out,c_out) = self.model(x.view(1,10,self.vocab) ,None)\n",
    "        outdata = self.output(r_out[:,-1,:])\n",
    "        return outdata\n",
    "net = RNN(len(all_data_h3_list))\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.1,momentum=0.8)\n",
    "optimizer_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<40:31,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1585.1748, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:04<37:42,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1584.8154, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [00:06<36:46,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1584.4099, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [00:08<36:22,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1584.1794, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:11<36:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1583.7769, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [00:13<35:49,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1583.3961, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [00:15<35:39,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1582.9591, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [00:17<35:45,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1582.4237, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [00:19<36:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1581.7617, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:21<35:50,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1580.8951, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [00:24<35:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1579.6691, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:26<35:28,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1577.9634, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [00:28<36:26,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1575.8523, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [00:30<36:37,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1571.4502, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [00:33<37:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1561.0111, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [00:33<36:41,  2.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m k \u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor(k)\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m      9\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(net(a),k)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     12\u001B[0m loss_ \u001B[38;5;241m=\u001B[39m loss_\u001B[38;5;241m+\u001B[39mloss\n",
      "File \u001B[0;32m~/PycharmProjects/python_spring01/venv/lib/python3.8/site-packages/torch/_tensor.py:307\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    300\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    301\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    306\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 307\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/python_spring01/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m--> 154\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(1000):\n",
    "    loss_ =0\n",
    "    for i , k in train_dataloader[:-1]:\n",
    "        optimizer.zero_grad()\n",
    "        a = encoder.transform(i.reshape(-1,1))\n",
    "        k = encoder.transform(k.reshape(-1,1))\n",
    "        a =torch.tensor(a).to(torch.float32)\n",
    "        k =torch.tensor(k).to(torch.float32)\n",
    "        loss = loss_function(net(a),k)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ = loss_+loss\n",
    "    print(loss_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "162\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataloader = dataloader(TESETLIST,10)\n",
    "\n",
    "# 能否根据当前的预测取进行下一步的预测\n",
    "lat_l =[]\n",
    "for i , k in test_dataloader[:-1]:\n",
    "        a = encoder.transform(i.reshape(-1,1))\n",
    "        k = encoder.transform(k.reshape(-1,1))\n",
    "        a =torch.tensor(a).to(torch.float32)\n",
    "        k =torch.tensor(k).to(torch.float32)\n",
    "        out = net(a)\n",
    "        out = out.detach().numpy()\n",
    "        index = np.argmax(out)\n",
    "        print(index)\n",
    "        d =vocab_reverse.get(index)\n",
    "        f = h3.h3_to_geo(str(d))\n",
    "        lat_l.append(f)\n",
    "\n",
    "draw(lat_l,150,10)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}